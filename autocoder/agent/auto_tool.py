from autocoder.pyproject import PyProject
from autocoder.tsproject import TSProject
from autocoder.suffixproject import SuffixProject
from autocoder.common import AutoCoderArgs
from autocoder.common.interpreter import Interpreter
from autocoder.common import ExecuteSteps, ExecuteStep, detect_env
from autocoder.common import code_auto_execute
from loguru import logger
import os
import io
import byzerllm
import yaml
import json
import sys
from contextlib import contextmanager
from pydantic import BaseModel
from byzerllm.types import Bool, ImagePath
from byzerllm.utils.client import code_utils
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.markdown import Markdown


class ClickPosition(BaseModel):
    left_top_x: int
    left_top_y: int
    right_bottom_x: int
    right_bottom_y: int

    def __str__(self):
        return f"left_top_x: {self.left_top_x}, left_top_y: {self.left_top_y}, right_bottom_x: {self.right_bottom_x}, right_bottom_y: {self.right_bottom_y}"


@contextmanager
def redirect_stdout():
    original_stdout = sys.stdout
    sys.stdout = f = io.StringIO()
    try:
        yield f
    finally:
        sys.stdout = original_stdout


@byzerllm.prompt()
def context() -> str:
    """
    ‰Ω†ÂùöÂÆöÁöÑÁõ∏‰ø°Ôºå‰∏ÄÂàá‰ªªÂä°ÈÉΩÂèØ‰ª•ÁºñÂÜô  Python ‰ª£Á†ÅÊù•Ëß£ÂÜ≥„ÄÇÊàë‰πà‰ºö‰πüÊèê‰æõ‰∫Ü‰∏Ä‰∏™Áõ∏Â∫îÁöÑÊâßË°å‰ª£Á†ÅÁöÑÂ∑•ÂÖ∑Ôºå‰Ω†ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™Â∑•ÂÖ∑Êù•ÊâßË°å‰Ω†ÁöÑ‰ª£Á†Å„ÄÇ
    ‰Ω†ÁöÑÁõÆÊ†áÊòØÂçèÂä©Áî®Êà∑ÊâßË°åÂêÑÁßç‰ªªÂä°ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é‰ª£Á†ÅÁîüÊàê„ÄÅ‰øÆÊîπ„ÄÅÊµãËØïÁ≠â„ÄÇËØ∑‰ªîÁªÜÈòÖËØª‰ª•‰∏ã‰ø°ÊÅØÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞ÂÆåÊàê‰ªªÂä°„ÄÇ

    ‰Ω†ÂΩìÂâçËøêË°åÁöÑÁéØÂ¢É‰ø°ÊÅØ:

    Êìç‰ΩúÁ≥ªÁªü: {{ env_info.os_name }} {{ env_info.os_version }}
    PythonÁâàÊú¨: {{ env_info.python_version }}
    {%- if env_info.conda_env %}
    CondaÁéØÂ¢É: {{ env_info.conda_env }}
    {%- endif %}
    {%- if env_info.virtualenv %}
    ËôöÊãüÁéØÂ¢É: {{ env_info.virtualenv }}
    {%- endif %}
    {%- if env_info.has_bash %}
    ÊîØÊåÅBash
    {%- else %}
    ‰∏çÊîØÊåÅBash
    {%- endif %}

    {{ project_map }}

    ‰∏ãÈù¢ÊòØ‰∏â‰∏™Ê†∏ÂøÉÁöÑÂ∑•ÂÖ∑ÔºåÂÖ∂‰ªñÂ∑•ÂÖ∑‰ºöÂú®ÂÖ∂‰ªñÂú∞Êñπ‰ªãÁªçÔºö

    1. run_python_code(code: str) -> str
       - ËøêË°åÊåáÂÆöÁöÑPython‰ª£Á†Å„ÄÇ
       - ËøîÂõû‰ª£Á†ÅÁöÑÊ†áÂáÜËæìÂá∫ÊàñÈîôËØØ‰ø°ÊÅØ„ÄÇ
       - ‰ΩøÁî®Êó∂ÈúÄÊåáÂÆöÈ°πÁõÆÊ†πÁõÆÂΩï„ÄÇ

    2. run_shell_code(script: str) -> str
       - ËøêË°åÊåáÂÆöÁöÑShell‰ª£Á†ÅÔºåÁî®‰∫éÁºñËØë„ÄÅËøêË°å„ÄÅÊµãËØïÁ≠â‰ªªÂä°„ÄÇ
       - ËøîÂõû‰ª£Á†ÅÁöÑËæìÂá∫ÊàñÈîôËØØ‰ø°ÊÅØ„ÄÇ
       - Ê≥®ÊÑèÔºö‰∏çÂÖÅËÆ∏ÊâßË°å‰ªª‰ΩïÂåÖÂê´rmÂëΩ‰ª§ÁöÑËÑöÊú¨„ÄÇ

    3. see_screen_and_do_something_by_generate_python_code(query: str) -> ClickPosition
         - ÂΩìÂâçË¶ÅÈíàÂØπÂ±èÂπïÂÅöÁöÑÊìç‰ΩúÊèèËø∞


    ‰Ω†ÊÄªÊòØÂ∞ùËØïÂéªÈÄöËøáÁºñÁ†ÅÊù•Ëß£ÂÜ≥ÈóÆÈ¢òÔºåÂπ∂‰∏îÂèëÊå•Ëá™Â∑±ÁöÑÊÉ≥Ë±°ÂäõÔºåÈÄÜÊµÅËÄå‰∏äÔºåÈî≤ËÄå‰∏çËàç„ÄÇ

    ÁâπÂà´Ê≥®ÊÑèÔºö

    1. ‰∏çÂÖÅËÆ∏Ëá™Â∑±pythonÂ∫ì
    2. ‰∏çÂÖÅËÆ∏Êúâ‰ªª‰ΩïÂà†Èô§Êñá‰ª∂ÊàñÁõÆÂΩïÁöÑÊìç‰Ωú
    3. Â∞ΩÈáè‰ΩøÁî® Python ‰ª£Á†ÅÊù•Ëß£ÂÜ≥ÈóÆÈ¢òËÄå‰∏çÊòØ Shell ËÑöÊú¨
    4. ÊâÄÊúâÂØπÂ§ñÈÉ®ÁéØÂ¢ÉÁöÑÊìç‰ΩúÈÉΩÈúÄË¶Å pyautogui ÁöÑÊúÄÊñ∞ÁâàÊú¨Êù•ÂÆûÁé∞„ÄÇ
    5. ‰Ω†ÂÜôÁöÑ‰ª£Á†ÅÂ∞ΩÈáèË¶Å‰øùÊåÅÂêàÁêÜÁöÑËæìÂá∫ÔºåÊñπ‰æøÂêéÁª≠‰Ω†ËÉΩÊ≠£Á°ÆÁöÑËßÇÂØüËøô‰∏™Â∏¶ÈòøÁ±≥ÊòØ‰∏çÊòØÂ∑≤ÁªèËææÊàê‰∫ÜÁõÆÊ†á„ÄÇ
    6. Âú®‰ΩøÁî®ÂÖ∑‰ΩìËΩØ‰ª∂ÁöÑÊó∂ÂÄôÔºåÊÄªÊòØË¶ÅÂÖàÈÄöËøáclickÊù•ËÅöÁÑ¶ËØ•ËΩØ‰ª∂ÔºåÂê¶Âàô‰Ω†ÂèØËÉΩ‰ºöÊÑèÂ§ñÁöÑÊìç‰ΩúÂà∞ÂÖ∂‰ªñËΩØ‰ª∂„ÄÇ
    """
    return {"env_info": detect_env()}


@byzerllm.prompt()
def detect_rm_command(command: str) -> Bool:
    """
    ÁªôÂÆöÂ¶Ç‰∏ãshellËÑöÊú¨Ôºö

    ```shell
    {{ command }}
    ```

    Â¶ÇÊûúËØ•ËÑöÊú¨‰∏≠ÂåÖÂê´Âà†Èô§ÁõÆÂΩïÊàñËÄÖÊñá‰ª∂ÁöÑÂëΩ‰ª§ÔºåËØ∑ËøîÂõûTrueÔºåÂê¶ÂàôËøîÂõûFalse„ÄÇ
    """


def get_tools(args: AutoCoderArgs, llm: byzerllm.ByzerLLM):
    def run_python_code(code: str) -> str:
        """
        ‰Ω†ÂèØ‰ª•ÈÄöËøáËØ•Â∑•ÂÖ∑ËøêË°åÊåáÂÆöÁöÑPython‰ª£Á†Å„ÄÇ
        ËæìÂÖ•ÂèÇÊï∞ code: Python‰ª£Á†Å
        ËøîÂõûÂÄºÊòØPython‰ª£Á†ÅÁöÑsys output ÊàñËÄÖ sys error ‰ø°ÊÅØ„ÄÇ

        ÈÄöÂ∏∏‰Ω†ÈúÄË¶ÅÂú®‰ª£Á†Å‰∏≠ÊåáÂÆöÈ°πÁõÆÁöÑÊ†πÁõÆÂΩïÔºàÂâçÈù¢Êàë‰ª¨Â∑≤ÁªèÊèêÂà∞‰∫ÜÔºâ„ÄÇ
        """
        interpreter = Interpreter(cwd=args.source_dir)
        s = ""
        try:
            s = interpreter.execute_steps(
                ExecuteSteps(steps=[ExecuteStep(lang="python", code=code)])
            )
        finally:
            interpreter.close()

        return s

    def run_shell_code(script: str) -> str:
        """
        ‰Ω†ÂèØ‰ª•ÈÄöËøáËØ•Â∑•ÂÖ∑ËøêË°åÊåáÂÆöÁöÑShell‰ª£Á†Å„ÄÇ‰∏ªË¶ÅÁî®‰∫é‰∏Ä‰∫õÁºñËØëÔºåËøêË°åÔºåÊµãËØïÁ≠â‰ªªÂä°„ÄÇ
        ËæìÂÖ•ÂèÇÊï∞ script: Shell‰ª£Á†Å
        ËøîÂõûÂÄºÊòØShell‰ª£Á†ÅÁöÑoutput ÊàñËÄÖ error ‰ø°ÊÅØ„ÄÇ
        """

        if detect_rm_command.with_llm(llm).run(script).value:
            return "The script contains rm command, which is not allowed."

        interpreter = Interpreter(cwd=args.source_dir)
        s = ""
        try:
            s = interpreter.execute_steps(
                ExecuteSteps(steps=[ExecuteStep(lang="shell", code=script)])
            )
        finally:
            interpreter.close()

        return s

    def see_screen_and_do_something_by_generate_python_code(action_desc: str):
        """
        ËØ•Â∑•ÂÖ∑ÂèØ‰ª•Â∏ÆÂä©‰Ω†Êü•ÁúãÂΩìÂâçÂ±èÂπïÊà™ÂõæÔºåÂπ∂‰∏îÊ†πÊçÆ‰∏ã‰∏ÄÊ≠•ÈúÄË¶ÅÂÅöÁöÑÊìç‰ΩúÊù•‰ΩøÁî® pyautogui ÁîüÊàêÊìç‰ΩúÁîµËÑëÁöÑ Python ‰ª£Á†Å„ÄÇ
        ËæìÂÖ•ÂèÇÊï∞ action_desc: ‰∏ã‰∏ÄÊ≠•ÈúÄË¶ÅÂÅöÁöÑÊìç‰ΩúÊèèËø∞ÔºåÊØîÂ¶ÇÂú®Âì™‰∏™Âú∞ÊñπÁÇπÂáªÊüê‰∏™ÊåâÈíÆ„ÄÅÂú®Âì™‰∏™appËæìÂÖ•Êüê‰∏™ÊñáÂ≠óÁ≠â„ÄÇ
        """
        @byzerllm.prompt()
        def analyze_screen_and_generate_code(
            image: ImagePath, action_desc: str, previous_result: str, attempt: int
        ) -> str:
            """
            {{ image }}
            
            ÁõÆÊ†áÊìç‰ΩúÔºö{{ action_desc }}
            
            {% if previous_result %}
            Ââç‰∏ÄÊ¨°Â∞ùËØïÁöÑ‰ª£Á†ÅÂíåÁªìÊûúÔºö
            ```
            {{ previous_result }}
            ```
            {% endif %}
            
            ÂΩìÂâçÊòØÁ¨¨ {{ attempt }} Ê¨°Â∞ùËØï„ÄÇ
            
            ËØ∑Ê†πÊçÆ‰ª•‰∏ãÊåáÂçóÁîüÊàêÊàñ‰øÆÊîπ Python ‰ª£Á†ÅÔºö
            
            1. ‰ªîÁªÜÂàÜÊûêÂ±èÂπïÊà™ÂõæÔºåËØÜÂà´Áõ∏ÂÖ≥ÁöÑUIÂÖÉÁ¥†ÔºàÂ¶ÇÊåâÈíÆ„ÄÅËæìÂÖ•Ê°Ü„ÄÅËèúÂçïÁ≠âÔºâ„ÄÇ
            2. Ê†πÊçÆÁõÆÊ†áÊìç‰ΩúÂíåUIÂÖÉÁ¥†Ôºå‰ΩøÁî® pyautogui Â∫ìÁîüÊàêÁõ∏Â∫îÁöÑ Python ‰ª£Á†Å„ÄÇ
            3. ‰ª£Á†ÅÂ∫îÂåÖÂê´ÂøÖË¶ÅÁöÑÈîôËØØÂ§ÑÁêÜÂíåÈ™åËØÅÊ≠•È™§„ÄÇ
            4. Â¶ÇÊûúÊòØ‰øÆÊîπÂâç‰∏ÄÊ¨°ÁöÑ‰ª£Á†ÅÔºåËØ∑Ëß£Èáä‰øÆÊîπÂéüÂõ†„ÄÇ
            5. ËæìÂá∫Â∫îÂè™ÂåÖÂê´‰∏Ä‰∏™‰ª£Á†ÅÂùóÔºå‰ΩøÁî® ```python ``` Ê†áÁ≠æÂåÖË£π„ÄÇ
            
            Ê≥®ÊÑè‰∫ãÈ°πÔºö
            - ÂßãÁªàÂÖàËÅöÁÑ¶ÁõÆÊ†áËΩØ‰ª∂ÔºåÂÜçËøõË°åÊìç‰Ωú„ÄÇ            
            - Ê∑ªÂä†ÈÄÇÂΩìÁöÑÂª∂Êó∂Ôºàpyautogui.sleep()Ôºâ‰ª•Á°Æ‰øùÊìç‰ΩúÁöÑÁ®≥ÂÆöÊÄß„ÄÇ
            - ‰ΩøÁî® try-except ÂùóÂ§ÑÁêÜÂèØËÉΩÁöÑÂºÇÂ∏∏„ÄÇ
            - Âú®ÂÖ≥ÈîÆÊ≠•È™§ÂêéÊ∑ªÂä†È™åËØÅÔºåÁ°ÆËÆ§Êìç‰ΩúÊòØÂê¶ÊàêÂäü„ÄÇ
            - Â¶ÇÊûúÊìç‰ΩúÊàêÂäüÔºåÊ∏ÖÊô∞Âú∞ÊåáÂá∫ÊàêÂäü‰ø°ÊÅØ„ÄÇ
            - Â¶ÇÊûúÊìç‰ΩúÂ§±Ë¥•ÊàñÈúÄË¶ÅËøõ‰∏ÄÊ≠•Â∞ùËØïÔºåÊèê‰æõÊòéÁ°ÆÁöÑÂ§±Ë¥•ÂéüÂõ†ÂíåÂª∫ËÆÆ„ÄÇ
            - Âä°ÂøÖ‰∏çË¶ÅÂÅö‰ªÄ‰πàÂÅáËÆæÔºåËÄåÊòØÂü∫‰∫éÂ±èÂπïÊà™ÂõæÁöÑÂÆûÈôÖÊÉÖÂÜµÊù•ÁºñÂÜô‰ª£Á†Å,‰Ω†ÁöÑ‰ª£Á†Å‰ºöË¢´Êó†‰ªª‰Ωï‰øÆÊîπÁõ¥Êé•ËøêË°å„ÄÇ
            
            Â¶ÇÊûúÊÇ®ËÆ§‰∏∫Â∑≤ÁªèËææÊàêÁõÆÊ†áÊàñÊó†Ê≥ïÁªßÁª≠Â∞ùËØïÔºåËØ∑‰∏çË¶ÅÁîüÊàê‰ª£Á†ÅÔºåËÄåÊòØÊèê‰æõ‰∏Ä‰∏™ÊÄªÁªìËØ¥Êòé„ÄÇ
            """
        
        import pyautogui
        import tempfile
        from rich.console import Console
        from rich.panel import Panel
        from rich.markdown import Markdown
        
        console = Console()
        vl_model = llm.get_sub_client("vl_model")
        
        max_attempts = 5
        for attempt in range(1, max_attempts + 1):
            # Ëé∑ÂèñÂ±èÂπïÊà™Âõæ
            screenshot = pyautogui.screenshot()
            
            # ÂàõÂª∫‰∏¥Êó∂Êñá‰ª∂
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as temp_file:
                temp_filename = temp_file.name
                screenshot.save(temp_filename)
            
            try:
                # ‰ΩøÁî®‰∏¥Êó∂Êñá‰ª∂Ë∑ØÂæÑÂàõÂª∫ ImagePath ÂØπË±°
                image_path = ImagePath(value=temp_filename)
                
                # ÁîüÊàêÊàñ‰øÆÊîπ‰ª£Á†Å
                result = analyze_screen_and_generate_code.with_llm(vl_model).run(
                    image_path, action_desc, result if attempt > 1 else "", attempt
                )
                
                console.print(Panel(Markdown(result), title=f"Ê®°ÂûãËæìÂá∫ (Â∞ùËØï {attempt})", border_style="green"))
                
                # ÊèêÂèñÂπ∂ÊâßË°å‰ª£Á†Å
                codes = code_utils.extract_code(result)
                if not codes:
                    # Â¶ÇÊûúÊ≤°ÊúâÁîüÊàê‰ª£Á†ÅÔºåÂèØËÉΩÊòØ‰ªªÂä°ÂÆåÊàêÊàñÊó†Ê≥ïÁªßÁª≠
                    return result
                
                code = codes[0][1]
                execution_result = run_python_code(code)
                
                console.print(Panel(execution_result, title=f"‰ª£Á†ÅÊâßË°åÁªìÊûú (Â∞ùËØï {attempt})", border_style="yellow"))
                
                # Êõ¥Êñ∞ÁªìÊûúÔºåÂåÖÂê´‰ª£Á†ÅÂíåÊâßË°åÁªìÊûú
                result = execution_result
            
                
                # Ê£ÄÊü•ÊòØÂê¶ÊàêÂäüÂÆåÊàê‰ªªÂä°
                if "ÊàêÂäü" in execution_result.lower():
                    console.print("[bold green]‰ªªÂä°ÊàêÂäüÂÆåÊàêÔºÅ[/bold green]")
                    return result
            
            finally:
                # Âà†Èô§‰∏¥Êó∂Êñá‰ª∂
                os.unlink(temp_filename)
        
        console.print("[bold red]ËææÂà∞ÊúÄÂ§ßÂ∞ùËØïÊ¨°Êï∞Ôºå‰ªªÂä°Êú™ËÉΩÂÆåÊàê„ÄÇ[/bold red]")
        return result
        
    from llama_index.core.tools import FunctionTool

    tools = [
        FunctionTool.from_defaults(run_python_code),
        FunctionTool.from_defaults(run_shell_code),
        FunctionTool.from_defaults(see_screen_and_do_something_by_generate_python_code),
    ]
    return tools


class AutoTool:
    def __init__(self, args: AutoCoderArgs, llm: byzerllm.ByzerLLM):
        self.llm = llm
        self.code_model = (
            self.llm.get_sub_client("code_model") if args.code_model else self.llm
        )
        self.vl_model = (
            self.llm.get_sub_client("vl_model") if args.vl_model else self.llm
        )
        self.args = args
        self.tools = get_tools(args=args, llm=llm)
        if self.args.project_type == "ts":
            self.pp = TSProject(args=self.args, llm=llm)
        elif self.args.project_type == "py":
            self.pp = PyProject(args=self.args, llm=llm)
        else:
            self.pp = SuffixProject(args=self.args, llm=self.llm, file_filter=None)

    def get_tree_like_directory_structure(self) -> str:
        self.pp.run()
        return self.pp.get_tree_like_directory_structure.prompt()

    def run(self, query: str, max_iterations: int = 20):
        from byzerllm.apps.llama_index.byzerai import ByzerAI
        from llama_index.core.agent import ReActAgent
        from autocoder.utils.rolling_display import rolling_progress

        agent = ReActAgent.from_tools(
            tools=self.tools,
            llm=ByzerAI(llm=self.code_model),
            verbose=True,
            max_iterations=max_iterations,
            context=context.prompt(),
        )

        # ‰ΩøÁî®ÊªöÂä®ÊòæÁ§∫Êù•Â±ïÁ§∫ agent ÁöÑÊÄùËÄÉËøáÁ®ã
        with rolling_progress(max_lines=5, title="ü§ñ Agent Ê≠£Âú®ÊÄùËÄÉÂíåÊâßË°å‰ªªÂä°..."):
            r = agent.chat(message=query)

        # ÊòæÁ§∫ÂÆåÊàêÊëòË¶Å
        console = Console()
        console.print("\n")
        console.print(Panel(
            r.response[:500] + ("..." if len(r.response) > 500 else ""),
            title="‚úÖ ‰ªªÂä°ÂÆåÊàê",
            border_style="green",
            padding=(1, 2)
        ))

        # print("\n\n=============EXECUTE==================")
        # executor = code_auto_execute.CodeAutoExecute(
        #     self.llm, self.args, code_auto_execute.Mode.SINGLE_ROUND
        # )
        # executor.run(query=query, context=r.response, source_code="")

        return r.response
