# Autocoder Agentic Agent èŒƒå¼ç ”ç©¶è¿‡ç¨‹è®°å½•

## ç ”ç©¶ä¿¡æ¯

**ç ”ç©¶æ—¶é—´**: 2025-01-XX
**ç ”ç©¶ç›®æ ‡**: æ·±å…¥ç†è§£ autocoder çš„ agentic agent èŒƒå¼å®ç°ï¼Œæ¢³ç†å·¥ç¨‹åŒ–ç»†èŠ‚
**ç ”ç©¶èŒƒå›´**: auto-coder 1.0.39 ç‰ˆæœ¬ï¼ˆæå–è‡ª wheel åŒ…ï¼‰
**ç ”ç©¶æ–¹æ³•**: ä»£ç é˜…è¯»ã€æ¶æ„åˆ†æã€æ¨¡å¼è¯†åˆ«

## ç ”ç©¶è¿‡ç¨‹

### ç¬¬ä¸€é˜¶æ®µï¼šæ•´ä½“æ¶æ„æ¢ç´¢

#### 1. å…¥å£ç‚¹è¯†åˆ«

é€šè¿‡ `entry_points.txt` è¯†åˆ«äº†ä¸»è¦å…¥å£ï¼š
- `auto-coder` / `auto-coder.core`: ä¸» CLI å…¥å£
- `auto-coder.chat` / `chat-auto-coder`: äº¤äº’å¼èŠå¤©ç•Œé¢
- `auto-coder.run` / `auto-coder.cli`: SDK CLI æ¥å£
- `auto-coder.rag`: RAG æ¨¡å¼

#### 2. æ ¸å¿ƒä»£ç ç»“æ„

æ‰¾åˆ°äº†ä¸¤ä¸ªæ ¸å¿ƒ Agent å®ç°ï¼š
- `autocoder/agent/base_agentic/base_agent.py` (1841è¡Œ) - åŸºç¡€ Agent å±‚
- `autocoder/common/v2/agent/agentic_edit.py` (3000+è¡Œ) - é«˜çº§ç¼–è¾‘å±‚

**æ¶æ„å‘ç°**ï¼š
```
AgenticEdit (ç»§æ‰¿) â†’ BaseAgent
    â†“
ä½¿ç”¨ç»„åˆæ¨¡å¼é›†æˆï¼š
- LLM (byzerllm.ByzerLLM / SimpleByzerLLM)
- ToolCaller (å·¥å…·è°ƒç”¨å™¨)
- AgenticConversationPruner (ä¸Šä¸‹æ–‡å‰ªè£å™¨)
- ConversationManager (å¯¹è¯ç®¡ç†å™¨)
- AgenticEditChangeManager (å˜æ›´ç®¡ç†å™¨)
- ToolRegistry (å·¥å…·æ³¨å†Œè¡¨)
- EventSystem (äº‹ä»¶ç³»ç»Ÿ)
```

### ç¬¬äºŒé˜¶æ®µï¼šæç¤ºè¯å·¥ç¨‹åˆ†æ

#### 1. è£…é¥°å™¨æœºåˆ¶å‘ç°

åœ¨ `agentic_edit.py:195` æ‰¾åˆ°äº†æ ¸å¿ƒæç¤ºè¯æ–¹æ³•ï¼š

```python
@byzerllm.prompt()
def _analyze(self, request: AgenticEditRequest) -> str:
    """
    {{system_prompt}}
    ====
    TOOL USE
    ...
    """
```

**å…³é”®å‘ç°**ï¼š
- ä½¿ç”¨ `@byzerllm.prompt()` è£…é¥°å™¨
- æ”¯æŒ Jinja2 æ¨¡æ¿è¯­æ³•
- è¿”å›å­—å…¸è¿›è¡Œå˜é‡æ³¨å…¥
- æç¤ºè¯ä¸ä»£ç åˆ†ç¦»

#### 2. ç³»ç»Ÿæç¤ºè¯ç»“æ„

åˆ†æäº†å®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆçº¦500+è¡Œï¼‰ï¼Œå‘ç°äº†æ¸…æ™°çš„åˆ†æ®µç»“æ„ï¼š

1. **SYSTEM PROMPT** - è‡ªå®šä¹‰ç³»ç»Ÿè§’è‰²
2. **TOOL USE** - å·¥å…·ä½¿ç”¨è¯´æ˜ï¼ˆæœ€å¤§çš„éƒ¨åˆ†ï¼‰
   - Tool Use Formatting (XML æ ¼å¼è¯´æ˜)
   - Tools (35+ å·¥å…·çš„è¯¦ç»†æè¿°)
   - Tool Use Examples (ä¸°å¯Œçš„ç¤ºä¾‹)
   - Tool Use Guidelines (ä½¿ç”¨æŒ‡å—)
3. **CAPABILITIES** - èƒ½åŠ›æè¿°
4. **RULES** - ä¸¥æ ¼çš„è§„åˆ™çº¦æŸ
5. **SYSTEM INFORMATION** - ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
6. **OBJECTIVE** - ç›®æ ‡å’Œå·¥ä½œæµç¨‹
7. **DEFAULT WORKFLOW** - é»˜è®¤å·¥ä½œæµ

**è®¾è®¡æ€æƒ³**ï¼š
- ç»“æ„åŒ–ã€æ¨¡å—åŒ–
- è§„åˆ™æ˜ç¡®ã€çº¦æŸæ¸…æ™°
- ç¤ºä¾‹ä¸°å¯Œã€ä¾¿äºç†è§£
- å¯æ‰©å±•ã€æ˜“ç»´æŠ¤

#### 3. å·¥å…·æè¿°è®¾è®¡

åœ¨ `agent/base_agentic/tool_registry.py` å’Œ `agent/base_agentic/default_tools.py` ä¸­å‘ç°äº†å®Œæ•´çš„å·¥å…·æ³¨å†Œæœºåˆ¶ï¼š

```python
class ToolRegistry:
    _tool_resolver_map: Dict[Type[BaseTool], Type[BaseToolResolver]] = {}
    _tag_model_map: Dict[str, Type[BaseTool]] = {}
    _tool_descriptions: Dict[str, ToolDescription] = {}
    _tool_examples: Dict[str, ToolExample] = {}
    _tool_use_guidelines: Dict[str, str] = {}
```

**å·¥å…·æ³¨å†Œæ¨¡å¼**ï¼š
```python
ToolRegistry.register_tool(
    tool_tag="read_file",
    tool_cls=ReadFileTool,
    resolver_cls=ReadFileToolResolver,
    description=ToolDescription(description="..."),
    example=ToolExample(title="...", body="..."),
    use_guideline="..."
)
```

### ç¬¬ä¸‰é˜¶æ®µï¼šä¸Šä¸‹æ–‡å·¥ç¨‹ç ”ç©¶

#### 1. å¤šå±‚æ¬¡ä¸Šä¸‹æ–‡æ„å»º

åœ¨ `agentic_edit.py:2115-2287` çš„ `analyze` æ–¹æ³•ä¸­å‘ç°äº†ç²¾å¦™çš„ä¸Šä¸‹æ–‡æ„å»ºç­–ç•¥ï¼š

**ç¬¬ä¸€å±‚ï¼šSystem**
```python
conversations = [
    {"role": "system", "content": system_prompt},
]
```

**ç¬¬äºŒå±‚ï¼šDocumentation**ï¼ˆé¢„è½®æ¬¡å¯¹è¯ï¼‰
```python
# 1. ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£
conversations.append({"role": "user", "content": library_docs_prompt})
conversations.append({"role": "assistant", "content": "I have read and understood..."})

# 2. å·¥å…·ä½¿ç”¨ä¿¡æ¯
conversations.append({"role": "user", "content": tools_prompt})
conversations.append({"role": "assistant", "content": "æˆ‘å·²ç»äº†è§£äº†å½“å‰é¡¹ç›®ä¸­å¯ç”¨çš„å·¥å…·..."})

# 3. ç”¨æˆ·è§„åˆ™
conversations.append({"role": "user", "content": rules_text})
conversations.append({"role": "assistant", "content": "I have read and understood the rules..."})
```

**ç¬¬ä¸‰å±‚ï¼šHistory**ï¼ˆå†å²å¯¹è¯æ¢å¤ï¼‰
```python
if current_conversation and current_conversation.get("messages"):
    for message in current_conversation["messages"]:
        conversations.append({
            "role": message["role"],
            "content": append_hint_to_text(
                message["content"],
                f"message_id: {message['message_id'][0:8]}"
            )
        })
```

**ç¬¬å››å±‚ï¼šCurrent Request**
```python
conversations.append({"role": "user", "content": request.user_input})
```

**å…³é”®æ´å¯Ÿ**ï¼š
- é€šè¿‡é¢„è®¾çš„ assistant å“åº”ï¼Œè®© LLM "å­¦ä¹ "æ–‡æ¡£å†…å®¹
- Documentation å±‚åªåœ¨é¦–æ¬¡å¯¹è¯æ—¶æ³¨å…¥ï¼Œä¸å ç”¨åç»­å¯¹è¯çš„ä¸Šä¸‹æ–‡
- Message ID åµŒå…¥ä¾¿äºè¿½è¸ªå’Œåˆ é™¤
- å±‚æ¬¡æ¸…æ™°ã€èŒè´£åˆ†æ˜

#### 2. Message ID ç³»ç»Ÿ

å‘ç°äº†å·§å¦™çš„ Message ID è¿½è¸ªç³»ç»Ÿï¼š

```python
message_id = self.conversation_manager.append_message(...)  # è¿”å› UUID

conversations.append({
    "role": message["role"],
    "content": append_hint_to_text(
        message["content"],
        f"message_id: {message_id[0:8]}"  # æˆªå–å‰8ä½
    )
})
```

**ä½œç”¨**ï¼š
1. ç²¾ç¡®å®šä½æ¶ˆæ¯ï¼ˆUUIDï¼‰
2. åœ¨å†…å®¹ä¸­åµŒå…¥æç¤ºï¼ˆå‰8ä½ï¼‰
3. æ”¯æŒåŸºäº ID çš„åˆ é™¤ï¼ˆconversation_message_ids_write å·¥å…·ï¼‰
4. ä¾¿äºè¿½è¸ªå’Œè°ƒè¯•

### ç¬¬å››é˜¶æ®µï¼šä¸Šä¸‹æ–‡å‰ªè£æ·±åº¦ç ”ç©¶ï¼ˆæ ¸å¿ƒäº®ç‚¹ï¼‰

#### 1. AgenticConversationPruner æ¶æ„

åœ¨ `common/pruner/agentic_conversation_pruner.py` ä¸­å‘ç°äº†ä¸¤é˜¶æ®µå‰ªè£ç­–ç•¥ï¼š

```python
def prune_conversations(self, conversations: List[Dict[str, Any]]):
    # é˜¶æ®µ1ï¼šMessage IDs-based pruningï¼ˆç²¾ç¡®åˆ é™¤ï¼‰
    processed_conversations = self._apply_message_ids_pruning(conversations)

    # è®¡ç®—å½“å‰ token æ•°
    current_tokens = count_tokens(json.dumps(processed_conversations))

    # é˜¶æ®µ2ï¼šTool cleanup pruningï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰
    if current_tokens > safe_zone_tokens:
        processed_conversations = self._unified_tool_cleanup_prune(
            processed_conversations, config
        )

    return processed_conversations
```

**è®¾è®¡æ€æƒ³**ï¼š
- å…ˆæ‰§è¡Œç”¨æˆ·ï¼ˆLLMï¼‰æŒ‡å®šçš„ç²¾ç¡®åˆ é™¤
- å†æ ¹æ® token é™åˆ¶è¿›è¡Œæ™ºèƒ½å‹ç¼©
- ä¿ç•™æœ€å…³é”®çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

#### 2. Message IDs Pruningï¼ˆç²¾ç¡®åˆ é™¤ï¼‰

å‘ç°äº† `ConversationMessageIdsPruner` ç±»å’Œé…å¥—çš„å·¥å…·ï¼š

**å·¥å…·å®šä¹‰**ï¼š
```python
class ConversationMessageIdsWriteTool(BaseTool):
    message_ids: str  # "9226b3a4,204e1cd8"
    action: str  # "create", "append", "delete"
```

**LLM ä½¿ç”¨æ–¹å¼**ï¼š
```xml
<conversation_message_ids_write>
<message_ids>9226b3a4,204e1cd8</message_ids>
<action>create</action>
</conversation_message_ids_write>
```

**å‰ªè£é€»è¾‘**ï¼š
```python
ids_to_delete = set(conversation_message_ids.message_ids.split(','))
pruned = [
    msg for msg in conversations
    if self._extract_message_id(msg) not in ids_to_delete
]
```

**å…³é”®æ´å¯Ÿ**ï¼š
- LLM å¯ä»¥ä¸»åŠ¨æ ‡è®°ä¸éœ€è¦çš„æ¶ˆæ¯
- 8ä½çŸ­ ID æ–¹ä¾¿ LLM è¯†åˆ«å’Œä½¿ç”¨
- ç²¾ç¡®æ§åˆ¶ã€ä¸è¯¯åˆ 

#### 3. Tool Cleanup Pruningï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰

å‘ç°äº† `ToolContentDetector` ç±»å’Œå‹ç¼©ç­–ç•¥ï¼š

**å¯å‹ç¼©å†…å®¹è¯†åˆ«**ï¼š
```python
class ToolContentDetector:
    def detect_tool_call(self, content: str) -> Optional[Dict]:
        # æ£€æµ‹ <tool_tag>...</tool_tag>
        tool_match = re.search(r'<([a-zA-Z0-9_]+)>', content)

        # æ£€æµ‹å¤§å‹å†…å®¹å­—æ®µ
        if self._has_large_content_field(content):
            return {"tool_name": tool_name, "has_large_content": True}

    def _has_large_content_field(self, content: str) -> bool:
        # æ£€æµ‹ <content>, <diff>, <path> ç­‰å¤§å­—æ®µ
        large_fields = ['content', 'diff', 'path', 'command']
        for field in large_fields:
            if f'<{field}>' in content:
                return True
```

**å‹ç¼©ç­–ç•¥**ï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰ï¼š
```python
def _unified_tool_cleanup_prune(self, conversations, config):
    cleanable_messages = []

    # 1. è¯†åˆ«æ‰€æœ‰å¯æ¸…ç†çš„æ¶ˆæ¯
    for i, conv in enumerate(conversations):
        if role == "user" and self._is_tool_result_message(content):
            cleanable_messages.append({"index": i, "type": "tool_result"})
        elif role == "assistant" and is_tool_call_content(content):
            cleanable_messages.append({"index": i, "type": "tool_call"})

    # 2. æŒ‰ä¼˜å…ˆçº§æ¸…ç†ï¼ˆå·¥å…·ç»“æœ > å·¥å…·è°ƒç”¨ï¼‰
    for message_info in cleanable_messages:
        if current_tokens <= safe_zone_tokens:
            break
        if remaining_unpruned < 6:  # ä¿ç•™è‡³å°‘6æ¡æ¶ˆæ¯
            break

        # æ›¿æ¢ä¸ºç®€åŒ–ç‰ˆæœ¬
        if msg_type == "tool_result":
            replacement = "<tool_result ...><message>Content cleared to save tokens</message>...</tool_result>"
        elif msg_type == "tool_call":
            # æˆªæ–­å¤§å‹å‚æ•°åˆ° max_content_length=500
            new_content = replace_tool_content(original, max_length=500)
```

**å…³é”®å‘ç°**ï¼š
- ä¼˜å…ˆæ¸…ç†å·¥å…·ç»“æœï¼ˆé€šå¸¸æœ€å¤§ï¼‰
- å…¶æ¬¡æ¸…ç†å·¥å…·è°ƒç”¨çš„å¤§å‚æ•°
- ä¿ç•™æ¶ˆæ¯ç»“æ„å’Œç±»å‹ä¿¡æ¯
- è‡³å°‘ä¿ç•™6æ¡æœªè£å‰ªæ¶ˆæ¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼‰
- Token é©±åŠ¨çš„åŠ¨æ€å‹ç¼©

#### 4. å®‰å…¨åŒºé…ç½®

å‘ç°äº†çµæ´»çš„é…ç½®ç³»ç»Ÿï¼š

```python
# æ”¯æŒå¤šç§æ ¼å¼
self.args.conversation_prune_safe_zone_tokens = "80k"   # 80K tokens
self.args.conversation_prune_safe_zone_tokens = 81920   # ç›´æ¥æ•°å­—
self.args.conversation_prune_safe_zone_tokens = "0.8"   # æ¨¡å‹çª—å£çš„80%
```

**è§£æé€»è¾‘**ï¼š
```python
def parse_conversation_prune_safe_zone_tokens(value, code_model):
    if value.endswith('k'):
        return int(float(value[:-1]) * 1024)
    elif value.endswith('M'):
        return int(float(value[:-1]) * 1024 * 1024)
    elif float(value) < 1.0:  # ç™¾åˆ†æ¯”
        model_window = self._get_model_window_size(code_model)
        return int(model_window * float(value))
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- çµæ´»é…ç½®
- è‡ªé€‚åº”ä¸åŒæ¨¡å‹
- æ˜“äºç†è§£å’Œè°ƒæ•´

### ç¬¬äº”é˜¶æ®µï¼šæµå¼å“åº”è§£æç ”ç©¶ï¼ˆæ ¸å¿ƒæŠ€æœ¯ï¼‰

#### 1. stream_and_parse_llm_response æ–¹æ³•

åœ¨ `agentic_edit.py:2747-2999` å‘ç°äº†å®Œæ•´çš„æµå¼è§£æå®ç°ï¼ˆ250+è¡Œï¼‰ã€‚

**æ ¸å¿ƒç®—æ³•**ï¼šçŠ¶æ€æœº + å¢é‡è§£æ

**çŠ¶æ€å®šä¹‰**ï¼š
```python
in_tool_block = False      # æ˜¯å¦åœ¨å·¥å…·è°ƒç”¨å—ä¸­
in_thinking_block = False  # æ˜¯å¦åœ¨æ€è€ƒå—ä¸­
current_tool_tag = None    # å½“å‰å·¥å…·æ ‡ç­¾
buffer = ""                # ç¼“å†²åŒº
```

**çŠ¶æ€è½¬æ¢é€»è¾‘**ï¼š
```
æ™®é€šæ–‡æœ¬ â†’ é‡åˆ° <thinking> â†’ æ€è€ƒå—
æ™®é€šæ–‡æœ¬ â†’ é‡åˆ° <tool_tag> â†’ å·¥å…·å—
æ€è€ƒå— â†’ é‡åˆ° </thinking> â†’ æ™®é€šæ–‡æœ¬
å·¥å…·å— â†’ é‡åˆ° </tool_tag> â†’ æ™®é€šæ–‡æœ¬
```

**å¢é‡è§£ææµç¨‹**ï¼š
```python
for content_chunk, metadata in generator:
    buffer += content_chunk  # è¿½åŠ åˆ°ç¼“å†²åŒº

    while True:  # å†…å±‚å¾ªç¯å¤„ç†ç¼“å†²åŒº
        if in_thinking_block:
            # æŸ¥æ‰¾ </thinking>
            end_pos = buffer.find("</thinking>")
            if end_pos != -1:
                yield LLMThinkingEvent(text=buffer[:end_pos])
                buffer = buffer[end_pos + len("</thinking>"):]
                in_thinking_block = False
                continue
            else:
                break  # éœ€è¦æ›´å¤šæ•°æ®

        elif in_tool_block:
            # æŸ¥æ‰¾ </tool_tag>
            end_tag = f"</{current_tool_tag}>"
            end_pos = buffer.find(end_tag)
            if end_pos != -1:
                tool_xml = buffer[:end_pos + len(end_tag)]
                tool_obj = parse_tool_xml(tool_xml, current_tool_tag)
                yield ToolCallEvent(tool=tool_obj, tool_xml=...)
                buffer = buffer[end_pos + len(end_tag):]
                in_tool_block = False
                continue
            else:
                break

        else:  # æ™®é€šæ–‡æœ¬çŠ¶æ€
            # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæ ‡ç­¾
            start_think_pos = buffer.find("<thinking>")
            tool_match = re.search(r"<([a-zA-Z0-9_]+)>", buffer)

            # ç¡®å®šå…ˆé‡åˆ°å“ªä¸ªæ ‡ç­¾
            if start_think_pos != -1:
                yield LLMOutputEvent(text=buffer[:start_think_pos])
                buffer = buffer[start_think_pos + len("<thinking>"):]
                in_thinking_block = True
                continue
            elif tool_match and tool_name in TOOL_MODEL_MAP:
                yield LLMOutputEvent(text=buffer[:tool_match.start()])
                buffer = buffer[tool_match.start():]
                in_tool_block = True
                current_tool_tag = tool_name
                continue
            else:
                # ä¿ç•™æœ€å100å­—ç¬¦ï¼ˆé˜²æ­¢æ ‡ç­¾è¢«æˆªæ–­ï¼‰
                split_point = max(0, len(buffer) - 100)
                if buffer[:split_point]:
                    yield LLMOutputEvent(text=buffer[:split_point])
                    buffer = buffer[split_point:]
                break
```

**å…³é”®æŠ€æœ¯ç‚¹**ï¼š
1. **åŒå±‚å¾ªç¯**ï¼šå¤–å±‚æ¥æ”¶æµï¼Œå†…å±‚å¤„ç†ç¼“å†²åŒº
2. **å°¾éƒ¨ä¿ç•™**ï¼šä¿ç•™100å­—ç¬¦é˜²æ­¢æ ‡ç­¾è¢«æˆªæ–­
3. **çŠ¶æ€æœº**ï¼šæ¸…æ™°çš„çŠ¶æ€è½¬æ¢é€»è¾‘
4. **å¢é‡å‘é€**ï¼šè¾¹è§£æè¾¹ yieldï¼Œå®æ—¶åé¦ˆ
5. **é”™è¯¯å®¹é”™**ï¼šè§£æå¤±è´¥æ—¶ä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†

#### 2. XML vs JSON çš„é€‰æ‹©

**å‘ç°çš„åŸå› **ï¼š

XML ä¼˜åŠ¿ï¼š
```xml
<write_to_file>
<path>src/main.py</path>
<content>
def hello():
    print("Hello World")
    return 42
</content>
</write_to_file>
```

JSON éœ€è¦è½¬ä¹‰ï¼š
```json
{
  "tool": "write_to_file",
  "content": "def hello():\n    print(\"Hello World\")\n    return 42"
}
```

**è®¾è®¡å†³ç­–**ï¼š
- å¤šè¡Œå†…å®¹æ— éœ€è½¬ä¹‰
- æµå¼è§£ææ›´è‡ªç„¶ï¼ˆåŸºäºæ ‡ç­¾åŒ¹é…ï¼‰
- æ›´æ˜“äººç±»é˜…è¯»å’Œè°ƒè¯•
- LLM ç”Ÿæˆæ›´ç¨³å®š

#### 3. stream_chat_with_continue ç»­å†™æœºåˆ¶

åœ¨ `common/utils_code_auto_generate.py:57-121` å‘ç°äº†ç»­å†™å®ç°ï¼š

```python
def stream_chat_with_continue(llm, conversations, llm_config, args):
    count = 0
    temp_conversations = [] + conversations

    while True:
        # æµå¼ç”Ÿæˆ
        stream_generator = llm.stream_chat_oai(
            conversations=temp_conversations,
            llm_config={
                ...
                "gen.response_prefix": True if count > 0 else False
            }
        )

        current_content = ""
        for res in stream_generator:
            content = res[0]
            current_content += content
            yield (content, metadata)

        # è¿½åŠ åˆ°å¯¹è¯å†å²
        temp_conversations.append({"role": "assistant", "content": current_content})

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
        if current_metadata.finish_reason != "length" or count >= args.generate_max_rounds:
            break

        count += 1
```

**å…³é”®æœºåˆ¶**ï¼š
- `finish_reason == "length"` è¡¨ç¤ºè¾“å‡ºè¢«æˆªæ–­
- `response_prefix=True` è¡¨ç¤ºç»­å†™å‰æ–‡
- è‡ªåŠ¨è¿½åŠ å†å²ï¼Œæ— ç¼è¡”æ¥
- æœ€å¤šç»­å†™ `generate_max_rounds` æ¬¡

### ç¬¬å…­é˜¶æ®µï¼šå·¥å…·ç³»ç»Ÿç ”ç©¶

#### 1. ToolRegistry æ³¨å†Œè¡¨æ¨¡å¼

å‘ç°äº†å®Œæ•´çš„å·¥å…·æ³¨å†Œæœºåˆ¶ï¼ˆ437è¡Œï¼‰ï¼š

```python
class ToolRegistry:
    # ç±»å˜é‡ï¼ˆå…¨å±€å…±äº«ï¼‰
    _tool_resolver_map: ClassVar[Dict[Type[BaseTool], Type[BaseToolResolver]]] = {}
    _tag_model_map: ClassVar[Dict[str, Type[BaseTool]]] = {}
    _tool_descriptions: ClassVar[Dict[str, ToolDescription]] = {}
    _tool_examples: ClassVar[Dict[str, ToolExample]] = {}
    _tool_use_guidelines: ClassVar[Dict[str, str]] = {}
    _default_tools: ClassVar[Dict[str, Type[BaseTool]]] = {}
```

**æ³¨å†Œæµç¨‹**ï¼š
```python
# 1. å®šä¹‰å·¥å…·ç±»
class ReadFileTool(BaseTool):
    path: str
    start_line: Optional[int] = None
    end_line: Optional[int] = None

# 2. å®šä¹‰ Resolver
class ReadFileToolResolver(BaseToolResolver):
    def resolve(self) -> ToolResult:
        # å®ç°é€»è¾‘
        ...

# 3. æ³¨å†Œ
ToolRegistry.register_tool(
    tool_tag="read_file",
    tool_cls=ReadFileTool,
    resolver_cls=ReadFileToolResolver,
    description=ToolDescription(...),
    example=ToolExample(...)
)
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- é›†ä¸­ç®¡ç†
- åŠ¨æ€æ³¨å†Œ/å¸è½½
- ç±»å‹å®‰å…¨ï¼ˆType hintsï¼‰
- æ˜“äºæ‰©å±•

#### 2. Resolver æ¨¡å¼

å‘ç°äº†ç®€æ´çš„ Resolver æŠ½è±¡ï¼š

```python
class BaseToolResolver(ABC):
    def __init__(self, agent: AgenticEdit, tool: BaseTool, args: AutoCoderArgs):
        self.agent = agent  # è®¿é—® agent ä¸Šä¸‹æ–‡
        self.tool = tool    # å·¥å…·å‚æ•°
        self.args = args    # å…¨å±€é…ç½®

    @abstractmethod
    def resolve(self) -> ToolResult:
        pass
```

**ä¼˜åŠ¿**ï¼š
- èŒè´£å•ä¸€ï¼ˆSingle Responsibilityï¼‰
- ä¾èµ–æ³¨å…¥ï¼ˆDependency Injectionï¼‰
- æ˜“äºæµ‹è¯•
- ç»Ÿä¸€æ¥å£

#### 3. 35+ å·¥å…·å®šä¹‰

åœ¨ `agentic_edit_types.py` ä¸­å‘ç°äº†å®Œæ•´çš„å·¥å…·å®šä¹‰ï¼š

**åˆ†ç±»ç»Ÿè®¡**ï¼š
- åŸºç¡€å·¥å…·ï¼šExecuteCommandTool, ReadFileTool, WriteToFileTool, ReplaceInFileTool (4ä¸ª)
- æœç´¢å·¥å…·ï¼šSearchFilesTool, ListFilesTool, ListCodeDefinitionNamesTool (3ä¸ª)
- äº¤äº’å·¥å…·ï¼šAskFollowupQuestionTool, AttemptCompletionTool, PlanModeRespondTool (3ä¸ª)
- é›†æˆå·¥å…·ï¼šUseMcpTool, UseRAGTool, RunNamedSubagentsTool (3ä¸ª)
- ç®¡ç†å·¥å…·ï¼šTodo/ACMod/ConversationMessageIds ç›¸å…³ (9ä¸ª)
- ä¼šè¯å·¥å…·ï¼šSessionStartTool, SessionInteractiveTool, SessionStopTool (3ä¸ª)
- é«˜çº§å·¥å…·ï¼šCountTokensTool, ExtractToTextTool, BackgroundTaskTool, WebCrawlTool, WebSearchTool (5ä¸ª)

**Pydantic å®šä¹‰ä¼˜åŠ¿**ï¼š
- è‡ªåŠ¨å‚æ•°éªŒè¯
- ç±»å‹æç¤º
- åºåˆ—åŒ–/ååºåˆ—åŒ–
- ç”Ÿæˆæ–‡æ¡£

### ç¬¬ä¸ƒé˜¶æ®µï¼šäº‹ä»¶ä¸å›è°ƒç³»ç»Ÿç ”ç©¶

#### 1. äº‹ä»¶ç±»å‹ä½“ç³»

å‘ç°äº†20+ç§äº‹ä»¶ç±»å‹ï¼ˆåœ¨ `agentic_edit_types.py:249-310`ï¼‰ï¼š

**æ ¸å¿ƒäº‹ä»¶**ï¼š
```python
class LLMOutputEvent(BaseModel):
    text: str

class LLMThinkingEvent(BaseModel):
    text: str

class ToolCallEvent(BaseModel):
    tool: SkipValidation[BaseTool]
    tool_xml: str

class ToolResultEvent(BaseModel):
    tool_name: str
    result: ToolResult

class CompletionEvent(BaseModel):
    completion: SkipValidation[AttemptCompletionTool]
    completion_xml: str
```

**å…ƒæ•°æ®äº‹ä»¶**ï¼š
```python
class TokenUsageEvent(BaseModel):
    usage: Any

class WindowLengthChangeEvent(BaseModel):
    tokens_used: int
    pruned_tokens_used: int
    conversation_round: int

class ConversationIdEvent(BaseModel):
    conversation_id: str
```

**æ§åˆ¶äº‹ä»¶**ï¼š
```python
class ErrorEvent(BaseModel):
    message: str

class RetryEvent(BaseModel):
    message: str
```

#### 2. AgenticCallBacks å›è°ƒç³»ç»Ÿ

åœ¨ `agentic_callbacks.py:43-271` å‘ç°äº†å®Œæ•´çš„å›è°ƒç®¡ç†å™¨ï¼š

**å›è°ƒç‚¹å®šä¹‰**ï¼ˆ16ä¸ªï¼‰ï¼š
```python
class AgenticCallbackPoint(str, Enum):
    CONVERSATION_START = "conversation_start"
    CONVERSATION_END = "conversation_end"
    PRE_TOOL_CALL = "pre_tool_call"
    POST_TOOL_CALL = "post_tool_call"
    API_REQUEST_START = "api_request_start"
    API_REQUEST_END = "api_request_end"
    PRE_RULES_LOADED = "pre_rules_loaded"
    POST_RULES_LOADED = "post_rules_loaded"
    PRE_LLM_FRIENDLY_PACKAGES_LOADED = "pre_llm_friendly_packages_loaded"
    POST_LLM_FRIENDLY_PACKAGES_LOADED = "post_llm_friendly_packages_loaded"
    PRE_TOOLS_LOADED = "pre_tools_loaded"
    POST_TOOLS_LOADED = "post_tools_loaded"
    PRE_CONVERSATION_RESUMED = "pre_conversation_resumed"
    POST_CONVERSATION_RESUMED = "post_conversation_resumed"
    TOOL_GENERATED_STARTED = "tool_generated_started"
    TOOL_GENERATED_END = "tool_generated_end"
```

**å›è°ƒç®¡ç†å™¨**ï¼š
```python
class AgenticCallBacks(BaseModel):
    _callbacks: Dict[AgenticCallbackPoint, List[AgenticCallbackFunction]] = PrivateAttr(default_factory=dict)

    def register(self, callback_point, callback_func) -> bool:
        # æ³¨å†Œå›è°ƒ
        ...

    def execute_callbacks(self, callback_point, context) -> List[Exception]:
        # æ‰§è¡Œæ‰€æœ‰å›è°ƒ
        for callback_func in self._callbacks[callback_point]:
            try:
                callback_func(context)
            except Exception as e:
                errors.append(e)
        return errors
```

**ä½¿ç”¨åœºæ™¯**ï¼š
```python
# åœ¨å…³é”®ä½ç½®æ‰§è¡Œå›è°ƒ
self.callbacks.execute_callbacks(
    AgenticCallbackPoint.PRE_TOOL_CALL,
    agentic_context
)

# å·¥å…·æ‰§è¡Œ
tool_result = self.tool_caller.call_tool(...)

self.callbacks.execute_callbacks(
    AgenticCallbackPoint.POST_TOOL_CALL,
    agentic_context
)
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- éä¾µå…¥å¼æ‰©å±•
- è§£è€¦ä¸šåŠ¡é€»è¾‘
- æ”¯æŒå¤šä¸ªå›è°ƒ
- é”™è¯¯éš”ç¦»

### ç¬¬å…«é˜¶æ®µï¼šå¯¹è¯ç®¡ç†ç ”ç©¶

#### 1. ConversationManager å•ä¾‹æ¨¡å¼

åœ¨ `conversations/get_conversation_manager.py:8-70` å‘ç°äº†çº¿ç¨‹å®‰å…¨çš„å•ä¾‹å®ç°ï¼š

```python
class ConversationManagerSingleton:
    _instance: Optional[PersistConversationManager] = None
    _lock = threading.Lock()
    _config: Optional[ConversationManagerConfig] = None

    @classmethod
    def get_instance(cls, config=None):
        if cls._instance is None:
            with cls._lock:  # åŒé‡æ£€æŸ¥é”å®š
                if cls._instance is None:
                    cls._instance = PersistConversationManager(config)
        return cls._instance
```

**é…ç½®ç»“æ„**ï¼š
```python
ConversationManagerConfig(
    storage_path=".auto-coder/conversations",
    max_cache_size=100,
    cache_ttl=300.0,
    lock_timeout=10.0,
    backup_enabled=True,
    backup_interval=3600.0,
    max_backups=10
)
```

#### 2. å‘½åç©ºé—´ç®¡ç†

å‘ç°äº†å¤šé¡¹ç›®éš”ç¦»çš„å‘½åç©ºé—´ç³»ç»Ÿï¼š

```python
# è®¾ç½®å½“å‰å¯¹è¯ï¼ˆæŒ‰å‘½åç©ºé—´ï¼‰
manager.set_current_conversation(conv_id, namespace="my_project")

# è·å–å½“å‰å¯¹è¯
current_id = manager.get_current_conversation_id(namespace="my_project")

# åˆ—å‡ºæ‰€æœ‰å‘½åç©ºé—´
namespaces = manager.list_namespaces()
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- å¤šé¡¹ç›®åŒæ—¶å·¥ä½œ
- ä¸Šä¸‹æ–‡éš”ç¦»
- çµæ´»åˆ‡æ¢

### ç¬¬ä¹é˜¶æ®µï¼šAgent Hub å’Œ Group ç³»ç»Ÿç ”ç©¶

#### 1. AgentHub å’Œ GroupHub

åœ¨ `agent/base_agentic/agent_hub.py:16-78` å‘ç°äº†ä¸¤ä¸ªä¸­å¿ƒç®¡ç†å™¨ï¼š

```python
class AgentHub:
    _instance = None
    agents: Dict[str, 'BaseAgent'] = {}

    @classmethod
    def register_agent(cls, agent):
        cls.agents[agent.name] = agent

class GroupHub:
    _instance = None
    groups: Dict[str, 'Group'] = {}
    _groups_lock = threading.RLock()

    @classmethod
    def register_group(cls, group):
        with cls._groups_lock:
            cls.groups[group.name] = group
```

#### 2. Group ç±»è®¾è®¡

å‘ç°äº†çº¿ç¨‹å®‰å…¨çš„ç¾¤ç»„å®ç°ï¼š

```python
class Group:
    # ç±»çº§çº¿ç¨‹æ± ï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
    _executor = ThreadPoolExecutor(max_workers=min(32, (os.cpu_count() or 1) * 4 + 4))

    def __init__(self, name: str):
        self.members: List[Agent] = []
        self.history: List[Message] = []
        self._members_lock = threading.RLock()
        self._history_lock = threading.RLock()

    def broadcast(self, message: Message):
        # å¹¶è¡Œå‘é€æ¶ˆæ¯
        futures = []
        for member in self.members:
            if member.name == message.sender:
                continue
            futures.append(
                self._executor.submit(
                    self._safe_send_message,
                    member, message
                )
            )
```

**å…³é”®è®¾è®¡**ï¼š
- ç±»çº§çº¿ç¨‹æ± ï¼ˆèµ„æºå…±äº«ï¼‰
- è¯»å†™é”ï¼ˆå¹¶å‘å®‰å…¨ï¼‰
- å¹¶è¡Œæ¶ˆæ¯å¹¿æ’­ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
- è‡ªåŠ¨æ³¨å†Œåˆ° Hub

### ç¬¬åé˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–å’Œå·¥ç¨‹å®è·µç ”ç©¶

#### 1. ç¼“å­˜æœºåˆ¶

å‘ç°äº†å¤šå¤„ç¼“å­˜ä¼˜åŒ–ï¼š

**å·¥å…·æ ‡ç­¾ç¼“å­˜**ï¼š
```python
_tool_tag_cache = {}

def _reconstruct_tool_xml(self, tool: BaseTool) -> str:
    tool_type = type(tool)
    tool_tag = self._tool_tag_cache.get(tool_type)
    if tool_tag is None:
        tool_tag = self._find_tool_tag(tool_type)
        self._tool_tag_cache[tool_type] = tool_tag
```

**æ¨¡å‹ä¿¡æ¯ç¼“å­˜**ï¼š
```python
if not hasattr(self, '_cached_model_info'):
    self._cached_model_info = llms_utils.get_model_info(model_name)
    self._cached_model_name = model_name
```

#### 2. Token ç»Ÿè®¡å’Œæˆæœ¬è¿½è¸ª

å‘ç°äº†å®Œæ•´çš„ Token è¿½è¸ªç³»ç»Ÿï¼š

```python
# ç´¯ç§¯ç»Ÿè®¡
total_input_tokens += metadata.input_tokens_count
total_output_tokens += metadata.generated_tokens_count

# æˆæœ¬è®¡ç®—
input_cost = (input_tokens * input_price) / 1000000
output_cost = (output_tokens * output_price) / 1000000

# LLM metadata åˆ›å»º
llm_metadata = {
    "model_name": model_name,
    "input_tokens": input_tokens,
    "output_tokens": output_tokens,
    "input_cost": input_cost,
    "output_cost": output_cost,
    "conversation_round": len(conversations) - 1
}

# å›å†™åˆ°æ¶ˆæ¯
self.conversation_manager.update_message(
    conversation_id=conv_id,
    message_id=message_id,
    llm_metadata=llm_metadata
)
```

#### 3. åå°ä»»åŠ¡ç®¡ç†

å‘ç°äº† `BackgroundProcessNotifier` ç³»ç»Ÿï¼š

```python
# æ£€æŸ¥åå°ä»»åŠ¡
notifier = get_background_process_notifier()
if notifier.has_messages(conv_id):
    msgs = notifier.poll_messages(conv_id, max_items=64)

    # æ ¼å¼åŒ–é€šçŸ¥
    summary_text = format_background_task_summary(msgs)

    # æ³¨å…¥åˆ°å¯¹è¯
    conversations.append({
        "role": "user",
        "content": summary_text
    })
```

**BackgroundTaskTool**ï¼š
- list: åˆ—å‡ºåå°ä»»åŠ¡
- monitor: ç›‘æ§ä»»åŠ¡è¾“å‡º
- cleanup: æ¸…ç†å·²å®Œæˆä»»åŠ¡
- kill: ç»ˆæ­¢è¿è¡Œä»»åŠ¡

#### 4. é”™è¯¯å¤„ç†å’Œé‡è¯•

å‘ç°äº†å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š

```python
retry_count = 0
max_retries = self.args.agentic_connection_retries

while True:
    try:
        # æ‰§è¡Œæ“ä½œ
        ...
        break  # æˆåŠŸåˆ™é€€å‡º
    except Exception as e:
        if isinstance(e, CancelRequestedException):
            raise e  # ç”¨æˆ·å–æ¶ˆï¼Œä¸é‡è¯•

        retry_count += 1

        if max_retries == -1 or retry_count <= max_retries:
            # ç”Ÿæˆ RetryEvent
            yield RetryEvent(
                message=f"Retry {retry_count}/{max_retries}: {str(e)}"
            )
            continue
        else:
            # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°
            yield ErrorEvent(message=f"Failed after {retry_count} retries")
            break
```

**global_cancel æœºåˆ¶**ï¼š
```python
# åœ¨å…³é”®ä½ç½®æ£€æŸ¥å–æ¶ˆ
global_cancel.check_and_raise(token=self.cancel_token)
```

## æ ¸å¿ƒå‘ç°æ€»ç»“

### 1. æ¶æ„è®¾è®¡ä¼˜ç§€ä¹‹å¤„

- **åŒå±‚æ¶æ„**ï¼šBaseAgent + AgenticEditï¼ŒèŒè´£æ¸…æ™°
- **ç»„åˆä¼˜äºç»§æ‰¿**ï¼šå¤§é‡ä½¿ç”¨ç»„åˆæ¨¡å¼
- **ä¾èµ–æ³¨å…¥**ï¼šResolver æ¨¡å¼ï¼Œä¾¿äºæµ‹è¯•
- **å•ä¾‹æ¨¡å¼**ï¼šå…¨å±€èµ„æºç»Ÿä¸€ç®¡ç†
- **æ³¨å†Œè¡¨æ¨¡å¼**ï¼šå·¥å…·åŠ¨æ€æ³¨å†Œï¼Œæ˜“äºæ‰©å±•

### 2. æç¤ºè¯å·¥ç¨‹äº®ç‚¹

- **è£…é¥°å™¨æ¨¡å¼**ï¼šæç¤ºè¯ä¸ä»£ç åˆ†ç¦»
- **Jinja2 æ¨¡æ¿**ï¼šåŠ¨æ€å˜é‡æ³¨å…¥
- **ç»“æ„åŒ–æç¤ºè¯**ï¼šæ¸…æ™°çš„åˆ†æ®µç»“æ„
- **XML æ ¼å¼**ï¼šé€‚åˆå¤šè¡Œå†…å®¹å’Œæµå¼è§£æ
- **ä¸°å¯Œç¤ºä¾‹**ï¼šå¸®åŠ© LLM ç†è§£å·¥å…·ä½¿ç”¨

### 3. ä¸Šä¸‹æ–‡ç®¡ç†åˆ›æ–°

- **å¤šå±‚æ¬¡æ„å»º**ï¼šSystem â†’ Documentation â†’ History â†’ Current
- **é¢„è½®æ¬¡å­¦ä¹ **ï¼šé€šè¿‡é¢„è®¾ assistant å“åº”è®© LLM "å­¦ä¹ "æ–‡æ¡£
- **Message ID ç³»ç»Ÿ**ï¼šç²¾ç¡®è¿½è¸ªå’Œåˆ é™¤
- **ä¸¤é˜¶æ®µå‰ªè£**ï¼šç²¾ç¡®åˆ é™¤ + æ™ºèƒ½å‹ç¼©
- **å®‰å…¨åŒºé…ç½®**ï¼šçµæ´»çš„ Token é™åˆ¶

### 4. æµå¼è§£ææŠ€æœ¯

- **çŠ¶æ€æœºè®¾è®¡**ï¼šæ¸…æ™°çš„çŠ¶æ€è½¬æ¢
- **å¢é‡è§£æ**ï¼šè¾¹æ¥æ”¶è¾¹å¤„ç†
- **åŒå±‚å¾ªç¯**ï¼šå¤–å±‚æ¥æ”¶æµï¼Œå†…å±‚å¤„ç†ç¼“å†²åŒº
- **å°¾éƒ¨ä¿ç•™**ï¼šé˜²æ­¢æ ‡ç­¾æˆªæ–­
- **ç»­å†™æœºåˆ¶**ï¼šè‡ªåŠ¨å¤„ç†è¾“å‡ºæˆªæ–­

### 5. å·¥å…·ç³»ç»Ÿå®Œå–„

- **æ³¨å†Œè¡¨æ¨¡å¼**ï¼šé›†ä¸­ç®¡ç†ï¼ŒåŠ¨æ€æ‰©å±•
- **Resolver æ¨¡å¼**ï¼šèŒè´£å•ä¸€ï¼Œæ˜“äºæµ‹è¯•
- **35+ å·¥å…·**ï¼šè¦†ç›–å„ç§åœºæ™¯
- **ç±»å‹å®‰å…¨**ï¼šPydantic æ¨¡å‹
- **æ’ä»¶ç³»ç»Ÿ**ï¼šå‰åç½®é’©å­

### 6. äº‹ä»¶é©±åŠ¨æ¶æ„

- **20+ äº‹ä»¶ç±»å‹**ï¼šè¦†ç›–æ‰€æœ‰äº¤äº’
- **16ä¸ªå›è°ƒç‚¹**ï¼šçµæ´»æ‰©å±•
- **è§£è€¦è®¾è®¡**ï¼šä¸šåŠ¡é€»è¾‘ä¸æ‰©å±•åˆ†ç¦»
- **å®æ—¶åé¦ˆ**ï¼šæµå¼äº‹ä»¶ç”Ÿæˆ

### 7. æ€§èƒ½ä¼˜åŒ–å…¨é¢

- **å¤šçº§ç¼“å­˜**ï¼šå·¥å…·æ ‡ç­¾ã€æ¨¡å‹ä¿¡æ¯
- **å¹¶è¡Œæ‰§è¡Œ**ï¼šçº¿ç¨‹æ± ã€å¹¶å‘å·¥å…·
- **Token ç»Ÿè®¡**ï¼šæˆæœ¬è¿½è¸ªã€ä¼˜åŒ–å»ºè®®
- **åå°ä»»åŠ¡**ï¼šå¼‚æ­¥æ‰§è¡Œã€é€šçŸ¥æœºåˆ¶

### 8. å·¥ç¨‹å®è·µå®Œå–„

- **çº¿ç¨‹å®‰å…¨**ï¼šé”ã€RLockã€çº¿ç¨‹æ± 
- **é”™è¯¯å¤„ç†**ï¼šé‡è¯•ã€é™çº§ã€éš”ç¦»
- **æ—¥å¿—ç³»ç»Ÿ**ï¼šç»“æ„åŒ–ã€åˆ†çº§
- **é…ç½®ç®¡ç†**ï¼šçµæ´»ã€å¯æ‰©å±•
- **æµ‹è¯•å‹å¥½**ï¼šä¾èµ–æ³¨å…¥ã€Mock

## è®¾è®¡æ¨¡å¼è¯†åˆ«

### ä½¿ç”¨çš„è®¾è®¡æ¨¡å¼

1. **å•ä¾‹æ¨¡å¼** (Singleton)
   - ConversationManager
   - AgentHub / GroupHub
   - å…¨å±€å›è°ƒç®¡ç†å™¨

2. **å·¥å‚æ¨¡å¼** (Factory)
   - ToolRegistry
   - Resolver åˆ›å»º

3. **ç­–ç•¥æ¨¡å¼** (Strategy)
   - å‰ªè£ç­–ç•¥
   - ä»£ç ç”Ÿæˆç­–ç•¥

4. **è§‚å¯Ÿè€…æ¨¡å¼** (Observer)
   - äº‹ä»¶ç³»ç»Ÿ
   - å›è°ƒç³»ç»Ÿ

5. **è£…é¥°å™¨æ¨¡å¼** (Decorator)
   - @byzerllm.prompt()

6. **çŠ¶æ€æ¨¡å¼** (State)
   - æµå¼è§£æçŠ¶æ€æœº

7. **æ¨¡æ¿æ–¹æ³•æ¨¡å¼** (Template Method)
   - BaseToolResolver

8. **ä»£ç†æ¨¡å¼** (Proxy)
   - ToolCaller

9. **æ³¨å†Œè¡¨æ¨¡å¼** (Registry)
   - ToolRegistry

10. **ç»„åˆæ¨¡å¼** (Composition)
    - AgenticEdit ç»„åˆå¤šä¸ªç»„ä»¶

## å…³é”®æŠ€æœ¯æ ˆ

### æ ¸å¿ƒä¾èµ–

- **byzerllm**: LLM é›†æˆï¼ˆæ”¯æŒ Ray åˆ†å¸ƒå¼ï¼‰
- **Pydantic**: æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–
- **Jinja2**: æ¨¡æ¿å¼•æ“ï¼ˆæç¤ºè¯ï¼‰
- **prompt_toolkit**: ç»ˆç«¯ UI
- **loguru**: æ—¥å¿—ç³»ç»Ÿ
- **fastapi**: Web æœåŠ¡ï¼ˆRAG/MCPï¼‰

### Python ç‰¹æ€§ä½¿ç”¨

- Type hintsï¼ˆç±»å‹æç¤ºï¼‰
- Dataclass å’Œ Pydantic
- Generatorï¼ˆç”Ÿæˆå™¨ï¼‰
- Context Managerï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰
- Threadingï¼ˆå¤šçº¿ç¨‹ï¼‰
- ABCï¼ˆæŠ½è±¡åŸºç±»ï¼‰
- Enumï¼ˆæšä¸¾ï¼‰
- ClassVarï¼ˆç±»å˜é‡ï¼‰

## å¾…æ·±å…¥ç ”ç©¶çš„é¢†åŸŸ

1. **MCP (Model Context Protocol) é›†æˆç»†èŠ‚**
2. **RAG ç³»ç»Ÿå®ç°ç»†èŠ‚**
3. **Sub Agent åè°ƒæœºåˆ¶**
4. **AC Mod æ¨¡å—ç³»ç»Ÿ**
5. **æµ‹è¯•æ¡†æ¶å’Œç­–ç•¥**
6. **æ€§èƒ½åŸºå‡†æµ‹è¯•**
7. **å¤šæ¨¡æ€æ”¯æŒï¼ˆVisionï¼‰**

## å‚è€ƒæ–‡çŒ®å’Œèµ„æº

### ä»£ç æ–‡ä»¶æ¸…å•

**æ ¸å¿ƒæ–‡ä»¶**ï¼š
- `autocoder/agent/base_agentic/base_agent.py` (1841è¡Œ)
- `autocoder/common/v2/agent/agentic_edit.py` (3000+è¡Œ)
- `autocoder/common/pruner/agentic_conversation_pruner.py` (å‰ªè£å™¨)
- `autocoder/agent/base_agentic/tool_registry.py` (437è¡Œ)
- `autocoder/common/v2/agent/agentic_edit_types.py` (å·¥å…·å®šä¹‰)
- `autocoder/common/v2/agent/agentic_callbacks.py` (271è¡Œ)
- `autocoder/common/conversations/get_conversation_manager.py` (242è¡Œ)
- `autocoder/agent/base_agentic/agent_hub.py` (169è¡Œ)
- `autocoder/common/utils_code_auto_generate.py` (ç»­å†™æœºåˆ¶)

**å·¥å…·ç›¸å…³**ï¼š
- `autocoder/agent/base_agentic/default_tools.py` (å·¥å…·æ³¨å†Œ)
- `autocoder/common/v2/agent/agentic_edit_tools/base_tool_resolver.py`
- `autocoder/common/v2/agent/tool_caller/tool_caller.py`

### ç›¸å…³æ¨¡å¼å’Œæ¶æ„

- Event-Driven Architecture (EDA)
- Plugin Architecture
- Registry Pattern
- Resolver Pattern
- State Machine Pattern

---

**ç ”ç©¶çŠ¶æ€**: âœ… åˆæ­¥ç ”ç©¶å®Œæˆ
**ä¸‹ä¸€æ­¥**: ç¼–å†™è¯¦ç»†çš„æŠ€æœ¯æŠ¥å‘Šæ–‡æ¡£
**é¢„è®¡é¡µæ•°**: 200+ é¡µ


---

# Autocoder Agentic Agent èŒƒå¼ç ”ç©¶ç»¼åˆæŠ¥å‘Š - é˜¶æ®µä¸€

**ç¼–å†™æ—¶é—´**: 2025-01-XX
**æŠ¥å‘Šç‰ˆæœ¬**: v1.0
**ç ”ç©¶é˜¶æ®µ**: é˜¶æ®µä¸€ï¼ˆåŸºç¡€éƒ¨åˆ†ï¼‰
**çŠ¶æ€**: ğŸ”„ è¿›è¡Œä¸­

## é˜¶æ®µç›®æ ‡

æœ¬é˜¶æ®µæ·±å…¥ç ”ç©¶ Autocoder Agentic Agent èŒƒå¼çš„ä¸‰ä¸ªæ ¸å¿ƒåŸºç¡€éƒ¨åˆ†ï¼š
1. æ•´ä½“æ¶æ„è®¾è®¡ï¼ˆåŒå±‚æ¶æ„ + æ ¸å¿ƒç»„ä»¶ï¼‰
2. æç¤ºè¯å·¥ç¨‹ï¼ˆè£…é¥°å™¨æœºåˆ¶ + ç»“æ„åŒ–æç¤ºè¯ï¼‰
3. ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆå¤šå±‚æ¬¡æ„å»º + Message ID + å¯¹è¯æŒä¹…åŒ–ï¼‰

---

# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•´ä½“æ¶æ„è®¾è®¡è¯¦è§£

## 1.1 åŒå±‚æ¶æ„ä½“ç³»

### 1.1.1 æ¶æ„æ¦‚è¿°

Autocoder é‡‡ç”¨äº†ä¸€ç§åˆ›æ–°çš„åŒå±‚æ¶æ„è®¾è®¡ï¼Œå°† Agent åŠŸèƒ½åˆ†ä¸ºä¸¤ä¸ªæ¸…æ™°çš„å±‚æ¬¡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AgenticEdit å±‚                        â”‚
â”‚  (é«˜çº§ç¼–è¾‘åŠŸèƒ½ + å¯¹è¯ç®¡ç† + ä¸Šä¸‹æ–‡å‰ªè£)                    â”‚
â”‚                         â†“                                â”‚
â”‚                   BaseAgent å±‚                           â”‚
â”‚  (åŸºç¡€ Agent èƒ½åŠ› + å·¥å…·ç³»ç»Ÿ + äº‹ä»¶ç³»ç»Ÿ)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®¾è®¡åŸç†**ï¼š
- **èŒè´£åˆ†ç¦»**ï¼šBaseAgent æä¾›åŸºç¡€èƒ½åŠ›ï¼ŒAgenticEdit æä¾›é«˜çº§åŠŸèƒ½
- **ç»„åˆæ¨¡å¼**ï¼šä¸¤å±‚éƒ½å¤§é‡ä½¿ç”¨ç»„åˆè€Œéç»§æ‰¿
- **å¯æ‰©å±•æ€§**ï¼šæ¯å±‚éƒ½å¯ä»¥ç‹¬ç«‹æ‰©å±•å’Œæ›¿æ¢

### 1.1.2 BaseAgent åŸºç¡€å±‚è¯¦è§£

**æ–‡ä»¶ä½ç½®**ï¼š`autocoder/agent/base_agentic/base_agent.py` (1841è¡Œ)

**æ ¸å¿ƒèŒè´£**ï¼š
1. å·¥å…·æ³¨å†Œå’Œç®¡ç†
2. æµå¼å“åº”è§£æ
3. äº‹ä»¶ç”Ÿæˆå’Œåˆ†å‘
4. åŸºç¡€å¯¹è¯å¾ªç¯

**ç±»ç»“æ„**ï¼š

```python
class BaseAgent(ABC):
    """
    åŸºç¡€ä»£ç†ç±»ï¼Œæ‰€æœ‰çš„ä»£ç†å®ç°éƒ½åº”ç»§æ‰¿æ­¤ç±»
    éµå¾ªåˆå§‹åŒ–é¡ºåºè§„åˆ™ï¼Œé¿å…FileMonitorã€tokenè®¡æ•°å™¨ç­‰ç»„ä»¶å†²çª
    """
    
    def __init__(
        self,
        name:str,
        llm: Union[byzerllm.ByzerLLM, byzerllm.SimpleByzerLLM],
        files: SourceCodeList,
        args: AutoCoderArgs,
        conversation_history: Optional[List[Dict[str, Any]]] = None,
        default_tools_list: Optional[List[str]] = None,
        custom_system_prompt: Optional[str] = None,
        conversation_config: Optional['AgenticEditConversationConfig'] = None,
        cancel_token: Optional[str] = None
    ):
        # åˆå§‹åŒ–é¡ºåºå¾ˆé‡è¦
        # 1. FileMonitorï¼ˆå¿…é¡»æœ€å…ˆï¼‰
        # 2. è§„åˆ™æ–‡ä»¶åŠ è½½
        # 3. Tokenizer åŠ è½½
        # 4. åŸºæœ¬ç»„ä»¶åˆå§‹åŒ–
        # 5. å…¶ä»–ç»„ä»¶åˆå§‹åŒ–
```

**å…³é”®æ–¹æ³•**ï¼š

1. **agentic_run()** - æ ¸å¿ƒå¯¹è¯å¾ªç¯
```python
def agentic_run(self, request: AgentRequest) -> Generator:
    """
    ä¸»è¦æµç¨‹ï¼š
    1. ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
    2. æ„å»ºå¯¹è¯å†å²
    3. è¿›å…¥è¿­ä»£å¾ªç¯
    4. æµå¼è§£æLLMå“åº”
    5. æ‰§è¡Œå·¥å…·è°ƒç”¨
    6. ç”Ÿæˆäº‹ä»¶æµ
    """
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = self._system.prompt(request)
    
    # å¯¹è¯åˆå§‹åŒ–
    conversations = [
        {"role": "system", "content": system_prompt},
    ]
    
    # ä¸»å¾ªç¯
    while iteration_count <= max_iterations:
        # LLM è¯·æ±‚
        llm_response_gen = stream_chat_with_continue(
            llm=self.llm,
            conversations=conversations,
            llm_config={},
            args=self.args
        )
        
        # æµå¼è§£æ
        parsed_events = self.stream_and_parse_llm_response(llm_response_gen)
        
        # å¤„ç†äº‹ä»¶
        for event in parsed_events:
            if isinstance(event, ToolCallEvent):
                # æ‰§è¡Œå·¥å…·
                tool_result = resolver.resolve()
                yield ToolResultEvent(tool_name=..., result=tool_result)
            elif isinstance(event, CompletionEvent):
                # ä»»åŠ¡å®Œæˆ
                yield event
                break
```

2. **stream_and_parse_llm_response()** - æµå¼å“åº”è§£æ
```python
def stream_and_parse_llm_response(
    self, generator: Generator
) -> Generator[Union[LLMOutputEvent, ToolCallEvent, ...], None, None]:
    """
    ä½¿ç”¨çŠ¶æ€æœºè¿›è¡Œå¢é‡è§£æ
    
    çŠ¶æ€ï¼š
    - æ™®é€šæ–‡æœ¬
    - thinking å—
    - tool è°ƒç”¨å—
    """
    buffer = ""
    in_tool_block = False
    in_thinking_block = False
    
    for content_chunk, metadata in generator:
        buffer += content_chunk
        
        # å†…å±‚å¾ªç¯å¤„ç†ç¼“å†²åŒº
        while True:
            if in_thinking_block:
                # å¤„ç† thinking å—
                end_pos = buffer.find("</thinking>")
                if end_pos != -1:
                    yield LLMThinkingEvent(text=buffer[:end_pos])
                    buffer = buffer[end_pos + len("</thinking>"):]
                    in_thinking_block = False
                    continue
            elif in_tool_block:
                # å¤„ç†å·¥å…·è°ƒç”¨
                # ... ç±»ä¼¼é€»è¾‘
            else:
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæ ‡ç­¾
                # ...
```

### 1.1.3 AgenticEdit é«˜çº§å±‚è¯¦è§£

**æ–‡ä»¶ä½ç½®**ï¼š`autocoder/common/v2/agent/agentic_edit.py` (3000+è¡Œ)

**æ ¸å¿ƒèŒè´£**ï¼š
1. å¯¹è¯ç®¡ç†å’ŒæŒä¹…åŒ–
2. ä¸Šä¸‹æ–‡å‰ªè£
3. å˜æ›´è¿½è¸ª
4. é«˜çº§å·¥å…·é›†æˆ

**ç»„åˆçš„æ ¸å¿ƒç»„ä»¶**ï¼š

```python
class AgenticEdit:
    def __init__(
        self,
        llm: Union[byzerllm.ByzerLLM, byzerllm.SimpleByzerLLM],
        args: AutoCoderArgs,
        custom_system_prompt: Optional[str] = None,
        conversation_config: Optional[AgenticEditConversationConfig] = None,
        cancel_token: Optional[str] = None,
    ):
        # 1. å›è°ƒç³»ç»Ÿ
        self.callbacks = AgenticCallBacks()
        
        # 2. LLM
        self.llm = llm
        self.context_prune_llm = get_single_llm(...)
        
        # 3. å¯¹è¯ç®¡ç†å™¨
        self.conversation_manager = get_conversation_manager()
        
        # 4. ä¸Šä¸‹æ–‡å‰ªè£å™¨
        self.conversation_pruner = AgenticConversationPruner(
            args=args,
            llm=self.context_prune_llm,
            conversation_id=self.conversation_config.conversation_id
        )
        
        # 5. å˜æ›´ç®¡ç†å™¨
        self.change_manager = AgenticEditChangeManager()
        
        # 6. å·¥å…·è°ƒç”¨å™¨
        self.tool_caller = ToolCaller(
            agent=self,
            args=args
        )
        
        # 7. RAG ç®¡ç†å™¨
        self.rag_manager = RAGManager(args)
```

**analyze() æ–¹æ³• - æ ¸å¿ƒæµç¨‹**ï¼š

è¿™æ˜¯ AgenticEdit çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå®ç°äº†å®Œæ•´çš„ Agentic å·¥ä½œæµï¼š

```python
def analyze(
    self, request: AgenticEditRequest
) -> Generator[Union[LLMOutputEvent, ToolCallEvent, ...], None, None]:
    """
    å®Œæ•´çš„ agentic å·¥ä½œæµç¨‹ï¼š
    
    1. æ„å»ºç³»ç»Ÿæç¤ºè¯
    2. æ³¨å…¥æ–‡æ¡£å±‚ï¼ˆç¬¬ä¸‰æ–¹åº“æ–‡æ¡£ã€å·¥å…·ä¿¡æ¯ã€ç”¨æˆ·è§„åˆ™ï¼‰
    3. æ¢å¤å¯¹è¯å†å²
    4. è¿½åŠ å½“å‰è¯·æ±‚
    5. åº”ç”¨ä¸Šä¸‹æ–‡å‰ªè£
    6. æµå¼ç”Ÿæˆå’Œè§£æ
    7. æ‰§è¡Œå·¥å…·è°ƒç”¨
    8. æŒä¹…åŒ–å¯¹è¯
    """
    
    # æ­¥éª¤1ï¼šç”Ÿæˆç³»ç»Ÿæç¤ºè¯
    system_prompt = self._analyze.prompt(request)
    
    # æ­¥éª¤2ï¼šåˆå§‹åŒ–å¯¹è¯
    conversations = [
        {"role": "system", "content": system_prompt},
    ]
    
    # æ­¥éª¤3ï¼šæ³¨å…¥æ–‡æ¡£å±‚ï¼ˆé¢„è½®æ¬¡å¯¹è¯ï¼‰
    # 3.1 ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£
    if added_libraries:
        library_docs_prompt = self.generate_library_docs_prompt.prompt(...)
        conversations.append({"role": "user", "content": library_docs_prompt})
        conversations.append({
            "role": "assistant", 
            "content": "I have read and understood the third-party library documentation..."
        })
    
    # 3.2 å·¥å…·ä½¿ç”¨ä¿¡æ¯
    if tools_prompt:
        conversations.append({"role": "user", "content": tools_prompt})
        conversations.append({
            "role": "assistant",
            "content": "æˆ‘å·²ç»äº†è§£äº†å½“å‰é¡¹ç›®ä¸­å¯ç”¨çš„å·¥å…·å‘½ä»¤..."
        })
    
    # 3.3 ç”¨æˆ·è§„åˆ™
    if rules_text:
        conversations.append({"role": "user", "content": rules_text})
        conversations.append({
            "role": "assistant",
            "content": "I have read and understood the rules structure..."
        })
    
    # æ­¥éª¤4ï¼šæ¢å¤å¯¹è¯å†å²ï¼ˆå¸¦ Message IDï¼‰
    if current_conversation and current_conversation.get("messages"):
        for message in current_conversation["messages"]:
            conversations.append({
                "role": message["role"],
                "content": append_hint_to_text(
                    message["content"],
                    f"message_id: {message['message_id'][0:8]}"
                )
            })
    
    # æ­¥éª¤5ï¼šè¿½åŠ å½“å‰è¯·æ±‚
    conversations.append({"role": "user", "content": request.user_input})
    
    # æŒä¹…åŒ–ç”¨æˆ·æ¶ˆæ¯
    self.conversation_manager.append_message(
        conversation_id=self.conversation_config.conversation_id,
        role="user",
        content=request.user_input,
        metadata={},
    )
    
    # æ­¥éª¤6ï¼šä¸»å¾ªç¯ï¼ˆå·¥å…·æ‰§è¡Œå¾ªç¯ï¼‰
    iteration_count = 0
    while iteration_count <= max_iterations:
        iteration_count += 1
        
        # 6.1 åº”ç”¨ä¸Šä¸‹æ–‡å‰ªè£
        pruned_conversations = self.conversation_pruner.prune_conversations(
            conversations
        )
        
        # 6.2 æµå¼ç”Ÿæˆ
        llm_response_gen = stream_chat_with_continue(
            llm=self.llm,
            conversations=pruned_conversations,
            llm_config={},
            args=self.args
        )
        
        # 6.3 æµå¼è§£æ
        parsed_events = self.stream_and_parse_llm_response(llm_response_gen)
        
        # 6.4 å¤„ç†äº‹ä»¶
        for event in parsed_events:
            if isinstance(event, ToolCallEvent):
                # å·¥å…·æ‰§è¡Œ
                tool_obj = event.tool
                resolver = self.tool_caller.call_tool(tool_obj)
                tool_result = resolver.resolve()
                
                # è¿½åŠ åˆ°å¯¹è¯å†å²
                conversations.append({
                    "role": "assistant",
                    "content": assistant_buffer + event.tool_xml
                })
                conversations.append({
                    "role": "user",
                    "content": tool_result_xml
                })
                
                # æŒä¹…åŒ–
                self.conversation_manager.append_message(...)
                
                yield ToolResultEvent(...)
            
            elif isinstance(event, CompletionEvent):
                # ä»»åŠ¡å®Œæˆ
                yield event
                break
```

### 1.1.4 ä¸¤å±‚æ¶æ„çš„è®¾è®¡ä¼˜åŠ¿

**1. èŒè´£åˆ†ç¦»ï¼ˆSeparation of Concernsï¼‰**

- **BaseAgent**ï¼šä¸“æ³¨äºåŸºç¡€çš„ LLM äº¤äº’ã€å·¥å…·æ‰§è¡Œã€äº‹ä»¶ç”Ÿæˆ
- **AgenticEdit**ï¼šä¸“æ³¨äºå¯¹è¯ç®¡ç†ã€ä¸Šä¸‹æ–‡ä¼˜åŒ–ã€å˜æ›´è¿½è¸ª

**2. å¯å¤ç”¨æ€§ï¼ˆReusabilityï¼‰**

- BaseAgent å¯ä»¥è¢«å…¶ä»–ç±»å‹çš„ Agent ç»§æ‰¿
- AgenticEdit çš„ç»„ä»¶å¯ä»¥å•ç‹¬ä½¿ç”¨

**3. å¯æµ‹è¯•æ€§ï¼ˆTestabilityï¼‰**

- æ¯å±‚éƒ½æœ‰æ¸…æ™°çš„æ¥å£
- å¯ä»¥ç‹¬ç«‹è¿›è¡Œå•å…ƒæµ‹è¯•

**4. å¯æ‰©å±•æ€§ï¼ˆExtensibilityï¼‰**

- å¯ä»¥è½»æ¾æ·»åŠ æ–°çš„å·¥å…·
- å¯ä»¥æ›¿æ¢æˆ–æ‰©å±•å‰ªè£ç­–ç•¥
- å¯ä»¥è‡ªå®šä¹‰å›è°ƒå’Œäº‹ä»¶å¤„ç†

## 1.2 æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1.2.1 LLM é›†æˆï¼ˆbyzerllmï¼‰

**èŒè´£**ï¼šç»Ÿä¸€çš„ LLM è®¿é—®æ¥å£

**ä¸¤ç§æ¨¡å¼**ï¼š

1. **ByzerLLM**ï¼ˆpro æ¨¡å¼ï¼‰
   - åŸºäº Ray çš„åˆ†å¸ƒå¼ LLM æœåŠ¡
   - æ”¯æŒå¤šæ¨¡å‹å¹¶å‘
   - é€‚åˆå¤§è§„æ¨¡éƒ¨ç½²

2. **SimpleByzerLLM**ï¼ˆlite æ¨¡å¼ï¼‰
   - ç›´æ¥ API è°ƒç”¨
   - è½»é‡çº§ï¼Œæ— éœ€ Ray é›†ç¾¤
   - é€‚åˆå•æœºä½¿ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼š

```python
# æµå¼èŠå¤©
def stream_chat_oai(
    self,
    conversations: List[Dict[str, str]],
    llm_config: Dict[str, Any] = {}
) -> Generator[Tuple[str, Any], None, None]:
    """
    æµå¼ç”Ÿæˆå“åº”
    
    Returns:
        Generator yielding (content_chunk, metadata)
    """
    pass

# éæµå¼èŠå¤©
def chat_oai(
    self,
    conversations: List[Dict[str, str]],
    llm_config: Dict[str, Any] = {}
) -> Tuple[str, Any]:
    """
    ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´å“åº”
    
    Returns:
        (full_response, metadata)
    """
    pass
```

**LLMManager** - å¤šæ¨¡å‹ç®¡ç†ï¼š

```python
class LLMManager:
    """
    ç®¡ç†å¤šä¸ª LLM å®ä¾‹
    
    æ”¯æŒçš„æ¨¡å‹ç±»å‹ï¼š
    - model: ä¸»æ¨¡å‹
    - code_model: ä»£ç ç”Ÿæˆæ¨¡å‹ï¼ˆå¯ä»¥æ˜¯é€—å·åˆ†éš”çš„åˆ—è¡¨ï¼‰
    - chat_model: èŠå¤©æ¨¡å‹
    - index_model: ç´¢å¼•æ¨¡å‹
    - emb_model: åµŒå…¥æ¨¡å‹
    - vl_model: è§†è§‰-è¯­è¨€æ¨¡å‹
    - planner_model, designer_model, commit_model: ä¸“ç”¨æ¨¡å‹
    """
    
    def get_llm(self, model_name: str) -> Union[ByzerLLM, SimpleByzerLLM]:
        """è·å–æŒ‡å®šæ¨¡å‹çš„ LLM å®ä¾‹"""
        pass
```

### 1.2.2 ToolCaller å·¥å…·è°ƒç”¨å™¨

**èŒè´£**ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶ç®¡ç†æ’ä»¶ç³»ç»Ÿ

**æ–‡ä»¶ä½ç½®**ï¼š`autocoder/common/v2/agent/tool_caller/tool_caller.py`

**æ ¸å¿ƒæµç¨‹**ï¼š

```python
class ToolCaller:
    def __init__(self, agent: AgenticEdit, args: AutoCoderArgs):
        self.agent = agent
        self.args = args
        self.plugin_manager = ToolPluginManager()
        self.stats = ToolCallerStats()
    
    def call_tool(
        self, 
        tool: BaseTool
    ) -> ToolResult:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ŒåŒ…å«æ’ä»¶é’©å­
        
        æµç¨‹ï¼š
        1. æ‰§è¡Œ before_tool_call é’©å­
        2. æ‰§è¡Œå·¥å…·
        3. æ‰§è¡Œ after_tool_call é’©å­
        4. é”™è¯¯å¤„ç†
        """
        tool_name = type(tool).__name__
        
        try:
            # 1. å‰ç½®é’©å­
            if self.plugin_manager.plugins_enabled:
                for plugin in self.plugin_manager.active_plugins:
                    plugin.before_tool_call(tool, self.agent)
            
            # 2. æ‰§è¡Œå·¥å…·
            resolver_cls = ToolRegistry.get_resolver_for_tool(tool)
            if not resolver_cls:
                raise ValueError(f"No resolver for tool {tool_name}")
            
            resolver = resolver_cls(agent=self.agent, tool=tool, args=self.args)
            tool_result = resolver.resolve()
            
            # 3. åç½®é’©å­
            if self.plugin_manager.plugins_enabled:
                for plugin in self.plugin_manager.active_plugins:
                    plugin.after_tool_call(tool, tool_result, self.agent)
            
            # 4. æ›´æ–°ç»Ÿè®¡
            self.stats.record_call(tool_name, tool_result.success)
            
            return tool_result
            
        except Exception as e:
            # é”™è¯¯é’©å­
            if self.plugin_manager.plugins_enabled:
                for plugin in self.plugin_manager.active_plugins:
                    plugin.on_tool_error(tool, e, self.agent)
            
            return ToolResult(
                success=False,
                message=f"Error executing tool: {str(e)}",
                content=None
            )
```

**æ’ä»¶ç³»ç»Ÿ**ï¼š

```python
class ToolPlugin(ABC):
    """å·¥å…·æ’ä»¶åŸºç±»"""
    
    @abstractmethod
    def before_tool_call(self, tool: BaseTool, agent: AgenticEdit):
        """å·¥å…·è°ƒç”¨å‰é’©å­"""
        pass
    
    @abstractmethod
    def after_tool_call(self, tool: BaseTool, result: ToolResult, agent: AgenticEdit):
        """å·¥å…·è°ƒç”¨åé’©å­"""
        pass
    
    @abstractmethod
    def on_tool_error(self, tool: BaseTool, error: Exception, agent: AgenticEdit):
        """å·¥å…·è°ƒç”¨å‡ºé”™é’©å­"""
        pass
```

### 1.2.3 AgenticConversationPruner ä¸Šä¸‹æ–‡å‰ªè£å™¨

**èŒè´£**ï¼šæ™ºèƒ½å‹ç¼©å¯¹è¯å†å²ï¼Œä¿æŒåœ¨ Token é™åˆ¶å†…

**æ–‡ä»¶ä½ç½®**ï¼š`autocoder/common/pruner/agentic_conversation_pruner.py`

**ä¸¤é˜¶æ®µå‰ªè£ç­–ç•¥**ï¼š

```python
class AgenticConversationPruner:
    def prune_conversations(
        self, 
        conversations: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ä¸¤é˜¶æ®µå‰ªè£ï¼š
        1. Message IDs Pruningï¼ˆç²¾ç¡®åˆ é™¤ï¼‰
        2. Tool Cleanup Pruningï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰
        """
        safe_zone_tokens = self._get_parsed_safe_zone_tokens()
        original_length = len(conversations)
        
        # é˜¶æ®µ1ï¼šç²¾ç¡®åˆ é™¤ï¼ˆåŸºäº Message IDsï¼‰
        processed_conversations = self._apply_message_ids_pruning(conversations)
        
        # è®¡ç®—å½“å‰ token æ•°
        current_tokens = count_tokens(
            json.dumps(processed_conversations, ensure_ascii=False)
        )
        
        # é˜¶æ®µ2ï¼šæ™ºèƒ½å‹ç¼©ï¼ˆå¦‚æœè¿˜éœ€è¦ï¼‰
        if current_tokens > safe_zone_tokens:
            processed_conversations = self._unified_tool_cleanup_prune(
                processed_conversations,
                {"safe_zone_tokens": safe_zone_tokens}
            )
        
        return processed_conversations
```

**é˜¶æ®µ1ï¼šMessage IDs Pruning**

LLM å¯ä»¥ä¸»åŠ¨æ ‡è®°è¦åˆ é™¤çš„æ¶ˆæ¯ï¼š

```python
def _apply_message_ids_pruning(
    self, 
    conversations: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    åŸºäºæ¶ˆæ¯ ID çš„ç²¾ç¡®åˆ é™¤
    
    å·¥ä½œæµç¨‹ï¼š
    1. è·å–è¦åˆ é™¤çš„æ¶ˆæ¯ ID åˆ—è¡¨ï¼ˆæ¥è‡ª conversation_message_idsï¼‰
    2. ä»å¯¹è¯ä¸­æå–æ¯æ¡æ¶ˆæ¯çš„ ID
    3. è¿‡æ»¤æ‰åŒ¹é…çš„æ¶ˆæ¯
    """
    conversation_id = self._get_current_conversation_id()
    conversation_message_ids = self.message_ids_api.get_conversation_message_ids(
        conversation_id
    )
    
    if not conversation_message_ids:
        return conversations
    
    # ä½¿ç”¨ ConversationMessageIdsPruner æ‰§è¡Œå‰ªè£
    pruning_result = self.message_ids_pruner.prune_conversations(
        conversations, conversation_message_ids
    )
    
    if pruning_result.success:
        logger.info(
            f"Message IDs pruning: {pruning_result.original_length} -> "
            f"{pruning_result.pruned_length} messages"
        )
        return pruning_result.pruned_conversations
    else:
        logger.error(f"Message IDs pruning failed: {pruning_result.error_message}")
        return conversations
```

**é˜¶æ®µ2ï¼šTool Cleanup Pruning**

æ™ºèƒ½å‹ç¼©å·¥å…·è°ƒç”¨å’Œç»“æœï¼š

```python
def _unified_tool_cleanup_prune(
    self, 
    conversations: List[Dict[str, Any]],
    config: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """
    ç»Ÿä¸€çš„å·¥å…·æ¸…ç†å‰ªè£
    
    ç­–ç•¥ï¼š
    1. è¯†åˆ«æ‰€æœ‰å¯æ¸…ç†çš„æ¶ˆæ¯ï¼ˆå·¥å…·ç»“æœå’Œå·¥å…·è°ƒç”¨ï¼‰
    2. æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆå·¥å…·ç»“æœä¼˜å…ˆï¼‰
    3. é€ä¸ªæ¸…ç†ï¼Œç›´åˆ°æ»¡è¶³æ¡ä»¶ï¼š
       - Token æ•°åœ¨å®‰å…¨åŒºå†…
       - æˆ–å‰©ä½™æœªè£å‰ªæ¶ˆæ¯å°‘äº6æ¡
    """
    safe_zone_tokens = config["safe_zone_tokens"]
    processed_conversations = copy.deepcopy(conversations)
    
    # 1. è¯†åˆ«å¯æ¸…ç†çš„æ¶ˆæ¯
    cleanable_messages = []
    for i, conv in enumerate(processed_conversations):
        content = conv.get("content", "")
        role = conv.get("role")
        
        # å·¥å…·ç»“æœæ¶ˆæ¯
        if role == "user" and self._is_tool_result_message(content):
            cleanable_messages.append({"index": i, "type": "tool_result"})
        
        # å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆassistant è§’è‰²ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨ï¼‰
        elif role == "assistant" and self.tool_content_detector.is_tool_call_content(content):
            cleanable_messages.append({"index": i, "type": "tool_call"})
    
    # 2. æ’åºï¼šå·¥å…·ç»“æœä¼˜å…ˆ
    cleanable_messages.sort(
        key=lambda x: (x["index"], x["type"] != "tool_result")
    )
    
    # 3. é€ä¸ªæ¸…ç†
    cleaned_count = 0
    for i, message_info in enumerate(cleanable_messages):
        # æ£€æŸ¥ token æ•°
        current_tokens = count_tokens(
            json.dumps(processed_conversations, ensure_ascii=False)
        )
        if current_tokens <= safe_zone_tokens:
            break
        
        # æ£€æŸ¥å‰©ä½™æ¶ˆæ¯æ•°
        remaining_unpruned = len(cleanable_messages) - (i + 1)
        if remaining_unpruned < 6:
            break
        
        # æ¸…ç†æ¶ˆæ¯
        msg_index = message_info["index"]
        msg_type = message_info["type"]
        
        if msg_type == "tool_result":
            # æ›¿æ¢å·¥å…·ç»“æœ
            tool_name = self._extract_tool_name(original_content)
            replacement = self._generate_replacement_message(tool_name)
            processed_conversations[msg_index]["content"] = replacement
            cleaned_count += 1
        
        elif msg_type == "tool_call":
            # æˆªæ–­å·¥å…·è°ƒç”¨çš„å¤§å‚æ•°
            new_content, replaced = self.tool_content_detector.replace_tool_content(
                original_content, max_content_length=500
            )
            if replaced:
                processed_conversations[msg_index]["content"] = new_content
                cleaned_count += 1
    
    return processed_conversations
```

### 1.2.4 ConversationManager å¯¹è¯ç®¡ç†å™¨

**èŒè´£**ï¼šå¯¹è¯çš„æŒä¹…åŒ–ã€æ¢å¤å’Œç®¡ç†

**æ–‡ä»¶ä½ç½®**ï¼š`autocoder/common/conversations/get_conversation_manager.py`

**å•ä¾‹æ¨¡å¼å®ç°**ï¼š

```python
class ConversationManagerSingleton:
    """çº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼"""
    
    _instance: Optional[PersistConversationManager] = None
    _lock = threading.Lock()
    _config: Optional[ConversationManagerConfig] = None
    
    @classmethod
    def get_instance(cls, config=None) -> PersistConversationManager:
        if cls._instance is None:
            with cls._lock:  # åŒé‡æ£€æŸ¥é”å®š
                if cls._instance is None:
                    if config is None:
                        config = cls._get_default_config()
                    cls._instance = PersistConversationManager(config)
        return cls._instance

# ä¾¿æ·å‡½æ•°
def get_conversation_manager(config=None) -> PersistConversationManager:
    return ConversationManagerSingleton.get_instance(config)
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **åˆ›å»ºå¯¹è¯**ï¼š

```python
def create_conversation(
    self,
    name: Optional[str] = None,
    description: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
    namespace: Optional[str] = None
) -> str:
    """
    åˆ›å»ºæ–°å¯¹è¯
    
    Returns:
        å¯¹è¯ ID (UUID)
    """
    conversation_id = str(uuid.uuid4())
    conversation = {
        "id": conversation_id,
        "name": name or f"Conversation {conversation_id[:8]}",
        "description": description,
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat(),
        "metadata": metadata or {},
        "messages": []
    }
    
    # ä¿å­˜åˆ°ç£ç›˜
    self._save_conversation(conversation_id, conversation)
    
    return conversation_id
```

2. **è¿½åŠ æ¶ˆæ¯**ï¼š

```python
def append_message(
    self,
    conversation_id: str,
    role: str,
    content: str,
    metadata: Optional[Dict[str, Any]] = None,
    llm_metadata: Optional[Dict[str, Any]] = None
) -> str:
    """
    å‘å¯¹è¯è¿½åŠ æ¶ˆæ¯
    
    Returns:
        æ¶ˆæ¯ ID (UUID)
    """
    message_id = str(uuid.uuid4())
    
    message = {
        "message_id": message_id,
        "role": role,
        "content": content,
        "created_at": datetime.now().isoformat(),
        "metadata": metadata or {},
        "llm_metadata": llm_metadata
    }
    
    # åŠ è½½å¯¹è¯
    conversation = self.get_conversation(conversation_id)
    conversation["messages"].append(message)
    conversation["updated_at"] = datetime.now().isoformat()
    
    # ä¿å­˜
    self._save_conversation(conversation_id, conversation)
    
    return message_id
```

3. **æ›´æ–°æ¶ˆæ¯**ï¼ˆç”¨äºå›å†™ token ç»Ÿè®¡ï¼‰ï¼š

```python
def update_message(
    self,
    conversation_id: str,
    message_id: str,
    content: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
    llm_metadata: Optional[Dict[str, Any]] = None
) -> bool:
    """
    æ›´æ–°æ¶ˆæ¯ï¼ˆé€šå¸¸ç”¨äºå›å†™ token ç»Ÿè®¡ï¼‰
    """
    conversation = self.get_conversation(conversation_id)
    
    for message in conversation["messages"]:
        if message["message_id"] == message_id:
            if content is not None:
                message["content"] = content
            if metadata is not None:
                message["metadata"].update(metadata)
            if llm_metadata is not None:
                message["llm_metadata"] = llm_metadata
            
            conversation["updated_at"] = datetime.now().isoformat()
            self._save_conversation(conversation_id, conversation)
            return True
    
    return False
```

4. **å‘½åç©ºé—´ç®¡ç†**ï¼š

```python
def set_current_conversation(
    self,
    conversation_id: str,
    namespace: Optional[str] = None
) -> bool:
    """è®¾ç½®å½“å‰å¯¹è¯ï¼ˆæŒ‰å‘½åç©ºé—´ï¼‰"""
    namespace_key = namespace or "default"
    self._current_conversations[namespace_key] = conversation_id
    self._save_current_conversations()
    return True

def get_current_conversation_id(
    self,
    namespace: Optional[str] = None
) -> Optional[str]:
    """è·å–å½“å‰å¯¹è¯ ID"""
    namespace_key = namespace or "default"
    return self._current_conversations.get(namespace_key)
```

### 1.2.5 AgenticEditChangeManager å˜æ›´ç®¡ç†å™¨

**èŒè´£**ï¼šè¿½è¸ªæ–‡ä»¶å˜æ›´ï¼Œç”Ÿæˆ diff

**æ ¸å¿ƒæ•°æ®ç»“æ„**ï¼š

```python
class FileChangeEntry(BaseModel):
    """å•ä¸ªæ–‡ä»¶çš„å˜æ›´ä¿¡æ¯"""
    type: str  # "added" æˆ– "modified"
    diffs: List[str]  # diff åˆ—è¡¨
    content: Optional[str] = None  # æœ€æ–°æ–‡ä»¶å†…å®¹

class AgenticEditChangeManager:
    def __init__(self):
        self.file_changes: Dict[str, FileChangeEntry] = {}
    
    def record_file_change(
        self,
        file_path: str,
        change_type: str,
        diff: Optional[str] = None,
        content: Optional[str] = None
    ):
        """
        è®°å½•å•ä¸ªæ–‡ä»¶çš„å˜æ›´
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            change_type: "added" æˆ– "modified"
            diff: diff å†…å®¹ï¼ˆæ¥è‡ª replace_in_fileï¼‰
            content: æœ€æ–°æ–‡ä»¶å†…å®¹ï¼ˆæ¥è‡ª write_to_fileï¼‰
        """
        entry = self.file_changes.get(file_path)
        
        if entry is None:
            # æ–°æ–‡ä»¶
            entry = FileChangeEntry(
                type=change_type,
                diffs=[],
                content=content
            )
            self.file_changes[file_path] = entry
        else:
            # å·²å­˜åœ¨çš„æ–‡ä»¶
            # type ä¼˜å…ˆä½¿ç”¨ "added"
            if entry.type != "added":
                entry.type = change_type
            
            # content ä½¿ç”¨æœ€æ–°çš„
            if content is not None:
                entry.content = content
        
        # è¿½åŠ  diff
        if diff:
            entry.diffs.append(diff)
    
    def get_all_file_changes(self) -> Dict[str, FileChangeEntry]:
        """è·å–æ‰€æœ‰æ–‡ä»¶å˜æ›´"""
        return self.file_changes
```

### 1.2.6 ToolRegistry å·¥å…·æ³¨å†Œè¡¨

**èŒè´£**ï¼šå…¨å±€å·¥å…·æ³¨å†Œå’Œç®¡ç†

**ç±»å˜é‡è®¾è®¡**ï¼ˆç±»çº§å…±äº«ï¼‰ï¼š

```python
class ToolRegistry:
    """
    å·¥å…·æ³¨å†Œè¡¨
    
    ä½¿ç”¨ç±»å˜é‡å®ç°å…¨å±€å…±äº«çš„æ³¨å†Œè¡¨
    """
    
    # å·¥å…·å’Œè§£æå™¨çš„æ˜ å°„
    _tool_resolver_map: ClassVar[Dict[Type[BaseTool], Type[BaseToolResolver]]] = {}
    
    # æ ‡ç­¾å’Œå·¥å…·ç±»çš„æ˜ å°„
    _tag_model_map: ClassVar[Dict[str, Type[BaseTool]]] = {}
    
    # å·¥å…·æè¿°
    _tool_descriptions: ClassVar[Dict[str, ToolDescription]] = {}
    
    # å·¥å…·ç¤ºä¾‹
    _tool_examples: ClassVar[Dict[str, ToolExample]] = {}
    
    # å·¥å…·ä½¿ç”¨æŒ‡å—
    _tool_use_guidelines: ClassVar[Dict[str, str]] = {}
    
    # å·¥å…·ç”¨ä¾‹æ–‡æ¡£
    _tools_case_doc: ClassVar[Dict[str, Dict[str, object]]] = {}
    
    # é»˜è®¤å·¥å…·é›†
    _default_tools: ClassVar[Dict[str, Type[BaseTool]]] = {}
```

**æ ¸å¿ƒæ–¹æ³•**ï¼š

```python
@classmethod
def register_tool(
    cls,
    tool_tag: str,
    tool_cls: Type[BaseTool],
    resolver_cls: Type[BaseToolResolver],
    description: ToolDescription,
    example: ToolExample,
    use_guideline: str = ""
) -> None:
    """æ³¨å†Œå·¥å…·"""
    cls._tool_resolver_map[tool_cls] = resolver_cls
    cls._tag_model_map[tool_tag] = tool_cls
    cls._tool_descriptions[tool_tag] = description
    cls._tool_examples[tool_tag] = example
    
    if use_guideline:
        cls._tool_use_guidelines[tool_tag] = use_guideline
    
    logger.info(f"æ³¨å†Œå·¥å…·: {tool_tag} -> {tool_cls.__name__}")

@classmethod
def get_resolver_for_tool(
    cls, 
    tool_cls_or_instance
) -> Type[BaseToolResolver]:
    """è·å–å·¥å…·çš„è§£æå™¨ç±»"""
    if not inspect.isclass(tool_cls_or_instance):
        tool_cls = type(tool_cls_or_instance)
    else:
        tool_cls = tool_cls_or_instance
    
    return cls._tool_resolver_map.get(tool_cls)

@classmethod
def get_model_for_tag(cls, tool_tag: str) -> Type[BaseTool]:
    """æ ¹æ®æ ‡ç­¾è·å–å·¥å…·ç±»"""
    return cls._tag_model_map.get(tool_tag)

@classmethod
def unregister_tool(cls, tool_tag: str) -> bool:
    """å¸è½½å·¥å…·"""
    tool_cls = cls._tag_model_map.get(tool_tag)
    if tool_cls is None:
        return False
    
    # æ¸…é™¤æ‰€æœ‰ç›¸å…³æ•°æ®
    if tool_cls in cls._tool_resolver_map:
        del cls._tool_resolver_map[tool_cls]
    if tool_tag in cls._tag_model_map:
        del cls._tag_model_map[tool_tag]
    if tool_tag in cls._tool_descriptions:
        del cls._tool_descriptions[tool_tag]
    if tool_tag in cls._tool_examples:
        del cls._tool_examples[tool_tag]
    if tool_tag in cls._tool_use_guidelines:
        del cls._tool_use_guidelines[tool_tag]
    if tool_tag in cls._default_tools:
        del cls._default_tools[tool_tag]
    
    return True
```

### 1.2.7 EventSystem äº‹ä»¶ç³»ç»Ÿ

**èŒè´£**ï¼šäº‹ä»¶é©±åŠ¨çš„æ¶æ„ï¼Œè§£è€¦ç»„ä»¶

**äº‹ä»¶ç±»å‹å±‚æ¬¡**ï¼š

```python
# åŸºç¡€äº‹ä»¶
class LLMOutputEvent(BaseModel):
    """æ™®é€šæ–‡æœ¬è¾“å‡º"""
    text: str

class LLMThinkingEvent(BaseModel):
    """æ€è€ƒè¿‡ç¨‹"""
    text: str

class ToolCallEvent(BaseModel):
    """å·¥å…·è°ƒç”¨"""
    tool: SkipValidation[BaseTool]
    tool_xml: str

class ToolResultEvent(BaseModel):
    """å·¥å…·ç»“æœ"""
    tool_name: str
    result: ToolResult

class CompletionEvent(BaseModel):
    """ä»»åŠ¡å®Œæˆ"""
    completion: SkipValidation[AttemptCompletionTool]
    completion_xml: str

# æ§åˆ¶äº‹ä»¶
class ErrorEvent(BaseModel):
    """é”™è¯¯"""
    message: str

class RetryEvent(BaseModel):
    """é‡è¯•"""
    message: str

# å…ƒæ•°æ®äº‹ä»¶
class TokenUsageEvent(BaseModel):
    """Token ä½¿ç”¨ç»Ÿè®¡"""
    usage: Any

class WindowLengthChangeEvent(BaseModel):
    """çª—å£é•¿åº¦å˜åŒ–"""
    tokens_used: int
    pruned_tokens_used: int
    conversation_round: int

class ConversationIdEvent(BaseModel):
    """å¯¹è¯ ID"""
    conversation_id: str
```

**äº‹ä»¶æµå¤„ç†**ï¼š

åœ¨ `analyze()` æ–¹æ³•ä¸­ï¼Œæ‰€æœ‰æ“ä½œéƒ½é€šè¿‡äº‹ä»¶æµæ¥é€šä¿¡ï¼š

```python
def analyze(self, request: AgenticEditRequest) -> Generator:
    # ... åˆå§‹åŒ– ...
    
    for event in parsed_events:
        if isinstance(event, LLMOutputEvent):
            # æ™®é€šè¾“å‡ºï¼Œç›´æ¥ yield
            yield event
        
        elif isinstance(event, LLMThinkingEvent):
            # æ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥ yield
            yield event
        
        elif isinstance(event, ToolCallEvent):
            # å·¥å…·è°ƒç”¨
            tool_obj = event.tool
            
            # æ‰§è¡Œå·¥å…·
            result = self.tool_caller.call_tool(tool_obj)
            
            # yield å·¥å…·è°ƒç”¨äº‹ä»¶
            yield event
            
            # yield å·¥å…·ç»“æœäº‹ä»¶
            yield ToolResultEvent(
                tool_name=type(tool_obj).__name__,
                result=result
            )
        
        elif isinstance(event, CompletionEvent):
            # ä»»åŠ¡å®Œæˆï¼Œç»“æŸå¾ªç¯
            yield event
            break
        
        elif isinstance(event, TokenUsageEvent):
            # Token ç»Ÿè®¡ï¼Œè®°å½•å¹¶ yield
            self._record_token_usage(event.usage)
            yield event
        
        elif isinstance(event, ErrorEvent):
            # é”™è¯¯ï¼Œè®°å½•å¹¶ yield
            logger.error(f"Error: {event.message}")
            yield event
```

## 1.3 ç»„ä»¶äº¤äº’æµç¨‹å›¾

**å®Œæ•´çš„è¯·æ±‚å¤„ç†æµç¨‹**ï¼š

```
ç”¨æˆ·è¯·æ±‚
  â†“
AgenticEdit.analyze()
  â†“
1. ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ (@byzerllm.prompt)
  â†“
2. æ„å»ºå¯¹è¯å†å²ï¼ˆå¤šå±‚æ¬¡ï¼‰
  â”œâ”€ System å±‚
  â”œâ”€ Documentation å±‚ï¼ˆé¢„è½®æ¬¡ï¼‰
  â”œâ”€ History å±‚ï¼ˆä» ConversationManager æ¢å¤ï¼‰
  â””â”€ Current Request
  â†“
3. å¯¹è¯æŒä¹…åŒ–ï¼ˆConversationManagerï¼‰
  â†“
4. ä¸»å¾ªç¯å¼€å§‹
  â†“
5. åº”ç”¨ä¸Šä¸‹æ–‡å‰ªè£ï¼ˆAgenticConversationPrunerï¼‰
  â”œâ”€ Message IDs Pruning
  â””â”€ Tool Cleanup Pruning
  â†“
6. æµå¼ç”Ÿæˆï¼ˆLLMï¼‰
  â†“
7. æµå¼è§£æï¼ˆstream_and_parse_llm_responseï¼‰
  â”œâ”€ çŠ¶æ€æœºè§£æ
  â””â”€ ç”Ÿæˆäº‹ä»¶
  â†“
8. äº‹ä»¶å¤„ç†
  â”œâ”€ LLMOutputEvent â†’ ç›´æ¥ yield
  â”œâ”€ LLMThinkingEvent â†’ ç›´æ¥ yield
  â”œâ”€ ToolCallEvent â†’ æ‰§è¡Œå·¥å…· â†’ ToolResultEvent
  â””â”€ CompletionEvent â†’ ç»“æŸå¾ªç¯
  â†“
9. å·¥å…·æ‰§è¡Œï¼ˆToolCallerï¼‰
  â”œâ”€ å‰ç½®é’©å­ï¼ˆæ’ä»¶ï¼‰
  â”œâ”€ è§£æå™¨æ‰§è¡Œï¼ˆResolverï¼‰
  â””â”€ åç½®é’©å­ï¼ˆæ’ä»¶ï¼‰
  â†“
10. æŒä¹…åŒ–ç»“æœï¼ˆConversationManagerï¼‰
  â†“
11. æ£€æŸ¥å®Œæˆæ¡ä»¶
  â”œâ”€ CompletionEvent â†’ å®Œæˆ
  â”œâ”€ æœ€å¤§è½®æ¬¡ â†’ å®Œæˆ
  â””â”€ ç»§ç»­å¾ªç¯ â†’ å›åˆ°æ­¥éª¤5
```

## 1.4 æ¶æ„è®¾è®¡æ€»ç»“

### ä¼˜ç‚¹

1. **æ¸…æ™°çš„èŒè´£åˆ†ç¦»**
   - BaseAgent è´Ÿè´£åŸºç¡€åŠŸèƒ½
   - AgenticEdit è´Ÿè´£é«˜çº§åŠŸèƒ½
   - æ¯ä¸ªç»„ä»¶éƒ½æœ‰æ˜ç¡®çš„èŒè´£

2. **é«˜åº¦å¯æ‰©å±•**
   - å·¥å…·æ³¨å†Œè¡¨æ”¯æŒåŠ¨æ€æ³¨å†Œ
   - æ’ä»¶ç³»ç»Ÿæ”¯æŒé’©å­
   - å›è°ƒç³»ç»Ÿæ”¯æŒäº‹ä»¶ç›‘å¬

3. **è§£è€¦è®¾è®¡**
   - äº‹ä»¶é©±åŠ¨æ¶æ„
   - ä¾èµ–æ³¨å…¥
   - ç»„åˆä¼˜äºç»§æ‰¿

4. **å®Œå–„çš„å·¥ç¨‹å®è·µ**
   - çº¿ç¨‹å®‰å…¨ï¼ˆé”ã€å•ä¾‹ï¼‰
   - é”™è¯¯å¤„ç†ï¼ˆé‡è¯•ã€é™çº§ï¼‰
   - æ€§èƒ½ä¼˜åŒ–ï¼ˆç¼“å­˜ã€å¹¶è¡Œï¼‰

### å¯æ”¹è¿›ä¹‹å¤„

1. **å¤æ‚åº¦è¾ƒé«˜**
   - ç»„ä»¶è¾ƒå¤šï¼Œç†è§£æˆæœ¬é«˜
   - æ–°æ‰‹ä¸Šæ‰‹éœ€è¦æ—¶é—´

2. **é…ç½®è¾ƒåˆ†æ•£**
   - å¤šä¸ªç»„ä»¶æœ‰å„è‡ªçš„é…ç½®
   - ç¼ºå°‘ç»Ÿä¸€çš„é…ç½®å…¥å£

3. **æµ‹è¯•è¦†ç›–**
   - éœ€è¦æ›´å¤šçš„å•å…ƒæµ‹è¯•
   - éœ€è¦é›†æˆæµ‹è¯•

---

**ï¼ˆç¬¬ä¸€éƒ¨åˆ†å®Œæˆï¼‰**

*ç»§ç»­é˜…è¯»ç¬¬äºŒéƒ¨åˆ†ï¼šæç¤ºè¯å·¥ç¨‹è¯¦è§£*


# ç¬¬äºŒéƒ¨åˆ†ï¼šæç¤ºè¯å·¥ç¨‹è¯¦è§£

## 2.1 byzerllm.prompt() è£…é¥°å™¨æœºåˆ¶

### 2.1.1 è£…é¥°å™¨åŸç†

`@byzerllm.prompt()` æ˜¯ä¸€ä¸ªåˆ›æ–°çš„è£…é¥°å™¨ï¼Œå®ç°äº†æç¤ºè¯ä¸ä»£ç çš„å®Œç¾åˆ†ç¦»ï¼š

**æ ¸å¿ƒç‰¹æ€§**ï¼š
1. ä½¿ç”¨ Jinja2 æ¨¡æ¿å¼•æ“
2. Docstring å³æç¤ºè¯
3. è¿”å›å­—å…¸æ³¨å…¥å˜é‡
4. æ”¯æŒåµŒå¥—è°ƒç”¨

**åŸºæœ¬ç”¨æ³•**ï¼š

```python
@byzerllm.prompt()
def generate_prompt(self, request: SomeRequest) -> str:
    """
    This is the system prompt.
    
    User input: {{ user_input }}
    Current time: {{ current_time }}
    """
    return {
        "user_input": request.user_input,
        "current_time": datetime.now().isoformat()
    }

# è°ƒç”¨
prompt_text = self.generate_prompt.prompt(request)
```

**å·¥ä½œæµç¨‹**ï¼š
1. è£…é¥°å™¨æå–å‡½æ•°çš„ docstring
2. æ‰§è¡Œå‡½æ•°è·å–å˜é‡å­—å…¸
3. ä½¿ç”¨ Jinja2 æ¸²æŸ“æ¨¡æ¿
4. è¿”å›æœ€ç»ˆçš„æç¤ºè¯æ–‡æœ¬

### 2.1.2 åœ¨ AgenticEdit ä¸­çš„åº”ç”¨

**æ ¸å¿ƒæç¤ºè¯æ–¹æ³•**ï¼š

```python
@byzerllm.prompt()
def _analyze(self, request: AgenticEditRequest) -> str:
    """
    {{system_prompt}}
    
    ====
    
    TOOL USE
    
    You have access to a set of tools that are executed upon the user's approval...
    
    # Tools
    
    {% for tool_tag, tool_description in tool_descriptions.items() %}
    ## {{ tool_tag }}
    {{ tool_description.description }}                
    {% endfor %}
    
    # Tool Use Examples
    
    {% for tool_tag, example in tool_examples.items() %}
    {% if example %}
    ## {{ example.title }}
    {{ example.body }}
    {% endif %}
    {% endfor %}
    
    ====
    
    RULES
    
    - Your current working directory is: {{current_project}}
    - You cannot `cd` into a different directory
    {% if extra_docs %}
    - Follow the rules in RULES OR DOCUMENTS PROVIDED BY USER section
    {% endif %}
    
    ...
    """
    # è·å–æ‰€æœ‰éœ€è¦æ³¨å…¥çš„å˜é‡
    tool_descriptions = ToolRegistry.get_all_tool_descriptions()
    tool_examples = ToolRegistry.get_all_tool_examples()
    
    return {
        "system_prompt": self.custom_system_prompt,
        "tool_descriptions": tool_descriptions,
        "tool_examples": tool_examples,
        "current_project": os.path.abspath(self.args.source_dir),
        "extra_docs": get_required_and_index_rules(),
        ...
    }
```

## 2.2 ç»“æ„åŒ–ç³»ç»Ÿæç¤ºè¯

### 2.2.1 æç¤ºè¯çš„ä¸ƒå¤§éƒ¨åˆ†

Autocoder çš„ç³»ç»Ÿæç¤ºè¯é‡‡ç”¨é«˜åº¦ç»“æ„åŒ–çš„è®¾è®¡ï¼ŒåŒ…å«7ä¸ªä¸»è¦éƒ¨åˆ†ï¼š

**1. SYSTEM PROMPT** - è‡ªå®šä¹‰ç³»ç»Ÿè§’è‰²
```
{{system_prompt}}
```
- ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰ Agent çš„è§’è‰²å’Œèƒ½åŠ›
- é»˜è®¤ä¸ºï¼šè½¯ä»¶å·¥ç¨‹ä¸“å®¶

**2. TOOL USE** - å·¥å…·ä½¿ç”¨è¯´æ˜ï¼ˆæœ€å¤§çš„éƒ¨åˆ†ï¼Œ500+è¡Œï¼‰

åŒ…å«ï¼š
- Tool Use Formattingï¼šXML æ ¼å¼è¯´æ˜
- Toolsï¼š35+ å·¥å…·çš„è¯¦ç»†æè¿°
- Tool Use Examplesï¼šä¸°å¯Œçš„ä½¿ç”¨ç¤ºä¾‹
- Tool Use Guidelinesï¼šä½¿ç”¨æŒ‡å—

**3. CAPABILITIES** - èƒ½åŠ›æè¿°
- ä½œä¸º RAG ç³»ç»Ÿçš„èƒ½åŠ›
- æ‰§è¡Œå‘½ä»¤çš„èƒ½åŠ›
- æ–‡ä»¶æœç´¢å’Œè¯»å–èƒ½åŠ›

**4. RULES** - ä¸¥æ ¼çš„è§„åˆ™çº¦æŸ
- å·¥ä½œç›®å½•é™åˆ¶
- å‘½ä»¤æ‰§è¡Œè§„èŒƒ
- æ–‡ä»¶æ“ä½œè§„èŒƒ
- å·¥å…·ä½¿ç”¨è§„èŒƒ

**5. SYSTEM INFORMATION** - ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
```
Operating System: {{os_distribution}}
Default Shell: {{shell_type}}
Home Directory: {{home_dir}}
Current Working Directory: {{current_project}}
```

**6. OBJECTIVE** - ç›®æ ‡å’Œå·¥ä½œæµç¨‹
- åˆ†æç”¨æˆ·æŸ¥è¯¢
- ä½¿ç”¨å·¥å…·æ”¶é›†ä¿¡æ¯
- æ€è€ƒæ ‡ç­¾åˆ†æ
- å®Œæˆä»»åŠ¡

**7. DEFAULT WORKFLOW** - é»˜è®¤å·¥ä½œæµ
- å¦‚æœæä¾›äº†æ–‡ä»¶åˆ—è¡¨ï¼Œå…ˆè¯»å–
- å¦‚æœéœ€è¦è§„åˆ™ï¼Œå…ˆè¯»å–è§„åˆ™æ–‡ä»¶

### 2.2.2 å·¥å…·æè¿°çš„è®¾è®¡

æ¯ä¸ªå·¥å…·åŒ…å«ï¼š
1. æè¿°ï¼ˆDescriptionï¼‰
2. å‚æ•°ï¼ˆParametersï¼‰
3. ä½¿ç”¨æ–¹æ³•ï¼ˆUsageï¼‰
4. ç¤ºä¾‹ï¼ˆExampleï¼‰

**ç¤ºä¾‹ - read_file å·¥å…·**ï¼š

```
## read_file

Description: Request to read the contents of a file at the specified path. 
Use this when you need to examine the contents of an existing file you do 
not know the contents of, for example to analyze code, review text files, 
or extract information from configuration files.

**IMPORTANT AC Module Check**: Before reading any file, first check if 
the file is located within an AC Module directory...

Parameters:
- path: (required) The path of the file to read (relative to the current 
  working directory {{ current_project }})
- start_line: (optional) Starting line number (1-based) to read from. 
  If specified, only reads from this line onwards.
- end_line: (optional) Ending line number (1-based) to read to. 
  If specified, only reads up to this line.

Usage:
<read_file>
<path>relative/path/to/file</path>
<start_line>10</start_line>
<end_line>50</end_line>
</read_file>
```

### 2.2.3 XML vs JSON çš„é€‰æ‹©

**ä¸ºä»€ä¹ˆé€‰æ‹© XML æ ¼å¼ï¼Ÿ**

1. **å¤šè¡Œå†…å®¹æ— éœ€è½¬ä¹‰**
```xml
<!-- XML: è‡ªç„¶çš„å¤šè¡Œå†…å®¹ -->
<write_to_file>
<path>src/main.py</path>
<content>
def hello():
    print("Hello World")
    return 42
</content>
</write_to_file>

<!-- JSON: éœ€è¦è½¬ä¹‰ -->
{
  "tool": "write_to_file",
  "content": "def hello():\n    print(\"Hello World\")\n    return 42"
}
```

2. **æµå¼è§£ææ›´è‡ªç„¶**
- åŸºäºæ ‡ç­¾åŒ¹é…ï¼š`<tool_name>` ... `</tool_name>`
- å¯ä»¥å¢é‡è§£æ
- å®¹é”™æ€§æ›´å¥½

3. **æ›´æ˜“äººç±»é˜…è¯»**
- ç»“æ„æ¸…æ™°
- å±‚æ¬¡åˆ†æ˜
- ä¾¿äºè°ƒè¯•

4. **LLM ç”Ÿæˆæ›´ç¨³å®š**
- ä¸éœ€è¦è€ƒè™‘è½¬ä¹‰è§„åˆ™
- ç”Ÿæˆé”™è¯¯ç‡æ›´ä½

## 2.3 å·¥å…·æè¿°ç”Ÿæˆå™¨ï¼ˆToolDescGeneratorsï¼‰

### 2.3.1 ToolDescription æ•°æ®ç»“æ„

```python
class ToolDescription(BaseModel):
    """å·¥å…·æè¿°"""
    description: str  # å·¥å…·çš„å®Œæ•´æè¿°ï¼ŒåŒ…å«å‚æ•°è¯´æ˜å’Œä½¿ç”¨æ–¹æ³•

class ToolExample(BaseModel):
    """å·¥å…·ç¤ºä¾‹"""
    title: str  # ç¤ºä¾‹æ ‡é¢˜
    body: str   # ç¤ºä¾‹å†…å®¹ï¼ˆåŒ…å«ä½¿ç”¨åœºæ™¯å’Œä»£ç ï¼‰

class ToolDefinition(BaseModel):
    """å®Œæ•´çš„å·¥å…·å®šä¹‰"""
    tool_cls: Type[BaseTool]
    resolver_cls: Type[BaseToolResolver]
    description: ToolDescription
    example: ToolExample
    use_guideline: str = ""
    is_default: bool = False
    case_docs: List[str] = []
```

### 2.3.2 å·¥å…·æ³¨å†Œç¤ºä¾‹

```python
# æ³¨å†Œ read_file å·¥å…·
ToolRegistry.register_tool(
    tool_tag="read_file",
    tool_cls=ReadFileTool,
    resolver_cls=ReadFileToolResolver,
    description=ToolDescription(
        description="""
        Request to read the contents of a file at the specified path...
        
        Parameters:
        - path: (required) The path of the file to read
        - start_line: (optional) Starting line number
        - end_line: (optional) Ending line number
        
        Usage:
        <read_file>
        <path>relative/path/to/file</path>
        </read_file>
        """
    ),
    example=ToolExample(
        title="Reading a configuration file",
        body="""
        <read_file>
        <path>config/settings.json</path>
        </read_file>
        """
    ),
    use_guideline="Always use this tool before modifying a file"
)
```

## 2.4 ä¸Šä¸‹æ–‡æ³¨å…¥ç­–ç•¥
## 2.3.4 é‡è¦å·¥å…·æè¿°æ¨¡æ¿å±•ç¤º

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/agent/base_agentic/default_tools.py`

å·¥å…·æè¿°æ˜¯ LLM ç†è§£å’Œæ­£ç¡®ä½¿ç”¨å·¥å…·çš„å…³é”®ã€‚Autocoder ä½¿ç”¨ `@byzerllm.prompt()` è£…é¥°å™¨å®šä¹‰å·¥å…·æè¿°æ¨¡æ¿ï¼Œç»“åˆ Jinja2 æ¨¡æ¿å¼•æ“å®ç°åŠ¨æ€å‚æ•°æ³¨å…¥ã€‚

ä»¥ä¸‹å±•ç¤º 5 ä¸ªæ ¸å¿ƒå·¥å…·çš„å®Œæ•´æè¿°æ¨¡æ¿ï¼Œå±•ç¤ºäº†æè¿°çš„æ ‡å‡†æ ¼å¼å’Œè®¾è®¡æ€è·¯ã€‚

### å·¥å…· 1: execute_command - æ‰§è¡Œç³»ç»Ÿå‘½ä»¤

```python
@byzerllm.prompt()
def execute_command(self) -> Dict:
    """
    Description: Request to execute a CLI command on the system. Use this when you need to perform system operations or run specific commands to accomplish any step in the user's task. You must tailor your command to the user's system and provide a clear explanation of what the command does. For command chaining, use the appropriate chaining syntax for the user's shell. Prefer to execute complex CLI commands over creating executable scripts, as they are more flexible and easier to run. Commands will be executed in the current working directory: {{current_project}}
    Parameters:
    - command: (required) The CLI command to execute. This should be valid for the current operating system. Ensure the command is properly formatted and does not contain any harmful instructions.
    - requires_approval: (required) A boolean indicating whether this command requires explicit user approval before execution in case the user has auto-approve mode enabled. Set to 'true' for potentially impactful operations like installing/uninstalling packages, deleting/overwriting files, system configuration changes, network operations, or any commands that could have unintended side effects. Set to 'false' for safe operations like reading files/directories, running development servers, building projects, and other non-destructive operations.
    Usage:
    <execute_command>
    <command>Your command here</command>
    <requires_approval>true or false</requires_approval>
    </execute_command>
    """
    return self.params
```

**è®¾è®¡è¦ç‚¹**:
- **Description**: è¯´æ˜å·¥å…·çš„ç”¨é€”ã€ä½¿ç”¨æ—¶æœºã€æ³¨æ„äº‹é¡¹
- **Parameters**: åˆ—å‡ºæ‰€æœ‰å‚æ•°ï¼Œæ˜ç¡®å¿…éœ€/å¯é€‰ã€ç±»å‹ã€å«ä¹‰
- **Usage**: æä¾› XML æ ¼å¼çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œå±•ç¤ºå‚æ•°å¦‚ä½•ä¼ é€’
- **å®‰å…¨æœºåˆ¶**: `requires_approval` å‚æ•°å®ç°äº†é£é™©æ“ä½œçš„å®¡æ‰¹æœºåˆ¶

### å·¥å…· 2: read_file - è¯»å–æ–‡ä»¶

```python
@byzerllm.prompt()
def read_file(self) -> Dict:
    """
    Description: Request to read the contents of a file at the specified path. Use this when you need to examine the contents of an existing file you do not know the contents of, for example to analyze code, review text files, or extract information from configuration files. Automatically extracts raw text from PDF and DOCX files. May not be suitable for other types of binary files, as it returns the raw content as a string.
    Parameters:
    - path: (required) The path of the file to read (relative to the current working directory ${cwd.toPosix()})
    Usage:
    <read_file>
    <path>File path here</path>
    </read_file>
    """
    return self.params
```

**è®¾è®¡è¦ç‚¹**:
- æ˜ç¡®ä½¿ç”¨åœºæ™¯ï¼šåˆ†æä»£ç ã€å®¡æŸ¥æ–‡æœ¬ã€æå–é…ç½®ä¿¡æ¯
- è¯´æ˜ç‰¹æ®Šèƒ½åŠ›ï¼šè‡ªåŠ¨æå– PDF å’Œ DOCX ä¸­çš„æ–‡æœ¬
- æç¤ºé™åˆ¶ï¼šä¸é€‚åˆå…¶ä»–ç±»å‹çš„äºŒè¿›åˆ¶æ–‡ä»¶
- è·¯å¾„è¯´æ˜ï¼šç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•

### å·¥å…· 3: replace_in_file - ç²¾ç¡®æ›¿æ¢æ–‡ä»¶å†…å®¹

```python
@byzerllm.prompt()
def replace_in_file(self) -> Dict:
    """
    Description: Request to replace sections of content in an existing file using SEARCH/REPLACE blocks that define exact changes to specific parts of the file. This tool should be used when you need to make targeted changes to specific parts of a file.
    Parameters:
    - path: (required) The path of the file to modify (relative to the current working directory ${cwd.toPosix()})
    - diff: (required) One or more SEARCH/REPLACE blocks following this exact format:
    ```
    <<<<<<< SEARCH
    [exact content to find]
    =======
    [new content to replace with]
    >>>>>>> REPLACE
    ```
    Critical rules:
    1. SEARCH content must match the associated file section to find EXACTLY:
        * Match character-for-character including whitespace, indentation, line endings
        * Include all comments, docstrings, etc.
    2. SEARCH/REPLACE blocks will ONLY replace the first match occurrence.
        * Including multiple unique SEARCH/REPLACE blocks if you need to make multiple changes.
        * Include *just* enough lines in each SEARCH section to uniquely match each set of lines that need to change.
        * When using multiple SEARCH/REPLACE blocks, list them in the order they appear in the file.
    3. Keep SEARCH/REPLACE blocks concise:
        * Break large SEARCH/REPLACE blocks into a series of smaller blocks that each change a small portion of the file.
        * Include just the changing lines, and a few surrounding lines if needed for uniqueness.
        * Do not include long runs of unchanging lines in SEARCH/REPLACE blocks.
        * Each line must be complete. Never truncate lines mid-way through as this can cause matching failures.
    4. Special operations:
        * To move code: Use two SEARCH/REPLACE blocks (one to delete from original + one to insert at new location)
        * To delete code: Use empty REPLACE section
    Usage:
    <replace_in_file>
    <path>File path here</path>
    <diff>
    Search and replace blocks here
    </diff>
    </replace_in_file>
    """
    return self.params
```

**è®¾è®¡è¦ç‚¹**:
- **ç²¾ç¡®åŒ¹é…**: å¼ºè°ƒ SEARCH å†…å®¹å¿…é¡»å®Œå…¨åŒ¹é…ï¼ˆåŒ…æ‹¬ç©ºæ ¼ã€ç¼©è¿›ã€æ¢è¡Œï¼‰
- **å¤šæ¬¡æ›¿æ¢**: æ”¯æŒå¤šä¸ª SEARCH/REPLACE å—è¿›è¡Œæ‰¹é‡ä¿®æ”¹
- **é¡ºåºè¦æ±‚**: å¤šä¸ªå—åº”æŒ‰æ–‡ä»¶ä¸­å‡ºç°çš„é¡ºåºæ’åˆ—
- **ç®€æ´åŸåˆ™**: æ¯ä¸ªå—åªåŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡ï¼Œé¿å…å†—é•¿
- **ç‰¹æ®Šæ“ä½œ**: æä¾›ç§»åŠ¨ä»£ç å’Œåˆ é™¤ä»£ç çš„å…·ä½“æ–¹æ³•

### å·¥å…· 4: search_files - æ­£åˆ™æœç´¢æ–‡ä»¶

```python
@byzerllm.prompt()
def search_files(self) -> Dict:
    """
    Description: Request to perform a regex search across files in a specified directory, providing context-rich results. This tool searches for patterns or specific content across multiple files, displaying each match with encapsulating context.
    Parameters:
    - path: (required) The path of the directory to search in (relative to the current working directory ${cwd.toPosix()}). This directory will be recursively searched.
    - regex: (required) The regular expression pattern to search for. Uses Rust regex syntax.
    - file_pattern: (optional) Glob pattern to filter files (e.g., '*.ts' for TypeScript files). If not provided, it will search all files (*).
    Usage:
    <search_files>
    <path>Directory path here</path>
    <regex>Your regex pattern here</regex>
    <file_pattern>file pattern here (optional)</file_pattern>
    </search_files>
    """
    return self.params
```

**è®¾è®¡è¦ç‚¹**:
- **æ­£åˆ™æ”¯æŒ**: ä½¿ç”¨ Rust regex è¯­æ³•ï¼ˆripgrep åº•å±‚ï¼‰
- **é€’å½’æœç´¢**: è‡ªåŠ¨é€’å½’æœç´¢æŒ‡å®šç›®å½•
- **æ–‡ä»¶è¿‡æ»¤**: æ”¯æŒ glob æ¨¡å¼è¿‡æ»¤æ–‡ä»¶ç±»å‹
- **ä¸Šä¸‹æ–‡å±•ç¤º**: æä¾›åŒ¹é…è¡Œçš„å‘¨å›´ä¸Šä¸‹æ–‡ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰

### å·¥å…· 5: attempt_completion - å®Œæˆä»»åŠ¡

```python
@byzerllm.prompt()
def attempt_completion(self) -> Dict:
    """
    Description: After each tool use, the user will respond with the result of that tool use, i.e. if it succeeded or failed, along with any reasons for failure. Once you've received the results of tool uses and can confirm that the task is complete, use this tool to present the result of your work to the user. Optionally you may provide a CLI command to showcase the result of your work. The user may respond with feedback if they are not satisfied with the result, which you can use to make improvements and try again.
    IMPORTANT NOTE: This tool CANNOT be used until you've confirmed from the user that any previous tool uses were successful. Failure to do so will result in code corruption and system failure. Before using this tool, you must ask yourself in <thinking></thinking> tags if you've confirmed from the user that any previous tool uses were successful. If not, then DO NOT use this tool.
    Parameters:
    - result: (required) The result of the task. Formulate this result in a way that is final and does not require further input from the user. Don't end your result with questions or offers for further assistance.
    - command: (optional) A CLI command to execute to show a live demo of the result to the user. For example, use \`open index.html\` to display a created html website, or \`open localhost:3000\` to display a locally running development server. But DO NOT use commands like \`echo\` or \`cat\` that merely print text. This command should be valid for the current operating system. Ensure the command is properly formatted and does not contain any harmful instructions.
    Usage:
    <attempt_completion>
    <result>
    Your final result description here
    </result>
    <command>Command to demonstrate result (optional)</command>
    </attempt_completion>
    """
    return self.params
```

**è®¾è®¡è¦ç‚¹**:
- **ä½¿ç”¨æ—¶æœº**: æ˜ç¡®åªæœ‰åœ¨ç¡®è®¤æ‰€æœ‰å·¥å…·è°ƒç”¨æˆåŠŸåæ‰èƒ½ä½¿ç”¨
- **å®‰å…¨è­¦å‘Š**: ç”¨å¤§å†™å’Œè­¦å‘Šè¯­æ°”å¼ºè°ƒè¿‡æ—©ä½¿ç”¨çš„ä¸¥é‡åæœ
- **æ€è€ƒæ ‡ç­¾**: è¦æ±‚ LLM åœ¨ `<thinking>` æ ‡ç­¾ä¸­è‡ªæˆ‘æ£€æŸ¥æ˜¯å¦æ»¡è¶³ä½¿ç”¨æ¡ä»¶
- **ç»“æœæ ¼å¼**: è¦æ±‚ç»“æœæ˜¯æœ€ç»ˆçš„ã€å®Œæ•´çš„ï¼Œä¸åŒ…å«åç»­é—®é¢˜
- **æ¼”ç¤ºå‘½ä»¤**: æ”¯æŒå¯é€‰çš„æ¼”ç¤ºå‘½ä»¤ï¼Œä½†é™åˆ¶äº†å‘½ä»¤ç±»å‹ï¼ˆä¸å…è®¸ç®€å•æ‰“å°å‘½ä»¤ï¼‰

### å·¥å…·æè¿°çš„é€šç”¨è®¾è®¡æ¨¡å¼

æ‰€æœ‰å·¥å…·æè¿°éƒ½éµå¾ªç»Ÿä¸€çš„ç»“æ„æ¨¡å¼ï¼š

1. **Description æ®µ**:
   - ç”¨é€”è¯´æ˜ï¼ˆUse this when...ï¼‰
   - ä½¿ç”¨åœºæ™¯ï¼ˆfor example...ï¼‰
   - ç‰¹æ®Šèƒ½åŠ›æˆ–é™åˆ¶ï¼ˆAutomatically... / May not be suitable...ï¼‰
   - ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚å·¥ä½œç›®å½•ï¼‰

2. **Parameters æ®µ**:
   - åˆ—ä¸¾æ‰€æœ‰å‚æ•°
   - æ ‡æ³¨ (required) æˆ– (optional)
   - è¯´æ˜ç±»å‹ã€æ ¼å¼ã€çº¦æŸ
   - æä¾›é»˜è®¤å€¼æˆ–ç¤ºä¾‹

3. **Usage æ®µ**:
   - æä¾›å®Œæ•´çš„ XML æ ¼å¼ç¤ºä¾‹
   - å±•ç¤ºæ‰€æœ‰å‚æ•°å¦‚ä½•ä¼ é€’
   - ä½¿ç”¨å ä½ç¬¦æç¤ºå®é™…å†…å®¹

4. **é¢å¤–è¯´æ˜**:
   - Critical rulesï¼ˆå…³é”®è§„åˆ™ï¼‰
   - IMPORTANT NOTEï¼ˆé‡è¦æç¤ºï¼‰
   - Special operationsï¼ˆç‰¹æ®Šæ“ä½œï¼‰

è¿™ç§ç»Ÿä¸€çš„æ ¼å¼ä½¿ LLM èƒ½å¤Ÿå¿«é€Ÿç†è§£å·¥å…·çš„åŠŸèƒ½ã€å‚æ•°å’Œä½¿ç”¨æ–¹æ³•ï¼Œé™ä½äº†å·¥å…·è¯¯ç”¨çš„å¯èƒ½æ€§ã€‚

---

### 2.4.1 MCP æœåŠ¡å™¨ä¿¡æ¯æ³¨å…¥

```python
mcp_server = get_mcp_server()
mcp_server_info_response = mcp_server.send_request(
    McpServerInfoRequest(
        model=args.inference_model or args.model,
        product_mode=args.product_mode,
    )
)
self.mcp_server_info = mcp_server_info_response.result

# æ³¨å…¥åˆ°æç¤ºè¯
"""
### MCP_SERVER_LIST
{{mcp_server_info}}
"""
```

### 2.4.2 RAG æœåŠ¡å™¨ä¿¡æ¯æ³¨å…¥

é€šè¿‡ RAGManager ç®¡ç† RAG æœåŠ¡ï¼Œå¹¶å°†å¯ç”¨çš„ RAG æœåŠ¡ä¿¡æ¯æ³¨å…¥åˆ°æç¤ºè¯ä¸­ã€‚

### 2.4.3 ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£æ³¨å…¥

```python
package_manager = LLMFriendlyPackageManager(project_root=self.args.source_dir)
added_libraries = package_manager.list_added_libraries()

if added_libraries:
    docs_content = package_manager.get_docs(return_paths=False)
    combined_docs = "\n\n".join(docs_content)
    
    library_docs_prompt = self.generate_library_docs_prompt.prompt(
        libraries_with_paths=libraries_with_paths,
        docs_content=combined_docs,
    )
    
    # æ³¨å…¥ä¸ºé¢„è½®æ¬¡å¯¹è¯
    conversations.append({"role": "user", "content": library_docs_prompt})
    conversations.append({
        "role": "assistant",
        "content": "I have read and understood the third-party library documentation..."
    })
```

#### 2.4.3.1 LLMFriendlyPackageManager æ¦‚è¿°

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/llm_friendly_package/main_manager.py`

LLMFriendlyPackageManager è´Ÿè´£ç®¡ç†ç¬¬ä¸‰æ–¹åº“çš„æ–‡æ¡£,ä¸º LLM æä¾›é¡¹ç›®ä¸­ä½¿ç”¨çš„ç¬¬ä¸‰æ–¹åº“çš„å‚è€ƒæ–‡æ¡£,å¸®åŠ© LLM ç”Ÿæˆç¬¦åˆåº“è§„èŒƒçš„ä»£ç ã€‚

**æ ¸å¿ƒåŠŸèƒ½**:

```python
class LLMFriendlyPackageManager:
    """
    å®Œæ•´çš„ LLM å‹å¥½åŒ…ç®¡ç†å™¨

    æä¾›çš„åŠŸèƒ½åŒ…æ‹¬:
    - åº“ç®¡ç†(æ·»åŠ ã€åˆ é™¤ã€åˆ—å‡º)
    - æ–‡æ¡£ç®¡ç†(è·å–æ–‡æ¡£ã€è·¯å¾„)
    - ä»“åº“ç®¡ç†(å…‹éš†ã€åˆ·æ–°ã€ä»£ç†)
    - æ˜¾ç¤ºç®¡ç†(è¡¨æ ¼ã€è¾“å‡º)
    """

    def __init__(self, project_root: Optional[str] = None):
        """
        åˆå§‹åŒ–åŒ…ç®¡ç†å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•,é»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•
        """
        self.project_root = project_root or os.getcwd()
        # ä½¿ç”¨ MemoryManager å­˜å‚¨åº“åˆ—è¡¨(å­˜å‚¨åœ¨ .auto-coder/memory.json)
        self.memory_manager = get_memory_manager(self.project_root)
        self.console = Console()

        # è®¾ç½®ç›®å½•è·¯å¾„
        self.lib_dir = os.path.join(self.project_root, ".auto-coder", "libs")
        # æ–‡æ¡£ä»“åº“é»˜è®¤å…‹éš†åˆ°è¿™ä¸ªä½ç½®
        self.llm_friendly_packages_dir = os.path.join(
            self.lib_dir, "llm_friendly_packages"
        )
```

**è®¾è®¡äº®ç‚¹**:

1. **é›†ä¸­å¼æ–‡æ¡£ä»“åº“**: ä» `https://github.com/allwefantasy/llm_friendly_packages` å…‹éš†æ–‡æ¡£
2. **æŒ‰éœ€åŠ è½½**: åªåŠ è½½ç”¨æˆ·æ·»åŠ çš„åº“çš„æ–‡æ¡£,é¿å…å…¨é‡åŠ è½½
3. **æŒä¹…åŒ–ç®¡ç†**: é€šè¿‡ MemoryManager è®°å½•å·²æ·»åŠ çš„åº“åˆ—è¡¨
4. **ç›®å½•ç»“æ„æ ‡å‡†åŒ–**: é‡‡ç”¨ `domain/username/lib_name` çš„ä¸‰å±‚ç›®å½•ç»“æ„

#### 2.4.3.2 æ–‡æ¡£åŠ è½½æµç¨‹

**ç¬¬ä¸€æ­¥:æ·»åŠ åº“**

```python
def add_library(self, lib_name: str) -> bool:
    """
    æ·»åŠ åº“åˆ°åˆ—è¡¨

    Args:
        lib_name: è¦æ·»åŠ çš„åº“åç§°

    Returns:
        æˆåŠŸè¿”å› True,å¤±è´¥è¿”å› False
    """
    # 1. é¦–æ¬¡ä½¿ç”¨æ—¶å…‹éš†ä»“åº“
    if not self._clone_repository():
        return False

    # 2. æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ 
    if self.memory_manager.has_lib(lib_name):
        self.console.print(f"Library {lib_name} is already added")
        return False

    # 3. æ·»åŠ åˆ° memory.json
    self.memory_manager.add_lib(lib_name, {})
    self.console.print(f"Added library: {lib_name}")
    return True
```

**ç¬¬äºŒæ­¥:è·å–æ–‡æ¡£**

```python
def get_docs(
    self,
    package_name: Optional[str] = None,
    return_paths: bool = False
) -> DocsList:
    """
    è·å–åŒ…çš„æ–‡æ¡£

    Args:
        package_name: æŒ‡å®šåŒ…åè·å–æ–‡æ¡£,None è¡¨ç¤ºè·å–æ‰€æœ‰å·²æ·»åŠ åŒ…çš„æ–‡æ¡£
        return_paths: True è¿”å›æ–‡ä»¶è·¯å¾„,False è¿”å›æ–‡ä»¶å†…å®¹

    Returns:
        æ–‡æ¡£å†…å®¹åˆ—è¡¨æˆ–æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    docs = []

    if not os.path.exists(self.llm_friendly_packages_dir):
        return docs

    # è·å–å·²æ·»åŠ çš„åº“åˆ—è¡¨
    libs = list(self.memory_manager.get_libs().keys())

    # éå†ä¸‰å±‚ç›®å½•ç»“æ„: domain/username/lib_name
    for domain in os.listdir(self.llm_friendly_packages_dir):
        domain_path = os.path.join(self.llm_friendly_packages_dir, domain)
        if not os.path.isdir(domain_path):
            continue

        for username in os.listdir(domain_path):
            username_path = os.path.join(domain_path, username)
            if not os.path.isdir(username_path):
                continue

            for lib_name in os.listdir(username_path):
                lib_path = os.path.join(username_path, lib_name)

                # æ£€æŸ¥ç›®å½•æœ‰æ•ˆæ€§
                if not os.path.isdir(lib_path):
                    continue

                # æ£€æŸ¥æ˜¯å¦æ˜¯è¯·æ±‚çš„åŒ…(æ”¯æŒ lib_name æˆ– username/lib_name æ ¼å¼)
                if package_name is not None:
                    if not (lib_name == package_name or
                           package_name == os.path.join(username, lib_name)):
                        continue

                # æ£€æŸ¥åº“æ˜¯å¦å·²æ·»åŠ 
                if lib_name not in libs:
                    continue

                # æ”¶é›†æ‰€æœ‰ .md æ–‡ä»¶
                for root, _, files in os.walk(lib_path):
                    for file in files:
                        if file.endswith(".md"):
                            file_path = os.path.join(root, file)
                            if return_paths:
                                docs.append(file_path)  # è¿”å›è·¯å¾„
                            else:
                                # è¿”å›å†…å®¹
                                try:
                                    with open(file_path, "r", encoding="utf-8") as f:
                                        docs.append(f.read())
                                except Exception as e:
                                    self.console.print(f"Error reading {file_path}: {e}")

    return docs
```

**ç¬¬ä¸‰æ­¥:æ–‡æ¡£æ ¼å¼åŒ–**

åœ¨ `agentic_edit.py` ä¸­,é€šè¿‡ byzerllm.prompt() è£…é¥°å™¨æ ¼å¼åŒ–æ–‡æ¡£æ³¨å…¥:

```python
@byzerllm.prompt()
def generate_library_docs_prompt(self) -> str:
    """
    ## Library Documentation

    The following third-party libraries are being used in this project:
    {% for lib in libraries_with_paths %}
    - {{ lib }}
    {% endfor %}

    Here is the documentation for these libraries:

    {{ docs_content }}

    Please use this documentation as a reference when generating code...
    """
    return {
        "libraries_with_paths": self.libraries_with_paths,
        "docs_content": self.docs_content
    }
```

#### 2.4.3.3 æ–‡æ¡£æ ¼å¼åŒ–ç­–ç•¥

**åˆå¹¶å¤šä¸ªæ–‡æ¡£**:

```python
# åœ¨ agentic_edit.py çš„ analyze() æ–¹æ³•ä¸­
package_manager = LLMFriendlyPackageManager(project_root=self.args.source_dir)
added_libraries = package_manager.list_added_libraries()

if added_libraries:
    # è·å–æ‰€æœ‰å·²æ·»åŠ åº“çš„æ–‡æ¡£å†…å®¹(ä¸æ˜¯è·¯å¾„)
    docs_content = package_manager.get_docs(return_paths=False)

    # ä½¿ç”¨ "\n\n" åˆå¹¶å¤šä¸ªæ–‡æ¡£
    combined_docs = "\n\n".join(docs_content)

    # ç”Ÿæˆæç¤ºè¯
    library_docs_prompt = self.generate_library_docs_prompt.prompt(
        libraries_with_paths=[f"{lib}" for lib in added_libraries],
        docs_content=combined_docs,
    )
```

**æ³¨å…¥ä¸ºé¢„è½®æ¬¡å¯¹è¯**:

```python
# æ–‡æ¡£å±‚æ³¨å…¥:è®© LLM "å­¦ä¹ "åº“æ–‡æ¡£
conversations.append({
    "role": "user",
    "content": library_docs_prompt
})

# æ¨¡æ‹Ÿ LLM çš„ç¡®è®¤å“åº”
conversations.append({
    "role": "assistant",
    "content": "I have read and understood the third-party library documentation. "
               "I will use it as a reference when generating code..."
})
```

**å…³é”®è®¾è®¡**:
- **åªåœ¨é¦–è½®å¯¹è¯æ³¨å…¥**: æ–‡æ¡£åªåœ¨ `current_conversation` ä¸ºç©ºæ—¶æ³¨å…¥,ä¸å ç”¨åç»­å¯¹è¯ä¸Šä¸‹æ–‡
- **åˆå¹¶è€Œéåˆ†æ•£**: å¤šä¸ªæ–‡æ¡£åˆå¹¶ä¸ºä¸€ä¸ªå¤§æ–‡æœ¬å—,å‡å°‘å¯¹è¯è½®æ¬¡
- **é¢„è½®æ¬¡å¯¹è¯**: ä½¿ç”¨ user + assistant å¯¹è¯å¯¹,è®© LLM è®°ä½æ–‡æ¡£å†…å®¹

#### 2.4.3.4 å¯¹ LLM å‹å¥½çš„æ–‡æ¡£å¤„ç†

**æ ‡å‡†æ–‡æ¡£ç»“æ„** (ä»¥ byzerllm åº“ä¸ºä¾‹):

```
.auto-coder/libs/llm_friendly_packages/
â””â”€â”€ github.com/
    â””â”€â”€ allwefantasy/
        â””â”€â”€ byzerllm/
            â”œâ”€â”€ README.md          # ä¸»æ–‡æ¡£
            â”œâ”€â”€ api_reference.md   # API å‚è€ƒ
            â”œâ”€â”€ examples.md        # ç¤ºä¾‹ä»£ç 
            â””â”€â”€ best_practices.md  # æœ€ä½³å®è·µ
```

**æ–‡æ¡£ç¼–å†™è§„èŒƒ**:

1. **ä½¿ç”¨æ ‡å‡† Markdown æ ¼å¼**: æ–¹ä¾¿ LLM è§£æ
2. **åŒ…å«å®Œæ•´ç¤ºä¾‹**: æä¾›å¯ç›´æ¥ä½¿ç”¨çš„ä»£ç ç‰‡æ®µ
3. **API ç­¾åæ¸…æ™°**: æ˜ç¡®å‚æ•°ç±»å‹å’Œè¿”å›å€¼
4. **åˆ†æ¨¡å—ç»„ç»‡**: ä¸€ä¸ªæ–‡ä»¶ä¸€ä¸ªä¸»é¢˜

**ç¤ºä¾‹ - byzerllm API æ–‡æ¡£ç‰‡æ®µ**:

```markdown
## byzerllm.prompt() è£…é¥°å™¨

ç”¨äºå°†å‡½æ•°è½¬æ¢ä¸º LLM æç¤ºè¯æ¨¡æ¿ã€‚

### ç­¾å

```python
@byzerllm.prompt(lambda_obj: bool = False)
def your_function() -> str:
    """Jinja2 æ¨¡æ¿å†…å®¹"""
    return variables_dict
```

### å‚æ•°

- `lambda_obj`: æ˜¯å¦è¿”å› lambda å¯¹è±¡(é»˜è®¤ False)

### è¿”å›å€¼

è£…é¥°åçš„å‡½æ•°è°ƒç”¨ `.prompt()` æ–¹æ³•æ—¶,è¿”å›æ¸²æŸ“åçš„æç¤ºè¯å­—ç¬¦ä¸²ã€‚

### ç¤ºä¾‹

```python
@byzerllm.prompt()
def generate_code(self) -> str:
    """
    Write a {{ language }} function that {{ description }}.

    Requirements:
    {% for req in requirements %}
    - {{ req }}
    {% endfor %}
    """
    return {
        "language": self.language,
        "description": self.description,
        "requirements": self.requirements
    }

# ä½¿ç”¨
prompt_text = generate_code.prompt()
```
```

**ä¼˜åŠ¿**:
- LLM å¯ä»¥ç›´æ¥ä»æ–‡æ¡£ä¸­å­¦ä¹ æ­£ç¡®çš„ API ç”¨æ³•
- åŒ…å«å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯(å‚æ•°ã€è¿”å›å€¼ã€ç¤ºä¾‹)
- å‡å°‘ LLM äº§ç”Ÿé”™è¯¯ä»£ç çš„æ¦‚ç‡

### 2.4.4 ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™æ³¨å…¥

```python
rules_text = get_rules_for_conversation()

if rules_text:
    conversations.append({
        "role": "user",
        "content": f"The following are user rules available for this project..."
    })
    conversations.append({
        "role": "assistant",
        "content": "I have read and understood the rules structure..."
    })
```

### 2.4.5 Sub Agents ä¿¡æ¯æ³¨å…¥

```python
# è·å–å¯ç”¨çš„ Agent ä¿¡æ¯
agent_names = AgentHub.list_agents()
if agent_names:
    agent_info = "Available Agents:\n"
    for name in agent_names:
        agent = AgentHub.get_agent(name)
        role = getattr(agent, "custom_system_prompt", "No description")
        agent_info += f"- {name}: {role[:100]}...\n"

# æ³¨å…¥åˆ°æç¤ºè¯
"""
### AVAILABLE_AGENTS
{{agent_info}}
"""
```

#### 2.4.5.1 AgentManager vs AgentHub åŒºåˆ«å¯¹æ¯”

**æºæ–‡ä»¶ä½ç½®**:
- AgentManager: `/projects/cuscli/autocoder/common/agents/agent_manager.py`
- AgentHub: `/projects/cuscli/autocoder/agent/base_agentic/agent_hub.py`

è™½ç„¶åå­—ç›¸ä¼¼,ä½†è¿™ä¸¤ä¸ªç±»èŒè´£å®Œå…¨ä¸åŒ:

| ç»´åº¦ | AgentManager | AgentHub |
|------|-------------|----------|
| **ä½œç”¨åŸŸ** | ç®¡ç† Named Sub Agents å®šä¹‰(`.md` æ–‡ä»¶) | ç®¡ç†è¿è¡Œæ—¶ Agent å®ä¾‹ |
| **æ•°æ®æ¥æº** | ä» `.autocoderagents/` ç›®å½•åŠ è½½ | ç¨‹åºè¿è¡Œæ—¶åŠ¨æ€æ³¨å†Œ |
| **æ•°æ®ç±»å‹** | `Agent` dataclass (é™æ€å…ƒæ•°æ®) | `BaseAgent` å®ä¾‹ (è¿è¡Œæ—¶å¯¹è±¡) |
| **ç”Ÿå‘½å‘¨æœŸ** | åº”ç”¨å¯åŠ¨æ—¶åŠ è½½,æƒ°æ€§æŸ¥æ‰¾ | Agent å®ä¾‹åŒ–æ—¶æ³¨å†Œ |
| **ä¸»è¦æ–¹æ³•** | `get_agent(name)`, `list_agents()`, `render_sub_agents_section()` | `register_agent()`, `get_agent()`, `list_agents()` |
| **ä½¿ç”¨åœºæ™¯** | ä¸º LLM æä¾›å¯å§”æ‰˜çš„å­ Agent ä¿¡æ¯ | å¤š Agent åä½œæ—¶çš„å®ä¾‹æŸ¥æ‰¾ |
| **å•ä¾‹æ¨¡å¼** | å¦,æ¯ä¸ª AgenticEdit å®ä¾‹åˆ›å»ºä¸€æ¬¡ | æ˜¯,å…¨å±€å•ä¾‹ |

**æ ¸å¿ƒåŒºåˆ«æ€»ç»“**:
- **AgentManager**: å¤„ç†"å¯ç”¨çš„ Agent æ¨¡æ¿",å‘Šè¯‰ LLM æœ‰å“ªäº› sub agent å¯ä»¥è°ƒç”¨
- **AgentHub**: å¤„ç†"è¿è¡Œä¸­çš„ Agent å®ä¾‹",æ”¯æŒ Agent ä¹‹é—´çš„é€šä¿¡å’Œåä½œ

#### 2.4.5.2 AgentManager è¯¦ç»†å®ç°

**æ ¸å¿ƒæ•°æ®ç»“æ„**:

```python
# agent_parser.py ä¸­å®šä¹‰çš„ Agent dataclass
@dataclass
class Agent:
    """è¡¨ç¤ºä¸€ä¸ª Agent å®šä¹‰"""
    name: str                      # Agent åç§°(å”¯ä¸€æ ‡è¯†ç¬¦)
    description: str               # Agent æè¿°(å‘Šè¯‰ LLM è¿™ä¸ª Agent çš„ç”¨é€”)
    tools: List[str]               # å¯ç”¨å·¥å…·åˆ—è¡¨,å¦‚ ["read_file", "write_to_file"]
    model: Optional[str] = None    # æŒ‡å®šçš„æ¨¡å‹,å¦‚ "gpt-4"
    content: str = ""              # System prompt å†…å®¹(Agent çš„è§’è‰²å®šä¹‰)
    file_path: Optional[Path] = None  # æºæ–‡ä»¶è·¯å¾„
    include_rules: bool = False    # æ˜¯å¦åŒ…å«å…¨å±€è§„åˆ™
```

**AgentManager åˆå§‹åŒ–å’ŒåŠ è½½**:

```python
class AgentManager:
    """ç®¡ç† Named Sub Agents å®šä¹‰çš„ç®¡ç†å™¨"""

    def __init__(self, project_root: str):
        """
        åˆå§‹åŒ– AgentManager

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.project_root = Path(project_root)
        # å­˜å‚¨æ‰€æœ‰åŠ è½½çš„ Agent å®šä¹‰(key: agent_name, value: Agent å¯¹è±¡)
        self.agents: Dict[str, Agent] = {}
        # è®°å½•å®é™…æ‰¾åˆ°çš„æœ‰æ•ˆ agent ç›®å½•åˆ—è¡¨
        self.agents_directories: List[str] = []
        # å¯åŠ¨æ—¶ç«‹å³åŠ è½½æ‰€æœ‰ agent å®šä¹‰
        self._load_agents()

    def _load_agents(self) -> None:
        """
        ä½¿ç”¨ä¼˜å…ˆçº§ç›®å½•æŸ¥æ‰¾å™¨åŠ è½½ agent å®šä¹‰ã€‚
        é‡‡ç”¨ MERGE_ALL ç­–ç•¥,åˆå¹¶æ‰€æœ‰ç›®å½•ä¸­çš„ agent å®šä¹‰,æ”¯æŒä¼˜å…ˆçº§è¦†ç›–å’Œ repos åŠŸèƒ½ã€‚
        """
        try:
            # åˆ›å»ºæ–‡ä»¶è¿‡æ»¤å™¨,åªæŸ¥æ‰¾ .md æ–‡ä»¶
            md_filter = create_file_filter(extensions=[".md"], recursive=False)

            # åˆ›å»ºæŸ¥æ‰¾å™¨é…ç½®,ä½¿ç”¨ MERGE_ALL ç­–ç•¥åˆå¹¶æ‰€æœ‰ç›®å½•
            config = FinderConfig(strategy=SearchStrategy.MERGE_ALL)

            # è·å–é¡¹ç›®å(ç”¨äº repos ç›®å½•)
            project_name = self.project_root.name

            # æŒ‰ä¼˜å…ˆçº§æ·»åŠ ç›®å½•é…ç½®(ä¼˜å…ˆçº§ 1 æœ€é«˜)
            config.add_directory(
                path=str(self.project_root / ".autocoderagents"),
                priority=1,  # é¡¹ç›®çº§ agent(æœ€é«˜ä¼˜å…ˆçº§)
                validation_mode=ValidationMode.HAS_SPECIFIC_FILES,
                file_filter=md_filter,
                description="é¡¹ç›®çº§agentç›®å½•"
            )
            config.add_directory(
                path=str(self.project_root / ".auto-coder" / ".autocoderagents"),
                priority=2,  # é¡¹ç›® .auto-coder agent ç›®å½•
                validation_mode=ValidationMode.HAS_SPECIFIC_FILES,
                file_filter=md_filter,
                description="é¡¹ç›®.auto-coder agentç›®å½•"
            )
            config.add_directory(
                path="~/.auto-coder/.autocoderagents",
                priority=3,  # å…¨å±€ agent ç›®å½•
                validation_mode=ValidationMode.HAS_SPECIFIC_FILES,
                file_filter=md_filter,
                description="å…¨å±€agentç›®å½•"
            )
            # æ·»åŠ  repos ç›®å½•æ”¯æŒ(é¡¹ç›®ç‰¹å®šçš„å…¨å±€ agent)
            repos_dir = f"~/.auto-coder/.autocoderagents/repos/{project_name}"
            config.add_directory(
                path=repos_dir,
                priority=4,  # repos ç›®å½•ä¼˜å…ˆçº§æœ€ä½
                validation_mode=ValidationMode.HAS_SPECIFIC_FILES,
                file_filter=md_filter,
                description=f"é¡¹ç›®ç‰¹å®šrepos agentç›®å½•: {project_name}"
            )

            # æ‰§è¡ŒæŸ¥æ‰¾
            finder = PriorityDirectoryFinder(config)
            result = finder.find_directories()

            if result.success and result.selected_directories:
                logger.info(f"ä½¿ç”¨ä¼˜å…ˆçº§æŸ¥æ‰¾å™¨æ‰¾åˆ° {len(result.selected_directories)} ä¸ªagentç›®å½•")
                self.agents_directories = result.selected_directories

                # æŒ‰ä¼˜å…ˆçº§é¡ºåºåŠ è½½ agents,é«˜ä¼˜å…ˆçº§è¦†ç›–ä½ä¼˜å…ˆçº§
                for agents_dir in self.agents_directories:
                    logger.info(f"åŠ è½½agentç›®å½•: {agents_dir}")
                    self._load_agents_from_directory(Path(agents_dir))
            else:
                logger.info("ä¼˜å…ˆçº§æŸ¥æ‰¾å™¨æœªæ‰¾åˆ°åŒ…å«agentæ–‡ä»¶çš„ç›®å½•")
                self.agents_directories = []

        except Exception as e:
            logger.error(f"ä½¿ç”¨ä¼˜å…ˆçº§æŸ¥æ‰¾å™¨åŠ è½½agentsæ—¶å‡ºé”™: {e}")
            # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
            self._load_agents_fallback()
```

**å•ä¸ªç›®å½•çš„ Agent åŠ è½½**:

```python
def _load_agents_from_directory(self, agents_dir: Path) -> None:
    """ä»æŒ‡å®šç›®å½•åŠ è½½ agents,å®ç°ä¼˜å…ˆçº§è¦†ç›–é€»è¾‘"""
    if not agents_dir.exists():
        logger.debug(f"Agents directory not found: {agents_dir}")
        return

    if not agents_dir.is_dir():
        logger.warning(f"Expected directory but found file: {agents_dir}")
        return

    # æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶
    md_files = list(agents_dir.glob("*.md"))

    if md_files:
        logger.debug(f"Found {len(md_files)} agent files in {agents_dir}")

    for md_file in md_files:
        try:
            # ä½¿ç”¨ AgentParser è§£æ .md æ–‡ä»¶
            agent = AgentParser.parse_agent_file(md_file)

            # éªŒè¯ agent å®šä¹‰
            errors = AgentParser.validate_agent(agent)
            if errors:
                logger.error(f"Validation errors for {md_file.name}: {'; '.join(errors)}")
                continue

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰åŒå agent,å®ç°ä¼˜å…ˆçº§è¦†ç›–é€»è¾‘
            if agent.name in self.agents:
                old_agent_path = self.agents[agent.name].file_path
                # ç”±äºæˆ‘ä»¬æŒ‰ä¼˜å…ˆçº§é¡ºåºåŠ è½½,ååŠ è½½çš„ä¼˜å…ˆçº§æ›´ä½,æ‰€ä»¥è·³è¿‡
                logger.debug(
                    f"è·³è¿‡agent '{agent.name}' from {md_file} "
                    f"(å·²å­˜åœ¨ä¼˜å…ˆçº§æ›´é«˜çš„ç‰ˆæœ¬: {old_agent_path})"
                )
                continue

            # å­˜å‚¨ agent å®šä¹‰
            self.agents[agent.name] = agent
            logger.debug(f"Loaded agent '{agent.name}' from {md_file}")

        except Exception as e:
            logger.error(f"Failed to parse agent file {md_file.name}: {e}")
```

#### 2.4.5.3 Agent æ–‡ä»¶æ ¼å¼è§„èŒƒ

**æ ‡å‡† Agent å®šä¹‰æ–‡ä»¶** (`.md` æ ¼å¼):

```markdown
---
name: code_reviewer
description: Reviews code for quality, style, and potential bugs
tools: read_file, search_files
model: gpt-4
include_rules: false
---

You are an expert code reviewer with years of experience in software engineering.

Your responsibilities:
1. Review code for correctness and potential bugs
2. Check adherence to coding standards and best practices
3. Suggest improvements for readability and maintainability
4. Identify security vulnerabilities

When reviewing code:
- Be constructive and specific in your feedback
- Provide examples of how to improve the code
- Prioritize issues by severity (critical, major, minor)
- Explain the reasoning behind your suggestions

Always maintain a professional and helpful tone.
```

**YAML Frontmatter å­—æ®µè¯´æ˜**:

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|------|
| `name` | string | æ˜¯ | Agent åç§°(å”¯ä¸€æ ‡è¯†ç¬¦) | `code_reviewer` |
| `description` | string | æ˜¯ | Agent æè¿°(ç®€çŸ­è¯´æ˜) | `Reviews code for quality` |
| `tools` | string | å¦ | é€—å·åˆ†éš”çš„å·¥å…·åˆ—è¡¨ | `read_file, write_to_file` |
| `model` | string | å¦ | æŒ‡å®šæ¨¡å‹ | `gpt-4`, `claude-3-5-sonnet` |
| `include_rules` | boolean | å¦ | æ˜¯å¦åŒ…å«å…¨å±€è§„åˆ™ | `true` æˆ– `false` |

**ç‰¹æ®Šå·¥å…·å€¼**:
- `tools: *` : è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨å·¥å…·
- `tools: ""` : è¡¨ç¤ºä¸ä½¿ç”¨ä»»ä½•å·¥å…·(çº¯å¯¹è¯ Agent)

#### 2.4.5.4 Agent ä¼˜å…ˆçº§å’Œè¦†ç›–æœºåˆ¶

**ç›®å½•ä¼˜å…ˆçº§**(ä»é«˜åˆ°ä½):

1. **é¡¹ç›®çº§**: `.autocoderagents/` (æœ€é«˜ä¼˜å…ˆçº§)
   - ç”¨äºé¡¹ç›®ç‰¹å®šçš„ã€ä¸´æ—¶çš„ agent
   - ä¸åº”æäº¤åˆ° git(æ·»åŠ åˆ° .gitignore)

2. **é¡¹ç›® .auto-coder çº§**: `.auto-coder/.autocoderagents/`
   - æ¨èä½ç½®,é¡¹ç›®ç›¸å…³çš„ agent
   - å¯ä»¥æäº¤åˆ° git,å›¢é˜Ÿå…±äº«

3. **å…¨å±€çº§**: `~/.auto-coder/.autocoderagents/`
   - ç”¨æˆ·ä¸ªäººå¸¸ç”¨çš„ agent
   - è·¨é¡¹ç›®å¤ç”¨

4. **Repos çº§**: `~/.auto-coder/.autocoderagents/repos/<é¡¹ç›®å>/`
   - ç‰¹å®šé¡¹ç›®çš„å…¨å±€ agent
   - æ ¹æ®é¡¹ç›®åè‡ªåŠ¨é€‰æ‹©

**è¦†ç›–è§„åˆ™**:

```python
# ç¤ºä¾‹:å‡è®¾ä»¥ä¸‹ç›®å½•éƒ½æœ‰åä¸º "translator" çš„ agent æ–‡ä»¶

# ä¼˜å…ˆçº§ 1: é¡¹ç›®çº§(ä¼šè¢«ä½¿ç”¨)
.autocoderagents/translator.md

# ä¼˜å…ˆçº§ 2: é¡¹ç›® .auto-coder çº§(è¢«å¿½ç•¥)
.auto-coder/.autocoderagents/translator.md

# ä¼˜å…ˆçº§ 3: å…¨å±€çº§(è¢«å¿½ç•¥)
~/.auto-coder/.autocoderagents/translator.md

# ä¼˜å…ˆçº§ 4: Repos çº§(è¢«å¿½ç•¥)
~/.auto-coder/.autocoderagents/repos/myproject/translator.md
```

**æ—¥å¿—è¾“å‡ºç¤ºä¾‹**:

```
INFO: ä½¿ç”¨ä¼˜å…ˆçº§æŸ¥æ‰¾å™¨æ‰¾åˆ° 3 ä¸ªagentç›®å½•
INFO: åŠ è½½agentç›®å½•: /path/to/project/.autocoderagents
DEBUG: Loaded agent 'translator' from /path/to/project/.autocoderagents/translator.md
INFO: åŠ è½½agentç›®å½•: ~/.auto-coder/.autocoderagents
DEBUG: è·³è¿‡agent 'translator' from ~/.auto-coder/.autocoderagents/translator.md
      (å·²å­˜åœ¨ä¼˜å…ˆçº§æ›´é«˜çš„ç‰ˆæœ¬: /path/to/project/.autocoderagents/translator.md)
```

#### 2.4.5.5 render_sub_agents_section æ–¹æ³•è¯¦è§£

**æ–¹æ³•ç­¾å**:

```python
@byzerllm.prompt()
def render_sub_agents_section(self, current_model: Optional[str] = None) -> str:
    """
    æ¸²æŸ“ Sub Agents ä¿¡æ¯åˆ° System Prompt

    Args:
        current_model: å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°(å¦‚æœ agent æœªæŒ‡å®šæ¨¡å‹åˆ™ä½¿ç”¨æ­¤å€¼)

    Returns:
        æ¸²æŸ“åçš„ Sub Agents ä¿¡æ¯æ–‡æœ¬
    """
```

**Jinja2 æ¨¡æ¿** (æ–¹æ³•çš„ docstring):

```jinja2
{% if not agents_available %}
{% else %}
## Available Named Sub Agents

The following specialized agents are available for delegation:

{% for agent in sorted_agents %}
### {{ agent.name }}
**Description**: {{ agent.description }}
{% if agent.tools %}
**Available Tools**: {{ agent.tools | join(', ') }}
{% endif %}

{% endfor %}
## How to Use

Use the `run_named_subagents` tool to run multiple agent commands:

### Example: Parallel Execution

<run_named_subagents>
<subagents>
mode: parallel
subagents:
{% for agent in example_agents %}
    - name: {{ agent.name }}
      task: {{ agent.example_task }}
{% endfor %}
</subagents>
</run_named_subagents>


### Example: Serial Execution

<run_named_subagents>
<subagents>
mode: serial
subagents:
    - name: agent_name
      task: your task description here
</subagents>
</run_named_subagents>

{% endif %}
```

**æ¨¡æ¿å˜é‡æ„å»º**:

```python
def render_sub_agents_section(self, current_model: Optional[str] = None) -> str:
    # å¦‚æœæ²¡æœ‰ agent,è¿”å›ç©ºæç¤º
    if not self.agents:
        return {
            "agents_available": False
        }

    # æŒ‰åç§°æ’åº,ä¿è¯è¾“å‡ºä¸€è‡´æ€§
    sorted_agents = sorted(self.agents.values(), key=lambda a: a.name)

    # å‡†å¤‡ agent æ•°æ®ä¾›æ¨¡æ¿ä½¿ç”¨
    agents_data = []
    for agent in sorted_agents:
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹(agent è‡ªå·±çš„æ¨¡å‹ æˆ– å½“å‰æ¨¡å‹)
        model_to_use = agent.model or current_model
        if not model_to_use:
            raise ValueError(
                f"Agent {agent.name} has no model specified "
                "and no current model provided"
            )

        # ç”Ÿæˆå®‰å…¨çš„ shell å‘½ä»¤ç¤ºä¾‹(ä½¿ç”¨ shlex.quote é¿å…æ³¨å…¥)
        safe_task = shlex.quote("YOUR_TASK_HERE")
        safe_model = shlex.quote(model_to_use)
        safe_prompt = shlex.quote(agent.content)
        command = (
            f'echo {safe_task} | '
            f'auto-coder.run --model {safe_model} --system-prompt {safe_prompt}'
        )

        agents_data.append({
            "name": agent.name,
            "description": agent.description,
            "tools": agent.tools if agent.tools else None,
            "command": command  # è™½ç„¶ç”Ÿæˆäº†å‘½ä»¤,ä½†æ¨¡æ¿ä¸­æœªä½¿ç”¨
        })

    # å‡†å¤‡ç¤ºä¾‹ agent æ•°æ®(å–å‰ 2 ä¸ªæˆ–å…¨éƒ¨)
    example_agents_data = []
    example_agents = sorted_agents[:2] if len(sorted_agents) >= 2 else sorted_agents
    for agent in example_agents:
        example_agents_data.append({
            "name": agent.name,
            "example_task": f"Task for {agent.name}"
        })

    # è¿”å›å­—å…¸ä¾› Jinja2 æ¨¡æ¿æ¸²æŸ“
    return {
        "agents_available": True,
        "sorted_agents": agents_data,
        "example_agents": example_agents_data
    }
```

**æ¸²æŸ“ç»“æœç¤ºä¾‹**:

å‡è®¾æœ‰ä¸¤ä¸ª agent: `code_reviewer` å’Œ `translator`,æ¸²æŸ“åçš„æç¤ºè¯ä¸º:

```markdown
## Available Named Sub Agents

The following specialized agents are available for delegation:

### code_reviewer
**Description**: Reviews code for quality, style, and potential bugs
**Available Tools**: read_file, search_files

### translator
**Description**: Translates text between different languages
**Available Tools**: read_file, write_to_file

## How to Use

Use the `run_named_subagents` tool to run multiple agent commands:

### Example: Parallel Execution

<run_named_subagents>
<subagents>
mode: parallel
subagents:
    - name: code_reviewer
      task: Task for code_reviewer
    - name: translator
      task: Task for translator
</subagents>
</run_named_subagents>


### Example: Serial Execution

<run_named_subagents>
<subagents>
mode: serial
subagents:
    - name: agent_name
      task: your task description here
</subagents>
</run_named_subagents>
```

**æ³¨å…¥åˆ° System Prompt**:

```python
# åœ¨ agentic_edit.py çš„ _analyze() æ–¹æ³•ä¸­
def _analyze(self, request: AgenticEditRequest) -> str:
    """
    {{system_prompt}}
    ====
    TOOL USE
    ...
    {{ sub_agents_section }}  # æ³¨å…¥ç‚¹
    ====
    ...
    """
    # åœ¨ analyze() æ–¹æ³•ä¸­å‡†å¤‡æ•°æ®
    sub_agents_section = ""
    if self.agent_manager:
        sub_agents_section = self.agent_manager.render_sub_agents_section.prompt(
            current_model=self.llm.default_model_name
        )

    return {
        "system_prompt": system_prompt,
        "sub_agents_section": sub_agents_section,
        ...
    }
```

**æ€»ç»“**:

AgentManager é€šè¿‡ä»¥ä¸‹æœºåˆ¶ä¸º LLM æä¾› Sub Agents ä¿¡æ¯:

1. **åŠ è½½**: ä»å¤šä¸ªä¼˜å…ˆçº§ç›®å½•åŠ è½½ `.md` agent å®šä¹‰æ–‡ä»¶
2. **è§£æ**: ä½¿ç”¨ AgentParser è§£æ YAML frontmatter å’Œ markdown å†…å®¹
3. **éªŒè¯**: æ£€æŸ¥å¿…éœ€å­—æ®µå’Œå·¥å…·æœ‰æ•ˆæ€§
4. **ä¼˜å…ˆçº§**: é«˜ä¼˜å…ˆçº§ç›®å½•çš„ agent è¦†ç›–ä½ä¼˜å…ˆçº§åŒå agent
5. **æ¸²æŸ“**: é€šè¿‡ Jinja2 æ¨¡æ¿ç”Ÿæˆæ ¼å¼åŒ–çš„ Sub Agents åˆ—è¡¨
6. **æ³¨å…¥**: æ³¨å…¥åˆ° System Prompt çš„ TOOL USE éƒ¨åˆ†ä¹‹å

è¿™ä½¿å¾— LLM å¯ä»¥:
- äº†è§£æœ‰å“ªäº›ä¸“ä¸š sub agent å¯ä»¥å§”æ‰˜ä»»åŠ¡
- çŸ¥é“æ¯ä¸ª sub agent çš„ç”¨é€”å’Œå¯ç”¨å·¥å…·
- é€šè¿‡ `run_named_subagents` å·¥å…·è°ƒç”¨è¿™äº› sub agent

### 2.4.6 å·¥å…·ä½¿ç”¨ä¿¡æ¯æ³¨å…¥

é€šè¿‡ ToolsManager è·å–é¡¹ç›®ä¸­å¯ç”¨çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œå¹¶æ³¨å…¥åˆ°æç¤ºè¯ä¸­ã€‚

---

# ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡å·¥ç¨‹è¯¦è§£

## 3.1 å¤šå±‚æ¬¡ä¸Šä¸‹æ–‡æ„å»º

### 3.1.1 å››å±‚ä¸Šä¸‹æ–‡æ¶æ„

Autocoder é‡‡ç”¨ç²¾å¿ƒè®¾è®¡çš„å››å±‚ä¸Šä¸‹æ–‡ç»“æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: System                      â”‚  ç³»ç»Ÿæç¤ºè¯ï¼ˆè§’è‰²å®šä¹‰ï¼‰
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 2: Documentation               â”‚  æ–‡æ¡£å±‚ï¼ˆé¢„è½®æ¬¡å¯¹è¯ï¼‰
â”‚  - ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£                         â”‚
â”‚  - å·¥å…·ä½¿ç”¨ä¿¡æ¯                         â”‚
â”‚  - ç”¨æˆ·è§„åˆ™                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3: History                     â”‚  å†å²å¯¹è¯ï¼ˆå¸¦ Message IDï¼‰
â”‚  - ä» ConversationManager æ¢å¤        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 4: Current Request             â”‚  å½“å‰ç”¨æˆ·è¯·æ±‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1.2 System å±‚

```python
system_prompt = self._analyze.prompt(request)

conversations = [
    {"role": "system", "content": system_prompt},
]
```

**ç‰¹ç‚¹**ï¼š
- å®šä¹‰ Agent çš„åŸºç¡€èƒ½åŠ›å’Œè§’è‰²
- åŒ…å«æ‰€æœ‰å·¥å…·æè¿°å’Œä½¿ç”¨è§„èŒƒ
- åŒ…å«ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
- åªåœ¨å¯¹è¯å¼€å§‹æ—¶è®¾ç½®ä¸€æ¬¡

### 3.1.3 Documentation å±‚ï¼ˆé¢„è½®æ¬¡å¯¹è¯ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡é¢„è®¾çš„ user-assistant è½®æ¬¡ï¼Œè®© LLM "å­¦ä¹ "æ–‡æ¡£å†…å®¹

**1. ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£**ï¼š
```python
conversations.append({
    "role": "user", 
    "content": library_docs_prompt  # åŒ…å«åº“æ–‡æ¡£å†…å®¹
})
conversations.append({
    "role": "assistant",
    "content": "I have read and understood the third-party library documentation..."
})
```

**2. å·¥å…·ä½¿ç”¨ä¿¡æ¯**ï¼š
```python
conversations.append({
    "role": "user",
    "content": tools_prompt  # é¡¹ç›®ä¸­å¯ç”¨çš„å‘½ä»¤è¡Œå·¥å…·
})
conversations.append({
    "role": "assistant",
    "content": "æˆ‘å·²ç»äº†è§£äº†å½“å‰é¡¹ç›®ä¸­å¯ç”¨çš„å·¥å…·å‘½ä»¤..."
})
```

**3. ç”¨æˆ·è§„åˆ™**ï¼š
```python
conversations.append({
    "role": "user",
    "content": rules_text  # @rulefiles/ ä¸­çš„è§„åˆ™
})
conversations.append({
    "role": "assistant",
    "content": "I have read and understood the rules structure..."
})
```

**ä¼˜åŠ¿**ï¼š
- æ–‡æ¡£å†…å®¹åªåœ¨é¦–æ¬¡å¯¹è¯æ—¶æ³¨å…¥
- ä¸å ç”¨åç»­å¯¹è¯çš„ä¸Šä¸‹æ–‡çª—å£
- LLM é€šè¿‡ assistant å“åº”"è®°ä½"äº†æ–‡æ¡£å†…å®¹
- ç”¨æˆ·çœ‹ä¸åˆ°è¿™äº›é¢„è½®æ¬¡å¯¹è¯

### 3.1.4 History å±‚ï¼ˆå†å²å¯¹è¯æ¢å¤ï¼‰

```python
if current_conversation and current_conversation.get("messages"):
    for message in current_conversation["messages"]:
        conversations.append({
            "role": message["role"],
            "content": append_hint_to_text(
                message["content"],
                f"message_id: {message['message_id'][0:8]}"  # åµŒå…¥ Message ID
            )
        })
```

**ç‰¹ç‚¹**ï¼š
- ä» ConversationManager æ¢å¤å®Œæ•´çš„å†å²å¯¹è¯
- æ¯æ¡æ¶ˆæ¯éƒ½åµŒå…¥ Message IDï¼ˆå‰8ä½ï¼‰
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œç”¨æˆ·å¯ä»¥éšæ—¶ç»§ç»­ä¹‹å‰çš„å¯¹è¯
- Message ID æ–¹ä¾¿åç»­çš„ç²¾ç¡®åˆ é™¤

### 3.1.5 Current Request å±‚

```python
conversations.append({
    "role": "user", 
    "content": request.user_input
})

# ç«‹å³æŒä¹…åŒ–
self.conversation_manager.append_message(
    conversation_id=self.conversation_config.conversation_id,
    role="user",
    content=request.user_input,
    metadata={},
)
```

**ç‰¹ç‚¹**ï¼š
- è¿½åŠ å½“å‰ç”¨æˆ·è¾“å…¥
- ç«‹å³æŒä¹…åŒ–åˆ°æ•°æ®åº“
- å®Œæˆå››å±‚ä¸Šä¸‹æ–‡çš„æ„å»º

## 3.2 Message ID ç³»ç»Ÿ

### 3.2.1 Message ID ç”Ÿæˆ

```python
def append_message(
    self,
    conversation_id: str,
    role: str,
    content: str,
    ...
) -> str:
    """è¿½åŠ æ¶ˆæ¯ï¼Œè¿”å› Message ID"""
    message_id = str(uuid.uuid4())  # ç”Ÿæˆ UUID
    
    message = {
        "message_id": message_id,
        "role": role,
        "content": content,
        ...
    }
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    ...
    
    return message_id
```

### 3.2.2 Message ID åµŒå…¥

```python
def append_hint_to_text(text: str, hint: str) -> str:
    """
    åœ¨æ–‡æœ¬æœ«å°¾åµŒå…¥æç¤ºä¿¡æ¯
    
    æ ¼å¼: åŸå§‹æ–‡æœ¬\n\n[Hint: æç¤ºä¿¡æ¯]
    """
    return f"{text}\n\n[Hint: {hint}]"

# ä½¿ç”¨
content_with_id = append_hint_to_text(
    message["content"],
    f"message_id: {message['message_id'][0:8]}"  # åªä½¿ç”¨å‰8ä½
)
```

**ä¸ºä»€ä¹ˆåªç”¨å‰8ä½ï¼Ÿ**
- èŠ‚çœ tokens
- 8ä½å·²ç»è¶³å¤Ÿå”¯ä¸€ï¼ˆåœ¨å•ä¸ªå¯¹è¯ä¸­ï¼‰
- æ–¹ä¾¿ LLM è¯†åˆ«å’Œå¼•ç”¨

### 3.2.3 åŸºäº Message ID çš„åˆ é™¤

**å·¥å…·å®šä¹‰**ï¼š
```python
class ConversationMessageIdsWriteTool(BaseTool):
    message_ids: str  # "9226b3a4,204e1cd8,abcd1234"
    action: str  # "create", "append", "delete"

# LLM ä½¿ç”¨
"""
<conversation_message_ids_write>
<message_ids>9226b3a4,204e1cd8</message_ids>
<action>create</action>
</conversation_message_ids_write>
"""
```

**åˆ é™¤æµç¨‹**ï¼š
1. LLM è¯†åˆ«ä¸éœ€è¦çš„æ¶ˆæ¯ï¼ˆé€šè¿‡ Message IDï¼‰
2. è°ƒç”¨ conversation_message_ids_write å·¥å…·
3. ä¸‹ä¸€è½®å¯¹è¯æ—¶ï¼ŒAgenticConversationPruner æ‰§è¡Œåˆ é™¤
4. è¢«æ ‡è®°çš„æ¶ˆæ¯ä»å¯¹è¯å†å²ä¸­ç§»é™¤

## 3.3 å¯¹è¯æŒä¹…åŒ–å’Œæ¢å¤

### 3.3.1 ConversationManager å­˜å‚¨ç»“æ„

**æ–‡ä»¶ç³»ç»Ÿå¸ƒå±€**ï¼š
```
.auto-coder/
â””â”€â”€ conversations/
    â”œâ”€â”€ <conversation_id_1>.json
    â”œâ”€â”€ <conversation_id_2>.json
    â”œâ”€â”€ ...
    â””â”€â”€ current_conversations.json  # å½“å‰å¯¹è¯æ˜ å°„
```

**å¯¹è¯æ–‡ä»¶æ ¼å¼**ï¼š
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "name": "Conversation abc123",
  "description": "ç”¨æˆ·æè¿°",
  "created_at": "2025-01-15T10:30:00",
  "updated_at": "2025-01-15T11:45:00",
  "metadata": {},
  "messages": [
    {
      "message_id": "123e4567-e89b-12d3-a456-426614174000",
      "role": "user",
      "content": "è¯·å¸®æˆ‘å®ç°ä¸€ä¸ªåŠŸèƒ½",
      "created_at": "2025-01-15T10:30:00",
      "metadata": {},
      "llm_metadata": null
    },
    {
      "message_id": "987fcdeb-51a2-43e8-b7c9-123456789abc",
      "role": "assistant",
      "content": "<thinking>åˆ†æéœ€æ±‚...</thinking>\nå¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å®ç°ã€‚\n<read_file>...",
      "created_at": "2025-01-15T10:30:15",
      "metadata": {},
      "llm_metadata": {
        "model_name": "claude-3-5-sonnet-20241022",
        "input_tokens": 1234,
        "output_tokens": 567,
        "input_cost": 0.00123,
        "output_cost": 0.00045,
        "conversation_round": 1
      }
    }
  ]
}
```

### 3.3.2 å‘½åç©ºé—´éš”ç¦»

**ç”¨é€”**ï¼šæ”¯æŒå¤šé¡¹ç›®åŒæ—¶å·¥ä½œ

```python
# è®¾ç½® project_a çš„å½“å‰å¯¹è¯
manager.set_current_conversation(conv_id_a, namespace="project_a")

# è®¾ç½® project_b çš„å½“å‰å¯¹è¯
manager.set_current_conversation(conv_id_b, namespace="project_b")

# è·å– project_a çš„å½“å‰å¯¹è¯
current_conv_a = manager.get_current_conversation_id(namespace="project_a")

# åˆ—å‡ºæ‰€æœ‰å‘½åç©ºé—´
namespaces = manager.list_namespaces()
# ["default", "project_a", "project_b"]
```

**current_conversations.json æ ¼å¼**ï¼š
```json
{
  "default": "550e8400-e29b-41d4-a716-446655440000",
  "project_a": "661f9511-f3ac-52e5-b827-557766551111",
  "project_b": "772g0622-g4bd-63f6-c938-668877662222"
}
```

### 3.3.3 Token ç»Ÿè®¡å›å†™

```python
# 1. LLM å“åº”æ—¶è·å– token ç»Ÿè®¡
metadata = last_response.metadata
input_tokens = metadata.input_tokens_count
output_tokens = metadata.generated_tokens_count

# 2. è®¡ç®—æˆæœ¬
model_info = llms_utils.get_model_info(model_name)
input_cost = (input_tokens * model_info["input_price"]) / 1000000
output_cost = (output_tokens * model_info["output_price"]) / 1000000

# 3. åˆ›å»º LLM metadata
llm_metadata = {
    "model_name": model_name,
    "input_tokens": input_tokens,
    "output_tokens": output_tokens,
    "input_cost": input_cost,
    "output_cost": output_cost,
    "conversation_round": current_round
}

# 4. å›å†™åˆ°æ¶ˆæ¯
self.conversation_manager.update_message(
    conversation_id=conv_id,
    message_id=assistant_message_id,
    llm_metadata=llm_metadata
)
```

#### 3.3.1 ConversationManager å•ä¾‹æ¨¡å¼å®ç°(æ‰©å±•)

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/conversations/get_conversation_manager.py`

**å•ä¾‹å®ç°ç±»**:

```python
class ConversationManagerSingleton:
    """å¯¹è¯ç®¡ç†å™¨çš„å•ä¾‹ç±»,ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹"""

    # ç±»çº§åˆ«å˜é‡,å­˜å‚¨å•ä¾‹å®ä¾‹
    _instance: Optional[PersistConversationManager] = None
    # çº¿ç¨‹é”,ç¡®ä¿çº¿ç¨‹å®‰å…¨
    _lock = threading.Lock()
    # å­˜å‚¨å½“å‰é…ç½®
    _config: Optional[ConversationManagerConfig] = None

    @classmethod
    def get_instance(
        cls,
        config: Optional[ConversationManagerConfig] = None
    ) -> PersistConversationManager:
        """
        è·å–å¯¹è¯ç®¡ç†å™¨å®ä¾‹(åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼)

        Args:
            config: é…ç½®å¯¹è±¡,å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®

        Returns:
            PersistConversationManagerå®ä¾‹
        """
        # ç¬¬ä¸€æ¬¡æ£€æŸ¥(æ— é”,æ€§èƒ½ä¼˜åŒ–)
        if cls._instance is None:
            # è·å–é”
            with cls._lock:
                # ç¬¬äºŒæ¬¡æ£€æŸ¥(æŒæœ‰é”,ä¿è¯çº¿ç¨‹å®‰å…¨)
                if cls._instance is None:
                    if config is None:
                        config = cls._get_default_config()
                    cls._config = config
                    # åˆ›å»ºå”¯ä¸€å®ä¾‹
                    cls._instance = PersistConversationManager(config)
        return cls._instance
```

**åŒé‡æ£€æŸ¥é”å®š(Double-Checked Locking)è§£æ**:

1. **ç¬¬ä¸€æ¬¡æ£€æŸ¥** (`if cls._instance is None`):
   - åœ¨é”å¤–è¿›è¡Œ,é¿å…æ¯æ¬¡è°ƒç”¨éƒ½åŠ é”
   - å¦‚æœå®ä¾‹å·²åˆ›å»º,ç›´æ¥è¿”å›,æ€§èƒ½æœ€ä¼˜

2. **è·å–é”** (`with cls._lock`):
   - åªæœ‰ç¬¬ä¸€æ¬¡æ£€æŸ¥å¤±è´¥æ—¶æ‰è·å–é”
   - ä¿è¯å¤šçº¿ç¨‹ç¯å¢ƒä¸‹åªåˆ›å»ºä¸€ä¸ªå®ä¾‹

3. **ç¬¬äºŒæ¬¡æ£€æŸ¥** (`if cls._instance is None`):
   - åœ¨é”å†…å†æ¬¡æ£€æŸ¥,é˜²æ­¢ç«æ€æ¡ä»¶
   - ä¾‹å¦‚:çº¿ç¨‹Aå’ŒBåŒæ—¶é€šè¿‡ç¬¬ä¸€æ¬¡æ£€æŸ¥,Aè·å¾—é”åˆ›å»ºå®ä¾‹,Bç­‰å¾…é”é‡Šæ”¾åå†æ¬¡æ£€æŸ¥,å‘ç°å®ä¾‹å·²åˆ›å»º,ç›´æ¥è¿”å›

**é»˜è®¤é…ç½®è·å–**:

```python
@classmethod
def _get_default_config(cls) -> ConversationManagerConfig:
    """è·å–é»˜è®¤é…ç½®"""
    # é»˜è®¤å­˜å‚¨è·¯å¾„ä¸ºå½“å‰å·¥ä½œç›®å½•ä¸‹çš„ .auto-coder/conversations
    default_storage_path = os.path.join(os.getcwd(), ".auto-coder", "conversations")

    return ConversationManagerConfig(
        storage_path=default_storage_path,  # å­˜å‚¨è·¯å¾„
        max_cache_size=100,                 # æœ€å¤§ç¼“å­˜å¯¹è¯æ•°
        cache_ttl=300.0,                    # ç¼“å­˜ç”Ÿå­˜æ—¶é—´(ç§’)
        lock_timeout=10.0,                  # æ–‡ä»¶é”è¶…æ—¶æ—¶é—´
        backup_enabled=True,                # æ˜¯å¦å¯ç”¨å¤‡ä»½
        backup_interval=3600.0,             # å¤‡ä»½é—´éš”(ç§’)
        max_backups=10                      # æœ€å¤§å¤‡ä»½æ•°
    )
```

**å…¨å±€è®¿é—®å‡½æ•°**:

```python
def get_conversation_manager(
    config: Optional[ConversationManagerConfig] = None
) -> PersistConversationManager:
    """
    è·å–å…¨å±€å¯¹è¯ç®¡ç†å™¨å®ä¾‹

    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·å‡½æ•°,å†…éƒ¨ä½¿ç”¨å•ä¾‹æ¨¡å¼ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹ã€‚
    é¦–æ¬¡è°ƒç”¨æ—¶ä¼šåˆ›å»ºå®ä¾‹,åç»­è°ƒç”¨ä¼šè¿”å›åŒä¸€ä¸ªå®ä¾‹ã€‚

    Args:
        config: å¯é€‰çš„é…ç½®å¯¹è±¡ã€‚å¦‚æœä¸ºNone,å°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚
               æ³¨æ„:åªæœ‰åœ¨é¦–æ¬¡è°ƒç”¨æ—¶,configå‚æ•°æ‰ä¼šç”Ÿæ•ˆã€‚

    Returns:
        PersistConversationManager: å¯¹è¯ç®¡ç†å™¨å®ä¾‹
    """
    return ConversationManagerSingleton.get_instance(config)
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# æ–¹å¼1:ä½¿ç”¨é»˜è®¤é…ç½®
manager = get_conversation_manager()

# æ–¹å¼2:ä½¿ç”¨è‡ªå®šä¹‰é…ç½®(ä»…åœ¨é¦–æ¬¡è°ƒç”¨æ—¶ç”Ÿæ•ˆ)
config = ConversationManagerConfig(
    storage_path="./my_conversations",
    max_cache_size=200,
    default_namespace="my_project"
)
manager = get_conversation_manager(config)

# æ–¹å¼3:åœ¨ä¸åŒä½ç½®è·å–åŒä¸€å®ä¾‹
manager_a = get_conversation_manager()  # åŒä¸€å®ä¾‹
manager_b = get_conversation_manager()  # åŒä¸€å®ä¾‹
assert manager_a is manager_b  # True
```

## 3.3.1 å¯¹è¯æŒä¹…åŒ–å’Œæ¢å¤(æ‰©å±•) - ConversationManager å•ä¾‹å®ç°

### 3.3.1.1 å•ä¾‹æ¨¡å¼çš„ Double-Check Locking å®ç°

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/conversations/get_conversation_manager.py`

å¯¹è¯ç®¡ç†å™¨é‡‡ç”¨çº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿æ•´ä¸ªåº”ç”¨ç¨‹åºä¸­åªæœ‰ä¸€ä¸ª `PersistConversationManager` å®ä¾‹ï¼Œé¿å…å¤šå®ä¾‹å¯¼è‡´çš„æ•°æ®ä¸ä¸€è‡´é—®é¢˜ã€‚

**å•ä¾‹ç±»å®ç°**:

```python
class ConversationManagerSingleton:
    """å¯¹è¯ç®¡ç†å™¨çš„å•ä¾‹ç±»ï¼Œç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹"""

    # ç±»çº§åˆ«çš„å®ä¾‹å˜é‡ï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
    _instance: Optional[PersistConversationManager] = None
    _lock = threading.Lock()  # çº¿ç¨‹é”ï¼Œä¿è¯çº¿ç¨‹å®‰å…¨
    _config: Optional[ConversationManagerConfig] = None  # å½“å‰ä½¿ç”¨çš„é…ç½®

    @classmethod
    def get_instance(cls, config: Optional[ConversationManagerConfig] = None) -> PersistConversationManager:
        """
        è·å–å¯¹è¯ç®¡ç†å™¨å®ä¾‹ï¼ˆDouble-Check Locking æ¨¡å¼ï¼‰

        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®

        Returns:
            PersistConversationManager å®ä¾‹
        """
        # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼šå¿«é€Ÿè·¯å¾„ï¼Œé¿å…ä¸å¿…è¦çš„é”å¼€é”€
        if cls._instance is None:
            # è·å–é”ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
            with cls._lock:
                # ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼šé˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶é€šè¿‡ç¬¬ä¸€æ¬¡æ£€æŸ¥
                if cls._instance is None:
                    # è·å–é…ç½®
                    if config is None:
                        config = cls._get_default_config()

                    # ä¿å­˜é…ç½®å¹¶åˆ›å»ºå®ä¾‹
                    cls._config = config
                    cls._instance = PersistConversationManager(config)

        return cls._instance
```

**Double-Check Locking åŸç†**:

1. **ç¬¬ä¸€æ¬¡æ£€æŸ¥** (`if cls._instance is None`):
   - åœ¨é”å¤–æ£€æŸ¥å®ä¾‹æ˜¯å¦å·²åˆ›å»º
   - å¦‚æœå·²åˆ›å»ºï¼Œç›´æ¥è¿”å›ï¼Œé¿å…é”çš„å¼€é”€ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
   - è¿™æ˜¯æ€§èƒ½ä¼˜åŒ–çš„å…³é”®

2. **è·å–é”** (`with cls._lock`):
   - å¦‚æœç¬¬ä¸€æ¬¡æ£€æŸ¥å‘ç°å®ä¾‹ä¸å­˜åœ¨ï¼Œè·å–é”
   - ç¡®ä¿åŒä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ªçº¿ç¨‹èƒ½è¿›å…¥ä¸´ç•ŒåŒº

3. **ç¬¬äºŒæ¬¡æ£€æŸ¥** (`if cls._instance is None`):
   - åœ¨é”å†…å†æ¬¡æ£€æŸ¥å®ä¾‹æ˜¯å¦å·²åˆ›å»º
   - é˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶é€šè¿‡ç¬¬ä¸€æ¬¡æ£€æŸ¥åé‡å¤åˆ›å»ºå®ä¾‹
   - è¿™æ˜¯æ­£ç¡®æ€§ä¿è¯çš„å…³é”®

4. **åˆ›å»ºå®ä¾‹**:
   - å¦‚æœç¡®å®ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ä¾‹å¹¶ä¿å­˜é…ç½®
   - é‡Šæ”¾é”åï¼Œåç»­è°ƒç”¨ä¼šèµ°å¿«é€Ÿè·¯å¾„

**é»˜è®¤é…ç½®ç”Ÿæˆ**:

```python
@classmethod
def _get_default_config(cls) -> ConversationManagerConfig:
    """
    è·å–é»˜è®¤é…ç½®

    é»˜è®¤é…ç½®è¯´æ˜ï¼š
    - å­˜å‚¨è·¯å¾„ï¼šå½“å‰å·¥ä½œç›®å½•/.auto-coder/conversations
    - ç¼“å­˜å¤§å°ï¼š100 ä¸ªå¯¹è¯
    - ç¼“å­˜ TTLï¼š300 ç§’ï¼ˆ5 åˆ†é’Ÿï¼‰
    - é”è¶…æ—¶ï¼š10 ç§’
    - å¤‡ä»½åŠŸèƒ½ï¼šå¯ç”¨
    - å¤‡ä»½é—´éš”ï¼š3600 ç§’ï¼ˆ1 å°æ—¶ï¼‰
    - æœ€å¤§å¤‡ä»½æ•°ï¼š10 ä¸ª
    """
    default_storage_path = os.path.join(os.getcwd(), ".auto-coder", "conversations")

    return ConversationManagerConfig(
        storage_path=default_storage_path,
        max_cache_size=100,
        cache_ttl=300.0,
        lock_timeout=10.0,
        backup_enabled=True,
        backup_interval=3600.0,
        max_backups=10
    )
```

**é‡ç½®å®ä¾‹æ–¹æ³•**ï¼ˆç”¨äºæµ‹è¯•æˆ–é…ç½®æ›´æ”¹ï¼‰:

```python
@classmethod
def reset_instance(cls, config: Optional[ConversationManagerConfig] = None):
    """
    é‡ç½®å®ä¾‹ï¼Œç”¨äºæµ‹è¯•æˆ–é…ç½®æ›´æ”¹æ—¶

    Args:
        config: æ–°çš„é…ç½®å¯¹è±¡
    """
    with cls._lock:
        # æ¸…ç©ºå½“å‰å®ä¾‹å’Œé…ç½®
        cls._instance = None
        cls._config = None

        # å¦‚æœæä¾›äº†æ–°é…ç½®ï¼Œç«‹å³åˆ›å»ºæ–°å®ä¾‹
        if config is not None:
            cls._instance = PersistConversationManager(config)
            cls._config = config
```

### 3.3.1.2 ConversationManagerConfig é…ç½®é¡¹è¯¦è§£

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/conversations/config.py`

ConversationManagerConfig æ˜¯ä¸€ä¸ª dataclassï¼Œå®šä¹‰äº†å¯¹è¯ç®¡ç†å™¨çš„æ‰€æœ‰é…ç½®å‚æ•°ï¼Œå¹¶æä¾›äº†éªŒè¯ã€åºåˆ—åŒ–ã€ä»ç¯å¢ƒå˜é‡åŠ è½½ç­‰åŠŸèƒ½ã€‚

**å®Œæ•´é…ç½®é¡¹å®šä¹‰**:

```python
@dataclass
class ConversationManagerConfig:
    """å¯¹è¯ç®¡ç†å™¨é…ç½®ç±»"""

    # å­˜å‚¨è·¯å¾„ï¼šå¯¹è¯æ–‡ä»¶çš„å­˜å‚¨ç›®å½•
    storage_path: str = "./.auto-coder/conversations"

    # ç¼“å­˜ç›¸å…³
    max_cache_size: int = 100      # å†…å­˜ç¼“å­˜çš„æœ€å¤§å¯¹è¯æ•°é‡
    cache_ttl: float = 300.0       # ç¼“å­˜ TTLï¼ˆç§’ï¼‰ï¼Œè¶…æ—¶åä»ç£ç›˜é‡æ–°åŠ è½½

    # å¹¶å‘æ§åˆ¶
    lock_timeout: float = 10.0     # æ–‡ä»¶é”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    # å¤‡ä»½ç›¸å…³
    backup_enabled: bool = True    # æ˜¯å¦å¯ç”¨è‡ªåŠ¨å¤‡ä»½
    backup_interval: float = 3600.0  # å¤‡ä»½é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 1 å°æ—¶
    max_backups: int = 10          # æœ€å¤§å¤‡ä»½æ–‡ä»¶æ•°é‡

    # å…¶ä»–åŠŸèƒ½
    enable_compression: bool = False  # æ˜¯å¦å¯ç”¨å¯¹è¯å‹ç¼©ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
    log_level: str = "INFO"        # æ—¥å¿—çº§åˆ«
    default_namespace: Optional[str] = None  # é»˜è®¤å‘½åç©ºé—´

    def __post_init__(self):
        """é…ç½®éªŒè¯ï¼ˆåœ¨å®ä¾‹åŒ–åè‡ªåŠ¨è°ƒç”¨ï¼‰"""
        self._validate()
```

**é…ç½®éªŒè¯é€»è¾‘**:

```python
def _validate(self):
    """éªŒè¯é…ç½®æ•°æ®çš„æœ‰æ•ˆæ€§"""

    # éªŒè¯å­˜å‚¨è·¯å¾„
    if not self.storage_path or not isinstance(self.storage_path, str):
        raise ValueError("å­˜å‚¨è·¯å¾„ä¸èƒ½ä¸ºç©º")

    # éªŒè¯ç¼“å­˜å¤§å°ï¼ˆå¿…é¡»æ˜¯æ­£æ•´æ•°ï¼‰
    if not isinstance(self.max_cache_size, int) or self.max_cache_size <= 0:
        raise ValueError("ç¼“å­˜å¤§å°å¿…é¡»æ˜¯æ­£æ•´æ•°")

    # éªŒè¯ç¼“å­˜ TTLï¼ˆå¿…é¡»æ˜¯æ­£æ•°ï¼‰
    if not isinstance(self.cache_ttl, (int, float)) or self.cache_ttl <= 0:
        raise ValueError("ç¼“å­˜ TTL å¿…é¡»æ˜¯æ­£æ•°")

    # éªŒè¯é”è¶…æ—¶æ—¶é—´
    if not isinstance(self.lock_timeout, (int, float)) or self.lock_timeout <= 0:
        raise ValueError("é”è¶…æ—¶æ—¶é—´å¿…é¡»æ˜¯æ­£æ•°")

    # éªŒè¯å¤‡ä»½é—´éš”
    if not isinstance(self.backup_interval, (int, float)) or self.backup_interval <= 0:
        raise ValueError("å¤‡ä»½é—´éš”å¿…é¡»æ˜¯æ­£æ•°")

    # éªŒè¯æœ€å¤§å¤‡ä»½æ•°
    if not isinstance(self.max_backups, int) or self.max_backups <= 0:
        raise ValueError("æœ€å¤§å¤‡ä»½æ•°å¿…é¡»æ˜¯æ­£æ•´æ•°")

    # éªŒè¯æ—¥å¿—çº§åˆ«
    valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
    if self.log_level not in valid_levels:
        raise ValueError(f"æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: {self.log_level}ï¼Œæœ‰æ•ˆçº§åˆ«: {valid_levels}")

    # éªŒè¯é»˜è®¤å‘½åç©ºé—´
    if self.default_namespace is not None and not isinstance(self.default_namespace, str):
        raise ValueError("é»˜è®¤å‘½åç©ºé—´å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ– None")
```

**ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®**:

```python
@classmethod
def from_env(cls, prefix: str = "CONVERSATION_") -> "ConversationManagerConfig":
    """
    ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®

    Args:
        prefix: ç¯å¢ƒå˜é‡å‰ç¼€ï¼Œé»˜è®¤ "CONVERSATION_"

    ç¯å¢ƒå˜é‡æ˜ å°„ï¼š
        CONVERSATION_STORAGE_PATH -> storage_path
        CONVERSATION_MAX_CACHE_SIZE -> max_cache_size
        CONVERSATION_CACHE_TTL -> cache_ttl
        CONVERSATION_LOCK_TIMEOUT -> lock_timeout
        CONVERSATION_BACKUP_ENABLED -> backup_enabled
        CONVERSATION_BACKUP_INTERVAL -> backup_interval
        CONVERSATION_MAX_BACKUPS -> max_backups
        CONVERSATION_ENABLE_COMPRESSION -> enable_compression
        CONVERSATION_LOG_LEVEL -> log_level
        CONVERSATION_DEFAULT_NAMESPACE -> default_namespace

    Returns:
        ConversationManagerConfig å®ä¾‹
    """
    config = cls()  # å…ˆåˆ›å»ºé»˜è®¤é…ç½®

    # ç¯å¢ƒå˜é‡åˆ°å±æ€§çš„æ˜ å°„
    env_mapping = {
        f"{prefix}STORAGE_PATH": "storage_path",
        f"{prefix}MAX_CACHE_SIZE": "max_cache_size",
        f"{prefix}CACHE_TTL": "cache_ttl",
        f"{prefix}LOCK_TIMEOUT": "lock_timeout",
        f"{prefix}BACKUP_ENABLED": "backup_enabled",
        f"{prefix}BACKUP_INTERVAL": "backup_interval",
        f"{prefix}MAX_BACKUPS": "max_backups",
        f"{prefix}ENABLE_COMPRESSION": "enable_compression",
        f"{prefix}LOG_LEVEL": "log_level",
        f"{prefix}DEFAULT_NAMESPACE": "default_namespace"
    }

    # éå†ç¯å¢ƒå˜é‡ï¼Œè¦†ç›–é»˜è®¤å€¼
    for env_key, attr_name in env_mapping.items():
        env_value = os.environ.get(env_key)
        if env_value is not None:
            # ç±»å‹è½¬æ¢
            try:
                if attr_name in ["max_cache_size", "max_backups"]:
                    value = int(env_value)
                elif attr_name in ["cache_ttl", "lock_timeout", "backup_interval"]:
                    value = float(env_value)
                elif attr_name in ["backup_enabled", "enable_compression"]:
                    # å¸ƒå°”å€¼è§£æï¼štrue/1/yes/on -> True
                    value = env_value.lower() in ["true", "1", "yes", "on"]
                else:
                    value = env_value

                setattr(config, attr_name, value)
            except (ValueError, TypeError) as e:
                raise ValueError(f"ç¯å¢ƒå˜é‡ {env_key} çš„å€¼ '{env_value}' æ— æ•ˆ: {e}")

    # é‡æ–°éªŒè¯ï¼ˆç¡®ä¿ç¯å¢ƒå˜é‡è¦†ç›–åé…ç½®ä»ç„¶æœ‰æ•ˆï¼‰
    config._validate()

    return config
```

**é…ç½®çš„åºåˆ—åŒ–ä¸ååºåˆ—åŒ–**:

```python
def to_dict(self) -> Dict[str, Any]:
    """è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äº JSON åºåˆ—åŒ–ï¼‰"""
    return {
        "storage_path": self.storage_path,
        "max_cache_size": self.max_cache_size,
        "cache_ttl": self.cache_ttl,
        "lock_timeout": self.lock_timeout,
        "backup_enabled": self.backup_enabled,
        "backup_interval": self.backup_interval,
        "max_backups": self.max_backups,
        "enable_compression": self.enable_compression,
        "log_level": self.log_level,
        "default_namespace": self.default_namespace
    }

@classmethod
def from_dict(cls, data: Dict[str, Any]) -> "ConversationManagerConfig":
    """ä»å­—å…¸åˆ›å»ºé…ç½®ï¼ˆç”¨äº JSON ååºåˆ—åŒ–ï¼‰"""
    config = cls()  # å…ˆåˆ›å»ºé»˜è®¤é…ç½®

    # æ›´æ–°é…ç½®å­—æ®µ
    for key, value in data.items():
        if hasattr(config, key):
            setattr(config, key, value)

    # é‡æ–°éªŒè¯
    config._validate()

    return config

def save_to_file(self, file_path: str):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    os.makedirs(os.path.dirname(file_path), exist_ok=True)

    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)

@classmethod
def load_from_file(cls, file_path: str) -> "ConversationManagerConfig":
    """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        return cls.from_dict(data)
    except json.JSONDecodeError as e:
        raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
```

### 3.3.1.3 æ ¸å¿ƒæ–¹æ³•å®ç°è¦ç‚¹

**ä¾¿æ·å‡½æ•°å°è£…**:

```python
def get_conversation_manager(config: Optional[ConversationManagerConfig] = None) -> PersistConversationManager:
    """
    è·å–å…¨å±€å¯¹è¯ç®¡ç†å™¨å®ä¾‹ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·å‡½æ•°ï¼Œå†…éƒ¨ä½¿ç”¨å•ä¾‹æ¨¡å¼ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹ã€‚
    é¦–æ¬¡è°ƒç”¨æ—¶ä¼šåˆ›å»ºå®ä¾‹ï¼Œåç»­è°ƒç”¨ä¼šè¿”å›åŒä¸€ä¸ªå®ä¾‹ã€‚

    Args:
        config: å¯é€‰çš„é…ç½®å¯¹è±¡ã€‚å¦‚æœä¸º Noneï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚
               æ³¨æ„ï¼šåªæœ‰åœ¨é¦–æ¬¡è°ƒç”¨æ—¶ï¼Œconfig å‚æ•°æ‰ä¼šç”Ÿæ•ˆã€‚

    Returns:
        PersistConversationManager: å¯¹è¯ç®¡ç†å™¨å®ä¾‹
    """
    return ConversationManagerSingleton.get_instance(config)

def reset_conversation_manager(config: Optional[ConversationManagerConfig] = None):
    """
    é‡ç½®å…¨å±€å¯¹è¯ç®¡ç†å™¨å®ä¾‹

    ç”¨äºæµ‹è¯•æˆ–éœ€è¦æ›´æ”¹é…ç½®æ—¶é‡ç½®å®ä¾‹ã€‚

    Args:
        config: æ–°çš„é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸º None åˆ™åœ¨ä¸‹æ¬¡è°ƒç”¨ get_conversation_manager æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
    """
    ConversationManagerSingleton.reset_instance(config)
```

**å‘½åç©ºé—´ç›¸å…³çš„ä¾¿æ·å‡½æ•°**:

```python
def get_current_conversation_id_with_namespace(namespace: Optional[str] = None) -> Optional[str]:
    """è·å–æŒ‡å®šå‘½åç©ºé—´çš„å½“å‰å¯¹è¯ ID"""
    manager = get_conversation_manager()
    return manager.get_current_conversation_id(namespace)

def set_current_conversation_with_namespace(conversation_id: str, namespace: Optional[str] = None) -> bool:
    """è®¾ç½®æŒ‡å®šå‘½åç©ºé—´çš„å½“å‰å¯¹è¯"""
    manager = get_conversation_manager()
    return manager.set_current_conversation(conversation_id, namespace)

def list_conversation_namespaces() -> List[Optional[str]]:
    """åˆ—å‡ºæ‰€æœ‰å·²ä½¿ç”¨çš„å‘½åç©ºé—´"""
    manager = get_conversation_manager()
    return manager.list_namespaces()
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# åœºæ™¯ 1ï¼šä½¿ç”¨é»˜è®¤é…ç½®
manager = get_conversation_manager()
conv_id = manager.create_conversation(name="æµ‹è¯•å¯¹è¯", description="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¯¹è¯")

# åœºæ™¯ 2ï¼šä½¿ç”¨è‡ªå®šä¹‰é…ç½®
custom_config = ConversationManagerConfig(
    storage_path="./my_conversations",
    max_cache_size=200,
    backup_enabled=False
)
manager = get_conversation_manager(custom_config)

# åœºæ™¯ 3ï¼šä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
#   export CONVERSATION_STORAGE_PATH="./custom_path"
#   export CONVERSATION_MAX_CACHE_SIZE="50"
env_config = ConversationManagerConfig.from_env()
reset_conversation_manager(env_config)
manager = get_conversation_manager()

# åœºæ™¯ 4ï¼šä½¿ç”¨å‘½åç©ºé—´ç®¡ç†å¤šé¡¹ç›®
manager.set_current_conversation(conv_id, namespace="project_a")
manager.set_current_conversation(another_conv_id, namespace="project_b")

current_a = get_current_conversation_id_with_namespace("project_a")
current_b = get_current_conversation_id_with_namespace("project_b")
```

**è®¾è®¡è¦ç‚¹æ€»ç»“**:

1. **çº¿ç¨‹å®‰å…¨**: Double-Check Locking ç¡®ä¿å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„å®‰å…¨æ€§
2. **é…ç½®çµæ´»**: æ”¯æŒé»˜è®¤é…ç½®ã€è‡ªå®šä¹‰é…ç½®ã€ç¯å¢ƒå˜é‡é…ç½®ã€æ–‡ä»¶é…ç½®
3. **éªŒè¯ä¸¥æ ¼**: æ‰€æœ‰é…ç½®é¡¹éƒ½æœ‰ä¸¥æ ¼çš„ç±»å‹å’Œå€¼éªŒè¯
4. **å•ä¾‹æ¨¡å¼**: ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹ï¼Œé¿å…æ•°æ®ä¸ä¸€è‡´
5. **å‘½åç©ºé—´**: æ”¯æŒå¤šé¡¹ç›®éš”ç¦»ï¼Œä¸åŒé¡¹ç›®å¯ä»¥æœ‰ç‹¬ç«‹çš„å½“å‰å¯¹è¯
6. **æ˜“ç”¨æ€§**: æä¾›ä¸°å¯Œçš„ä¾¿æ·å‡½æ•°ï¼Œç®€åŒ–å¸¸è§æ“ä½œ

---
#### 3.3.2 ConversationManagerConfig è¯¦è§£(æ‰©å±•)

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/conversations/config.py`

**é…ç½®ç±»å®šä¹‰**:

```python
@dataclass
class ConversationManagerConfig:
    """å¯¹è¯ç®¡ç†å™¨é…ç½®ç±»"""

    # å­˜å‚¨é…ç½®
    storage_path: str = "./.auto-coder/conversations"  # å¯¹è¯å­˜å‚¨è·¯å¾„
    max_cache_size: int = 100                         # æœ€å¤§ç¼“å­˜å¯¹è¯æ•°
    cache_ttl: float = 300.0                          # ç¼“å­˜ç”Ÿå­˜æ—¶é—´(ç§’)

    # å¹¶å‘æ§åˆ¶
    lock_timeout: float = 10.0                        # æ–‡ä»¶é”è¶…æ—¶æ—¶é—´(ç§’)

    # å¤‡ä»½é…ç½®
    backup_enabled: bool = True                       # æ˜¯å¦å¯ç”¨å¤‡ä»½
    backup_interval: float = 3600.0                   # å¤‡ä»½é—´éš”(ç§’)
    max_backups: int = 10                             # æœ€å¤§å¤‡ä»½æ•°

    # å…¶ä»–é…ç½®
    enable_compression: bool = False                  # æ˜¯å¦å¯ç”¨å‹ç¼©
    log_level: str = "INFO"                           # æ—¥å¿—çº§åˆ«
    default_namespace: Optional[str] = None           # é»˜è®¤å‘½åç©ºé—´

    def __post_init__(self):
        """é…ç½®éªŒè¯(dataclassè‡ªåŠ¨è°ƒç”¨)"""
        self._validate()

    def _validate(self):
        """éªŒè¯é…ç½®æ•°æ®"""
        # éªŒè¯å­˜å‚¨è·¯å¾„
        if not self.storage_path or not isinstance(self.storage_path, str):
            raise ValueError("å­˜å‚¨è·¯å¾„ä¸èƒ½ä¸ºç©º")

        # éªŒè¯ç¼“å­˜å¤§å°
        if not isinstance(self.max_cache_size, int) or self.max_cache_size <= 0:
            raise ValueError("ç¼“å­˜å¤§å°å¿…é¡»æ˜¯æ­£æ•´æ•°")

        # éªŒè¯ç¼“å­˜TTL
        if not isinstance(self.cache_ttl, (int, float)) or self.cache_ttl <= 0:
            raise ValueError("ç¼“å­˜TTLå¿…é¡»æ˜¯æ­£æ•°")

        # éªŒè¯é”è¶…æ—¶
        if not isinstance(self.lock_timeout, (int, float)) or self.lock_timeout <= 0:
            raise ValueError("é”è¶…æ—¶æ—¶é—´å¿…é¡»æ˜¯æ­£æ•°")

        # éªŒè¯æ—¥å¿—çº§åˆ«
        valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        if self.log_level not in valid_levels:
            raise ValueError(f"æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: {self.log_level}ï¼Œæœ‰æ•ˆçº§åˆ«: {valid_levels}")
```

**é…ç½®çš„å¤šç§åˆ›å»ºæ–¹å¼**:

```python
# 1. ä½¿ç”¨é»˜è®¤å€¼
config = ConversationManagerConfig()

# 2. ä»å­—å…¸åˆ›å»º
config_dict = {
    "storage_path": "./custom_path",
    "max_cache_size": 200,
    "cache_ttl": 600.0
}
config = ConversationManagerConfig.from_dict(config_dict)

# 3. ä»ç¯å¢ƒå˜é‡åˆ›å»º
# ç¯å¢ƒå˜é‡æ ¼å¼: CONVERSATION_<å­—æ®µåå¤§å†™>
# ä¾‹å¦‚: CONVERSATION_STORAGE_PATH=/path/to/conversations
os.environ["CONVERSATION_STORAGE_PATH"] = "/path/to/conversations"
os.environ["CONVERSATION_MAX_CACHE_SIZE"] = "200"
config = ConversationManagerConfig.from_env()

# 4. ä»æ–‡ä»¶åŠ è½½
config.save_to_file("config.json")  # ä¿å­˜åˆ°æ–‡ä»¶
config = ConversationManagerConfig.load_from_file("config.json")  # ä»æ–‡ä»¶åŠ è½½

# 5. åŠ¨æ€æ›´æ–°é…ç½®
config.update(max_cache_size=300, cache_ttl=900.0)
```

#### 3.3.3 create_conversation æµç¨‹(æ‰©å±•)

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/conversations/manager.py`

**å®Œæ•´æµç¨‹**:

```python
def create_conversation(
    self,
    name: str,
    description: Optional[str] = None,
    initial_messages: Optional[List[Dict[str, Any]]] = None,
    metadata: Optional[Dict[str, Any]] = None,
    conversation_id: Optional[str] = None
) -> str:
    """
    åˆ›å»ºæ–°å¯¹è¯

    Args:
        name: å¯¹è¯åç§°
        description: å¯é€‰æè¿°
        initial_messages: å¯é€‰çš„åˆå§‹æ¶ˆæ¯åˆ—è¡¨
        metadata: å¯é€‰çš„å…ƒæ•°æ®å­—å…¸
        conversation_id: å¯é€‰çš„å¯¹è¯IDã€‚å¦‚æœä¸æä¾›,å°†è‡ªåŠ¨ç”ŸæˆUUID

    Returns:
        åˆ›å»ºçš„å¯¹è¯ID

    Raises:
        ConversationManagerError: å¦‚æœå¯¹è¯åˆ›å»ºå¤±è´¥
    """
    try:
        # æ­¥éª¤1: åˆ›å»º Conversation å¯¹è±¡
        if conversation_id:
            # æ£€æŸ¥å¯¹è¯IDæ˜¯å¦å·²å­˜åœ¨
            if self.storage.conversation_exists(conversation_id):
                raise ConversationManagerError(
                    f"Conversation with ID {conversation_id} already exists"
                )

            conversation = Conversation(
                name=name,
                description=description,
                metadata=metadata or {},
                conversation_id=conversation_id  # ä½¿ç”¨æŒ‡å®šçš„ID
            )
        else:
            # è‡ªåŠ¨ç”ŸæˆUUID
            conversation = Conversation(
                name=name,
                description=description,
                metadata=metadata or {}
            )

        # æ­¥éª¤2: æ·»åŠ åˆå§‹æ¶ˆæ¯
        if initial_messages:
            for msg_data in initial_messages:
                message = ConversationMessage(
                    role=msg_data['role'],
                    content=msg_data['content'],
                    metadata=msg_data.get('metadata', {})
                )
                conversation.add_message(message)

        # æ­¥éª¤3: ä¿å­˜å¯¹è¯(å¸¦é”)
        with self._conversation_lock(conversation.conversation_id):
            # 3.1 ä¿å­˜åˆ°æ–‡ä»¶å­˜å‚¨
            self.storage.save_conversation(conversation.to_dict())

            # 3.2 æ›´æ–°ç´¢å¼•
            self.index_manager.add_conversation(conversation.to_dict())

            # 3.3 æ›´æ–°ç¼“å­˜
            self.conversation_cache.set(
                conversation.conversation_id,
                conversation.to_dict()
            )

        # æ­¥éª¤4: æ›´æ–°ç»Ÿè®¡
        self._stats['conversations_created'] += 1

        return conversation.conversation_id

    except Exception as e:
        raise ConversationManagerError(f"Failed to create conversation: {e}")
```

**å…³é”®å®ç°ç»†èŠ‚**:

1. **UUID ç”Ÿæˆ**: ä½¿ç”¨ `uuid.uuid4()` ç”Ÿæˆå…¨å±€å”¯ä¸€ID
2. **æ–‡ä»¶é”**: `_conversation_lock()` ç¡®ä¿å¹¶å‘å®‰å…¨
3. **ä¸‰å±‚å­˜å‚¨**: storage(æ–‡ä»¶) + index(ç´¢å¼•) + cache(ç¼“å­˜)
4. **åŸå­æ€§**: æ•´ä¸ªæ“ä½œåœ¨é”ä¿æŠ¤ä¸‹,è¦ä¹ˆå…¨éƒ¨æˆåŠŸ,è¦ä¹ˆå…¨éƒ¨å¤±è´¥

#### 3.3.4 get_conversation æ¢å¤æµç¨‹(æ‰©å±•)

**å®Œæ•´æµç¨‹**:

```python
def get_conversation(self, conversation_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–å¯¹è¯(æŒ‰ä¼˜å…ˆçº§:ç¼“å­˜ -> å­˜å‚¨)

    Args:
        conversation_id: å¯¹è¯ID

    Returns:
        å¯¹è¯æ•°æ®æˆ–None(å¦‚æœä¸å­˜åœ¨)
    """
    try:
        # æ­¥éª¤1: å°è¯•ä»ç¼“å­˜è·å–
        cached_conversation = self.conversation_cache.get(conversation_id)
        if cached_conversation:
            self._stats['cache_hits'] += 1
            return cached_conversation

        self._stats['cache_misses'] += 1

        # æ­¥éª¤2: ä»å­˜å‚¨åŠ è½½(å¸¦è¯»é”)
        with self._conversation_lock(conversation_id, exclusive=False):
            # 2.1 ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½
            conversation_data = self.storage.load_conversation(conversation_id)

            if conversation_data:
                # 2.2 æ›´æ–°ç¼“å­˜
                self.conversation_cache.set(conversation_id, conversation_data)
                self._stats['conversations_loaded'] += 1
                return conversation_data

            return None

    except Exception as e:
        raise ConversationManagerError(
            f"Failed to get conversation {conversation_id}: {e}"
        )
```

**ç¼“å­˜æœºåˆ¶**:

```python
# ç¼“å­˜åˆå§‹åŒ–(åœ¨ _init_cache æ–¹æ³•ä¸­)
from .cache import MemoryCache

self.conversation_cache = MemoryCache(
    max_size=self.config.max_cache_size,      # æœ€å¤§ç¼“å­˜100ä¸ªå¯¹è¯
    default_ttl=self.config.cache_ttl         # é»˜è®¤TTL 300ç§’(5åˆ†é’Ÿ)
)

self.message_cache = MemoryCache(
    max_size=self.config.max_cache_size * 10, # æ¶ˆæ¯ç¼“å­˜æ˜¯å¯¹è¯çš„10å€
    default_ttl=self.config.cache_ttl
)
```

**è¯»å†™é”çš„ä½¿ç”¨**:

```python
@contextlib.contextmanager
def _conversation_lock(
    self,
    conversation_id: str,
    exclusive: bool = True
) -> Generator[None, None, None]:
    """
    è·å–å¯¹è¯é”(æ”¯æŒè¯»å†™åˆ†ç¦»)

    Args:
        conversation_id: å¯¹è¯ID
        exclusive: True=å†™é”(ç‹¬å ), False=è¯»é”(å…±äº«)
    """
    lock_file = self._get_conversation_lock_file(conversation_id)
    locker = FileLocker(lock_file, timeout=self.config.lock_timeout)

    try:
        if exclusive:
            with locker.acquire_write_lock():  # å†™é”:åªå…è®¸ä¸€ä¸ªå†™å…¥è€…
                yield
        else:
            with locker.acquire_read_lock():   # è¯»é”:å…è®¸å¤šä¸ªè¯»å–è€…
                yield
    except Exception as e:
        raise ConcurrencyError(
            f"Failed to acquire lock for conversation {conversation_id}: {e}"
        )
```

#### 3.3.5 append_message å’Œ update_message æ–¹æ³•(æ‰©å±•)

**append_message æµç¨‹**:

```python
def append_message(
    self,
    conversation_id: str,
    role: str,
    content: Union[str, Dict[str, Any], List[Any]],
    metadata: Optional[Dict[str, Any]] = None,
    llm_metadata: Optional['LLMCallMetadata'] = None
) -> str:
    """
    å‘å¯¹è¯è¿½åŠ æ¶ˆæ¯

    Returns:
        æ¶ˆæ¯ID(UUID)
    """
    try:
        # æ­¥éª¤1: åˆ›å»ºæ¶ˆæ¯å¯¹è±¡
        message = ConversationMessage(
            role=role,
            content=content,
            metadata=metadata or {},
            llm_metadata=llm_metadata
        )

        # æ­¥éª¤2: åŠ è½½å¯¹è¯å¹¶æ·»åŠ æ¶ˆæ¯(å¸¦å†™é”)
        with self._conversation_lock(conversation_id):
            # 2.1 åŠ è½½å¯¹è¯
            conversation_data = self.storage.load_conversation(conversation_id)
            if not conversation_data:
                raise ConversationNotFoundError(conversation_id)

            # 2.2 æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯
            conversation = Conversation.from_dict(conversation_data)
            conversation.add_message(message)

            # 2.3 ä¿å­˜æ›´æ–°åçš„å¯¹è¯
            updated_data = conversation.to_dict()
            self.storage.save_conversation(updated_data)

            # 2.4 æ›´æ–°ç´¢å¼•
            self.index_manager.update_conversation(updated_data)

            # 2.5 æ›´æ–°ç¼“å­˜
            self.conversation_cache.set(conversation_id, updated_data)
            self.message_cache.set(
                f"{conversation_id}:{message.message_id}",
                message.to_dict()
            )

        # æ­¥éª¤3: æ›´æ–°ç»Ÿè®¡
        self._stats['messages_added'] += 1

        return message.message_id

    except ConversationNotFoundError:
        raise
    except Exception as e:
        raise ConversationManagerError(
            f"Failed to append message to conversation {conversation_id}: {e}"
        )
```

**update_message æµç¨‹**(ç”¨äºå›å†™ LLM metadata):

```python
def update_message(
    self,
    conversation_id: str,
    message_id: str,
    content: Optional[Union[str, Dict[str, Any], List[Any]]] = None,
    metadata: Optional[Dict[str, Any]] = None,
    llm_metadata: Optional["LLMCallMetadata"] = None
) -> bool:
    """
    æ›´æ–°æ¶ˆæ¯(ä¾‹å¦‚:å›å†™ token ç»Ÿè®¡)

    Returns:
        True if update was successful
    """
    try:
        with self._conversation_lock(conversation_id):
            # åŠ è½½å¯¹è¯
            conversation_data = self.storage.load_conversation(conversation_id)
            if not conversation_data:
                raise ConversationNotFoundError(conversation_id)

            conversation = Conversation.from_dict(conversation_data)

            # æŸ¥æ‰¾å¹¶æ›´æ–°æ¶ˆæ¯
            for i, message_data in enumerate(conversation.messages):
                msg = ConversationMessage.from_dict(message_data)
                if msg.message_id == message_id:
                    # æ›´æ–°æ¶ˆæ¯å­—æ®µ
                    if content is not None:
                        msg.content = content
                    if metadata is not None:
                        if msg.metadata is None:
                            msg.metadata = {}
                        msg.metadata.update(metadata)
                    if llm_metadata is not None:
                        msg.llm_metadata = llm_metadata

                    # æ›´æ–°æ—¶é—´æˆ³
                    msg.timestamp = time.time()

                    # æ›¿æ¢æ¶ˆæ¯
                    conversation.messages[i] = msg.to_dict()
                    conversation.updated_at = time.time()

                    # ä¿å­˜æ›´æ–°
                    updated_data = conversation.to_dict()
                    self.storage.save_conversation(updated_data)
                    self.index_manager.update_conversation(updated_data)
                    self.conversation_cache.set(conversation_id, updated_data)
                    self.message_cache.set(
                        f"{conversation_id}:{message_id}",
                        msg.to_dict()
                    )

                    return True

            raise MessageNotFoundError(message_id)

    except (ConversationNotFoundError, MessageNotFoundError):
        raise
    except Exception as e:
        raise ConversationManagerError(
            f"Failed to update message {message_id}: {e}"
        )
```

#### 3.3.6 å¹¶å‘å®‰å…¨æœºåˆ¶(æ‰©å±•)

**æ–‡ä»¶é”å®ç°**:

```python
# åœ¨ manager.py ä¸­
def _get_conversation_lock_file(self, conversation_id: str) -> str:
    """è·å–å¯¹è¯çš„é”æ–‡ä»¶è·¯å¾„"""
    return os.path.join(self._lock_dir, f"{conversation_id}.lock")

# FileLocker å®ç°(åœ¨ file_locker.py ä¸­)
class FileLocker:
    def __init__(self, lock_file: str, timeout: float = 10.0):
        self.lock_file = Path(lock_file)
        self.timeout = timeout

    @contextlib.contextmanager
    def acquire_write_lock(self):
        """è·å–å†™é”(ç‹¬å é”)"""
        # ä½¿ç”¨fcntl(Linux)æˆ–msvcrt(Windows)å®ç°æ–‡ä»¶é”
        with open(self.lock_file, 'w') as f:
            start_time = time.time()
            while True:
                try:
                    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                    yield
                    break
                except IOError:
                    if time.time() - start_time > self.timeout:
                        raise TimeoutError("Lock timeout")
                    time.sleep(0.1)
            finally:
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)

    @contextlib.contextmanager
    def acquire_read_lock(self):
        """è·å–è¯»é”(å…±äº«é”)"""
        with open(self.lock_file, 'r') as f:
            start_time = time.time()
            while True:
                try:
                    fcntl.flock(f.fileno(), fcntl.LOCK_SH | fcntl.LOCK_NB)
                    yield
                    break
                except IOError:
                    if time.time() - start_time > self.timeout:
                        raise TimeoutError("Lock timeout")
                    time.sleep(0.1)
            finally:
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)
```

**å¹¶å‘åœºæ™¯ä¸¾ä¾‹**:

```python
# åœºæ™¯1: å¤šä¸ªè¯»å–è€…åŒæ—¶è¯»å–å¯¹è¯(å…è®¸)
thread1: with manager._conversation_lock(conv_id, exclusive=False):  # è¯»é”
thread2: with manager._conversation_lock(conv_id, exclusive=False):  # è¯»é”
# ä¸¤ä¸ªçº¿ç¨‹å¯ä»¥åŒæ—¶æŒæœ‰è¯»é”,äº’ä¸é˜»å¡

# åœºæ™¯2: ä¸€ä¸ªå†™å…¥è€…æ’ä»–æ‰§è¡Œ(é˜»å¡å…¶ä»–æ‰€æœ‰æ“ä½œ)
thread1: with manager._conversation_lock(conv_id, exclusive=True):   # å†™é”
thread2: with manager._conversation_lock(conv_id, exclusive=False):  # è¯»é”(ç­‰å¾…)
thread3: with manager._conversation_lock(conv_id, exclusive=True):   # å†™é”(ç­‰å¾…)
# thread2 å’Œ thread3 å¿…é¡»ç­‰å¾… thread1 é‡Šæ”¾é”

# åœºæ™¯3: ç¼“å­˜å‡å°‘é”ç«äº‰
# å¤§éƒ¨åˆ†è¯»å–æ“ä½œå‘½ä¸­ç¼“å­˜,ä¸éœ€è¦è·å–é”
cached_data = manager.conversation_cache.get(conv_id)  # æ— é”,å¿«é€Ÿè¿”å›
if not cached_data:
    # åªæœ‰ç¼“å­˜æœªå‘½ä¸­æ—¶æ‰è·å–é”
    with manager._conversation_lock(conv_id, exclusive=False):
        data = manager.storage.load_conversation(conv_id)
```

**æ€»ç»“**:

ConversationManager çš„æŒä¹…åŒ–å’Œæ¢å¤æœºåˆ¶é€šè¿‡ä»¥ä¸‹è®¾è®¡ç¡®ä¿å¯é æ€§:

1. **å•ä¾‹æ¨¡å¼**: å…¨å±€å”¯ä¸€å®ä¾‹,é¿å…çŠ¶æ€ä¸ä¸€è‡´
2. **ä¸‰å±‚å­˜å‚¨**: ç¼“å­˜(å¿«é€Ÿ) + ç´¢å¼•(æŸ¥è¯¢) + æ–‡ä»¶(æŒä¹…)
3. **æ–‡ä»¶é”**: è¯»å†™é”åˆ†ç¦»,æ”¯æŒå¹¶å‘è¯»,ä¸²è¡Œå†™
4. **å‘½åç©ºé—´**: æ”¯æŒå¤šé¡¹ç›®éš”ç¦»
5. **Token å›å†™**: å¼‚æ­¥å›å†™ LLM metadata,ä¸é˜»å¡ä¸»æµç¨‹
6. **åŸå­æ“ä½œ**: é”ä¿æŠ¤ä¸‹çš„åŸå­æ€§æ›´æ–°

---

# é˜¶æ®µä¸€è¡¥å……:æ·±åŒ–å…³é”®å®ç°ç»†èŠ‚

> **è¡¥å……è¯´æ˜**:æœ¬éƒ¨åˆ†æ˜¯å¯¹ç¬¬äºŒã€ç¬¬ä¸‰éƒ¨åˆ†çš„æ·±åº¦æ‰©å±•ï¼Œé€šè¿‡è¯¦ç»†çš„æºç åˆ†æï¼Œæ·±å…¥è§£æ ToolsManagerã€Rules æ–‡ä»¶ç³»ç»Ÿã€æ³¨å…¥é¡ºåºä¸ä¼˜å…ˆçº§ã€å±‚æ¬¡äº¤äº’ç­‰æ ¸å¿ƒæœºåˆ¶çš„å®ç°ç»†èŠ‚ã€‚

## 2.4.5 Sub Agents ä¿¡æ¯æ³¨å…¥(æ‰©å±•) - AgentManager è¯¦ç»†å®ç°

### 2.4.5.1 AgentManager ç±»æ¶æ„æ¦‚è§ˆ

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/agents/agent_manager.py`

AgentManager è´Ÿè´£ä»å¤šä¼˜å…ˆçº§ç›®å½•åŠ è½½å’Œç®¡ç† Agent å®šä¹‰æ–‡ä»¶ï¼ˆ.mdæ ¼å¼ï¼‰ï¼Œä¸º AgenticEdit æä¾›å‘½åå­ä»£ç†ï¼ˆNamed Sub Agentsï¼‰åŠŸèƒ½ï¼Œå®ç°ä»»åŠ¡çš„åˆ†å±‚å§”æ‰˜æ‰§è¡Œã€‚

**æ ¸å¿ƒèŒè´£**:
- ä»å¤šä¸ªä¼˜å…ˆçº§ç›®å½•åŠ è½½ .md æ ¼å¼çš„ agent å®šä¹‰æ–‡ä»¶
- è§£æ agent å…ƒæ•°æ®ï¼ˆåç§°ã€æè¿°ã€å·¥å…·åˆ—è¡¨ã€æ¨¡å‹é…ç½®ç­‰ï¼‰
- å®ç°ä¼˜å…ˆçº§è¦†ç›–æœºåˆ¶ï¼ˆé«˜ä¼˜å…ˆçº§ç›®å½•çš„åŒå agent è¦†ç›–ä½ä¼˜å…ˆçº§çš„ï¼‰
- æ¸²æŸ“ Sub Agents æç¤ºè¯æ®µè½ï¼Œæ³¨å…¥åˆ°ä¸» Agent çš„ç³»ç»Ÿæç¤ºä¸­
- æ”¯æŒ repos ç‰¹æ€§ï¼ˆé¡¹ç›®ç‰¹å®šçš„å…¨å±€ agent ç›®å½•ï¼‰

**ä¾èµ–æ¨¡å—**:
```python
from autocoder.common.agents.agent_parser import AgentParser, Agent
from autocoder.common.priority_directory_finder import (
    PriorityDirectoryFinder, FinderConfig, SearchStrategy,
    ValidationMode, create_file_filter
)
```

### 2.4.5.2 Agent æ–‡ä»¶æ ¼å¼è§„èŒƒ

Agent æ–‡ä»¶å¿…é¡»æ˜¯ `.md` æ ¼å¼çš„ Markdown æ–‡ä»¶ï¼Œé€šè¿‡ YAML front-matter å®šä¹‰å…ƒæ•°æ®ï¼š

**æ ‡å‡†æ ¼å¼ç¤ºä¾‹** (`research_agent.md`):
```markdown
---
name: research_agent
description: ä¸“é—¨ç”¨äºæŠ€æœ¯ç ”ç©¶å’Œæ–‡æ¡£åˆ†æçš„åŠ©æ‰‹
model: gpt-4o  # å¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨å½“å‰æ¨¡å‹
tools:
  - read_file
  - search_files
  - write_to_file
---

You are a specialized research agent focused on technical documentation analysis.

Your responsibilities:
1. Deep dive into technical documentation
2. Extract key architectural patterns
3. Summarize complex technical concepts
4. Provide clear, concise explanations

When analyzing code:
- Focus on design patterns and architectural decisions
- Identify potential improvements
- Document findings in structured format
```

**å…ƒæ•°æ®å­—æ®µè¯´æ˜**:
- `name` (å¿…éœ€): Agent çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºè°ƒç”¨æ—¶æŒ‡å®š
- `description` (å¿…éœ€): Agent çš„åŠŸèƒ½æè¿°ï¼Œä¼šæ˜¾ç¤ºåœ¨å¯ç”¨ agent åˆ—è¡¨ä¸­
- `model` (å¯é€‰): æŒ‡å®šè¯¥ agent ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨å½“å‰ä¸»æ¨¡å‹
- `tools` (å¯é€‰): è¯¥ agent å¯ä»¥ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ï¼Œé™åˆ¶å…¶å·¥å…·è®¿é—®æƒé™

**front-matter ä¹‹åçš„å†…å®¹**æ˜¯ agent çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰ï¼Œä¼šä½œä¸ºè¯¥ agent çš„è¡Œä¸ºæŒ‡å—ã€‚

### 2.4.5.3 å¤šä¼˜å…ˆçº§ç›®å½•æŸ¥æ‰¾ä¸è¦†ç›–æœºåˆ¶

**ç›®å½•ä¼˜å…ˆçº§å±‚æ¬¡**ï¼ˆä»é«˜åˆ°ä½ï¼‰:

```python
def _get_agents_search_paths(self) -> List[Path]:
    """
    è·å– agent æœç´¢è·¯å¾„åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº

    ä¼˜å…ˆçº§é¡ºåºï¼š
    1. é¡¹ç›®æ ¹ç›®å½•/.autocoderagents              (æœ€é«˜ä¼˜å…ˆçº§)
    2. é¡¹ç›®æ ¹ç›®å½•/.auto-coder/.autocoderagents  (æ¬¡é«˜ä¼˜å…ˆçº§)
    3. ~/.auto-coder/.autocoderagents           (ç”¨æˆ·å…¨å±€)
    4. ~/.auto-coder/.autocoderagents/repos/<é¡¹ç›®å> (é¡¹ç›®ç‰¹å®šå…¨å±€ï¼Œé€šè¿‡ repos åŠŸèƒ½)
    """
    search_paths = []

    # 1. é¡¹ç›®çº§ agent ç›®å½• (ç”¨äºé¡¹ç›®ç‰¹å®šçš„ä¸´æ—¶æˆ–å®éªŒæ€§ agent)
    project_agents_dir = self.project_root / ".autocoderagents"
    search_paths.append(project_agents_dir)

    # 2. é¡¹ç›® .auto-coder å­ç›®å½• (æ¨èä½ç½®ï¼Œä¼šè¢« git è·Ÿè¸ª)
    project_autocoder_dir = self.project_root / ".auto-coder" / ".autocoderagents"
    search_paths.append(project_autocoder_dir)

    # 3. ç”¨æˆ·å…¨å±€ agent ç›®å½• (è·¨é¡¹ç›®å…±äº«çš„é€šç”¨ agent)
    home_autocoder_dir = Path.home() / ".auto-coder" / ".autocoderagents"
    search_paths.append(home_autocoder_dir)

    return search_paths
```

**Repos ç‰¹æ€§**:

AgentManager è¿˜æ”¯æŒ `repos/<é¡¹ç›®å>` ç›®å½•ç»“æ„ï¼Œå…è®¸ä¸ºç‰¹å®šé¡¹ç›®å®šä¹‰å…¨å±€å…±äº«çš„ agentï¼š

```python
# åœ¨ _load_agents() æ–¹æ³•ä¸­
project_name = self.project_root.name
repos_dir = f"~/.auto-coder/.autocoderagents/repos/{project_name}"
config.add_directory(
    path=repos_dir,
    priority=4,  # ä¼˜å…ˆçº§æœ€ä½
    validation_mode=ValidationMode.HAS_SPECIFIC_FILES,
    file_filter=md_filter,
    description=f"é¡¹ç›®ç‰¹å®š repos agent ç›®å½•: {project_name}"
)
```

**ä¼˜å…ˆçº§è¦†ç›–é€»è¾‘**:

```python
def _load_agents_from_directory(self, agents_dir: Path) -> None:
    """ä»æŒ‡å®šç›®å½•åŠ è½½ agentsï¼Œå®ç°ä¼˜å…ˆçº§è¦†ç›–"""
    for md_file in agents_dir.glob("*.md"):
        agent = AgentParser.parse_agent_file(md_file)

        # éªŒè¯ agent å…ƒæ•°æ®
        errors = AgentParser.validate_agent(agent)
        if errors:
            logger.error(f"éªŒè¯å¤±è´¥: {'; '.join(errors)}")
            continue

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒå agent
        if agent.name in self.agents:
            old_agent_path = self.agents[agent.name].file_path
            # ç”±äºæŒ‰ä¼˜å…ˆçº§é¡ºåºåŠ è½½ï¼ŒååŠ è½½çš„ä¼˜å…ˆçº§æ›´ä½ï¼Œè·³è¿‡
            logger.debug(f"è·³è¿‡ agent '{agent.name}' from {md_file} "
                        f"(å·²å­˜åœ¨æ›´é«˜ä¼˜å…ˆçº§ç‰ˆæœ¬: {old_agent_path})")
            continue

        # æ·»åŠ åˆ° agent å­—å…¸
        self.agents[agent.name] = agent
        logger.debug(f"åŠ è½½ agent '{agent.name}' from {md_file}")
```

**è®¾è®¡è¦ç‚¹**:
- ä½¿ç”¨ `PriorityDirectoryFinder` ç»Ÿä¸€ç®¡ç†å¤šç›®å½•æŸ¥æ‰¾
- é‡‡ç”¨ `MERGE_ALL` ç­–ç•¥åˆå¹¶æ‰€æœ‰æœ‰æ•ˆç›®å½•
- æŒ‰ä¼˜å…ˆçº§é¡ºåºåŠ è½½ï¼Œå…ˆåŠ è½½çš„ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰ä¼šé˜»æ­¢åç»­çš„åŒå agent
- æ”¯æŒ `HAS_SPECIFIC_FILES` éªŒè¯æ¨¡å¼ï¼Œåªé€‰æ‹©åŒ…å« .md æ–‡ä»¶çš„ç›®å½•

### 2.4.5.4 render_sub_agents_section æ–¹æ³•è¯¦è§£

è¿™æ˜¯ AgentManager çš„æ ¸å¿ƒè¾“å‡ºæ–¹æ³•ï¼Œä½¿ç”¨ `@byzerllm.prompt()` è£…é¥°å™¨ï¼Œå°†åŠ è½½çš„ agents æ¸²æŸ“æˆæ ¼å¼åŒ–çš„æç¤ºè¯æ®µè½ï¼Œæ³¨å…¥åˆ°ä¸» Agent çš„ç³»ç»Ÿæç¤ºä¸­ã€‚

**å®Œæ•´å®ç°**:

```python
@byzerllm.prompt()
def render_sub_agents_section(self, current_model: Optional[str] = None) -> str:
    """
    æ¸²æŸ“ Sub Agents æç¤ºè¯æ®µè½

    æ¨¡æ¿ç»“æ„ï¼š
    1. å¦‚æœæ²¡æœ‰å¯ç”¨çš„ agentsï¼Œè¿”å›ç©ºå†…å®¹
    2. å¦‚æœæœ‰ agentsï¼š
       - åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å‘½åå­ä»£ç†åŠå…¶æè¿°å’Œå·¥å…·
       - æä¾› run_named_subagents å·¥å…·çš„ä½¿ç”¨è¯´æ˜
       - å±•ç¤ºå¹¶è¡Œå’Œä¸²è¡Œæ‰§è¡Œçš„ç¤ºä¾‹

    Args:
        current_model: å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œç”¨äº agent æ²¡æœ‰æŒ‡å®šæ¨¡å‹æ—¶çš„é»˜è®¤å€¼

    Returns:
        æ¸²æŸ“åçš„æç¤ºè¯å­—ç¬¦ä¸²ï¼ˆé€šè¿‡ Jinja2 æ¨¡æ¿å¼•æ“ï¼‰
    """
    # Jinja2 æ¨¡æ¿å†…å®¹ï¼ˆåœ¨è£…é¥°å™¨çš„ docstring ä¸­å®šä¹‰ï¼‰
    """
    {% if not agents_available %}
    {% else %}
    ## Available Named Sub Agents

    The following specialized agents are available for delegation:

    {% for agent in sorted_agents %}
    ### {{ agent.name }}
    **Description**: {{ agent.description }}
    {% if agent.tools %}
    **Available Tools**: {{ agent.tools | join(', ') }}
    {% endif %}

    {% endfor %}
    ## How to Use

    Use the `run_named_subagents` tool to run multiple agent commands:

    ### Example: Parallel Execution

    <run_named_subagents>
    <subagents>
    mode: parallel
    subagents:
    {% for agent in example_agents %}
        - name: {{ agent.name }}
          task: {{ agent.example_task }}
    {% endfor %}
    </subagents>
    </run_named_subagents>


    ### Example: Serial Execution

    <run_named_subagents>
    <subagents>
    mode: serial
    subagents:
        - name: agent_name
          task: your task description here
    </subagents>
    </run_named_subagents>

    {% endif %}
    """

    # å¦‚æœæ²¡æœ‰åŠ è½½ä»»ä½• agentsï¼Œè¿”å›ç©ºæ ‡è®°
    if not self.agents:
        return {
            "agents_available": False
        }

    # æŒ‰åç§°æ’åºï¼Œç¡®ä¿è¾“å‡ºä¸€è‡´æ€§
    sorted_agents = sorted(self.agents.values(), key=lambda a: a.name)

    # å‡†å¤‡ agent æ•°æ®ï¼Œç”¨äºæ¨¡æ¿æ¸²æŸ“
    agents_data = []
    for agent in sorted_agents:
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹ï¼ˆagent è‡ªå®šä¹‰æˆ–å½“å‰æ¨¡å‹ï¼‰
        model_to_use = agent.model or current_model
        if not model_to_use:
            raise ValueError(f"Agent {agent.name} æ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä¸”æœªæä¾›å½“å‰æ¨¡å‹")

        # ä½¿ç”¨ shlex.quote è¿›è¡Œå®‰å…¨çš„ shell è½¬ä¹‰
        safe_task = shlex.quote("YOUR_TASK_HERE")
        safe_model = shlex.quote(model_to_use)
        safe_prompt = shlex.quote(agent.content)

        # ç”Ÿæˆ SDK CLI è°ƒç”¨å‘½ä»¤ï¼ˆå®é™…ä¸Šç°åœ¨ä½¿ç”¨ run_named_subagents å·¥å…·ï¼‰
        command = f'echo {safe_task} | auto-coder.run --model {safe_model} --system-prompt {safe_prompt}'

        agents_data.append({
            "name": agent.name,
            "description": agent.description,
            "tools": agent.tools if agent.tools else None,
            "command": command  # ä¿ç•™ç”¨äºå‘åå…¼å®¹
        })

    # å‡†å¤‡ç¤ºä¾‹æ•°æ®ï¼ˆå–å‰2ä¸ª agent ä½œä¸ºç¤ºä¾‹ï¼‰
    example_agents_data = []
    example_agents = sorted_agents[:2] if len(sorted_agents) >= 2 else sorted_agents
    for agent in example_agents:
        example_agents_data.append({
            "name": agent.name,
            "example_task": f"Task for {agent.name}"
        })

    # è¿”å›æ¨¡æ¿å˜é‡å­—å…¸ï¼ˆbyzerllm ä¼šè‡ªåŠ¨åº”ç”¨ Jinja2 æ¨¡æ¿ï¼‰
    return {
        "agents_available": True,
        "sorted_agents": agents_data,
        "example_agents": example_agents_data
    }  # type: ignore
```

**å…³é”®è®¾è®¡ç‚¹**:

1. **æ¡ä»¶æ¸²æŸ“**: å¦‚æœæ²¡æœ‰å¯ç”¨ agentsï¼Œè¿”å› `agents_available=False`ï¼Œæ¨¡æ¿ä¼šè¾“å‡ºç©ºå†…å®¹
2. **æ•°æ®æ’åº**: æŒ‰ agent åç§°æ’åºï¼Œç¡®ä¿è¾“å‡ºç¨³å®šã€å¯é¢„æµ‹
3. **å®‰å…¨è½¬ä¹‰**: ä½¿ç”¨ `shlex.quote()` å¯¹å‘½ä»¤å‚æ•°è¿›è¡Œå®‰å…¨è½¬ä¹‰ï¼Œé˜²æ­¢æ³¨å…¥æ”»å‡»
4. **æ¨¡å‹å›é€€**: Agent å¯ä»¥æŒ‡å®šè‡ªå·±çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å½“å‰æ¨¡å‹
5. **å·¥å…·åˆ—è¡¨**: å¯é€‰åœ°å±•ç¤ºæ¯ä¸ª agent å¯ç”¨çš„å·¥å…·ï¼Œå¸®åŠ©ä¸» agent åšå‡ºå§”æ‰˜å†³ç­–
6. **ä½¿ç”¨ç¤ºä¾‹**: æä¾›å¹¶è¡Œå’Œä¸²è¡Œæ‰§è¡Œçš„å…·ä½“ç¤ºä¾‹ï¼Œé™ä½ LLM ä½¿ç”¨é—¨æ§›

**æ¸²æŸ“è¾“å‡ºç¤ºä¾‹**:

å‡è®¾åŠ è½½äº†ä¸¤ä¸ª agentsï¼ˆ`research_agent` å’Œ `code_reviewer`ï¼‰ï¼Œæ¸²æŸ“ç»“æœä¼šæ˜¯ï¼š

```markdown
## Available Named Sub Agents

The following specialized agents are available for delegation:

### research_agent
**Description**: ä¸“é—¨ç”¨äºæŠ€æœ¯ç ”ç©¶å’Œæ–‡æ¡£åˆ†æçš„åŠ©æ‰‹
**Available Tools**: read_file, search_files, write_to_file

### code_reviewer
**Description**: ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œä¸“æ³¨äºä»£ç è´¨é‡å’Œæœ€ä½³å®è·µ
**Available Tools**: read_file, search_files, replace_in_file

## How to Use

Use the `run_named_subagents` tool to run multiple agent commands:

### Example: Parallel Execution

<run_named_subagents>
<subagents>
mode: parallel
subagents:
    - name: research_agent
      task: Task for research_agent
    - name: code_reviewer
      task: Task for code_reviewer
</subagents>
</run_named_subagents>

### Example: Serial Execution

<run_named_subagents>
<subagents>
mode: serial
subagents:
    - name: agent_name
      task: your task description here
</subagents>
</run_named_subagents>
```

è¿™æ®µæ¸²æŸ“åçš„å†…å®¹ä¼šè¢«æ’å…¥åˆ° `AgenticEdit._analyze()` æ–¹æ³•çš„ç³»ç»Ÿæç¤ºè¯ä¸­çš„ `{{sub_agents_section}}` å ä½ç¬¦å¤„ï¼Œè®©ä¸» Agent äº†è§£å¯ä»¥å§”æ‰˜ç»™å“ªäº›å­ Agentï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚

---
## 2.4.6 å·¥å…·ä½¿ç”¨ä¿¡æ¯æ³¨å…¥(æ‰©å±•) - ToolsManager è¯¦ç»†å®ç°

### 2.4.6.1 ToolsManager ç±»è¯¦è§£

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/tools_manager/manager.py`

ToolsManager è´Ÿè´£ä»å¤šä¸ªä¼˜å…ˆçº§ç›®å½•ä¸­åŠ è½½å’Œç®¡ç†å¤–éƒ¨å·¥å…·å‘½ä»¤æ–‡ä»¶ï¼Œä¸º LLM æä¾›å¯æ‰§è¡Œçš„å·¥å…·èƒ½åŠ›æ‰©å±•ã€‚

**æ ¸å¿ƒæ•°æ®ç»“æ„**:

```python
# å®šä¹‰åœ¨ models.py ä¸­
class ToolCommand(BaseModel):
    """è¡¨ç¤ºä¸€ä¸ªå·¥å…·å‘½ä»¤çš„ä¿¡æ¯"""
    model_config = {"frozen": True, "extra": "forbid"}

    name: str              # å‘½ä»¤åç§°ï¼Œå¦‚ "search-code"
    path: str              # å‘½ä»¤æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
    help_text: str         # å‘½ä»¤çš„å¸®åŠ©ä¿¡æ¯ï¼ˆä»æ–‡ä»¶æˆ–å‘½ä»¤æå–ï¼‰
    is_executable: bool    # æ˜¯å¦å¯æ‰§è¡Œï¼ˆchmod +xï¼‰
    file_extension: str    # æ–‡ä»¶æ‰©å±•åï¼Œå¦‚ ".sh"ã€".py" æˆ– ""ï¼ˆæ— æ‰©å±•åçš„äºŒè¿›åˆ¶ï¼‰
    source_directory: str  # æ¥æºç›®å½•ï¼ˆç”¨äºä¼˜å…ˆçº§åˆ¤æ–­ï¼‰

class ToolsLoadResult(BaseModel):
    """å·¥å…·åŠ è½½ç»“æœ"""
    success: bool
    tools: List[ToolCommand]
    error_message: Optional[str] = None
    total_count: int = 0        # æˆåŠŸåŠ è½½çš„å·¥å…·æ•°é‡
    failed_count: int = 0       # åŠ è½½å¤±è´¥çš„å·¥å…·æ•°é‡
```

**ToolsManager åˆå§‹åŒ–æµç¨‹**:

```python
class ToolsManager:
    """
    å·¥å…·ç®¡ç†å™¨

    æ”¯æŒçš„ç›®å½•ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. å½“å‰é¡¹ç›®/.autocodertools         ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    2. .auto-coder/.autocodertools       ï¼ˆæ¨èä½ç½®ï¼‰
    3. ~/.auto-coder/.autocodertools     ï¼ˆç”¨æˆ·å…¨å±€ï¼‰
    4. ~/.auto-coder/.autocodertools/repos/<é¡¹ç›®å> ï¼ˆé¡¹ç›®ç‰¹å®šå…¨å±€ï¼‰
    """

    def __init__(self, tools_dirs: Optional[List[str]] = None):
        """
        Args:
            tools_dirs: è‡ªå®šä¹‰å·¥å…·ç›®å½•åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æŸ¥æ‰¾ç­–ç•¥
        """
        # å¦‚æœæœªæŒ‡å®šç›®å½•ï¼Œåˆ™è‡ªåŠ¨å‘ç°
        self.tools_dirs = tools_dirs or self._find_tools_directories()
        # ç¼“å­˜åŠ è½½ç»“æœï¼Œé¿å…é‡å¤æ‰«æ
        self._result_cache: Optional[ToolsLoadResult] = None
```

### 2.4.6.2 åŠ¨æ€å·¥å…·å‘ç°æœºåˆ¶

**ç›®å½•æŸ¥æ‰¾ç­–ç•¥**ï¼ˆåŸºäº `PriorityDirectoryFinder`ï¼‰:

```python
def _find_tools_directories(self) -> List[str]:
    """
    æŸ¥æ‰¾æ‰€æœ‰æœ‰æ•ˆçš„å·¥å…·ç›®å½•

    ä½¿ç”¨ PriorityDirectoryFinder ç»Ÿä¸€ç®¡ç†å¤šä¼˜å…ˆçº§ç›®å½•æŸ¥æ‰¾ï¼š
    - æ”¯æŒç›®å½•å­˜åœ¨æ€§éªŒè¯
    - æ”¯æŒå†…å®¹éªŒè¯ï¼ˆHAS_FILES æ¨¡å¼ï¼šç›®å½•å¿…é¡»åŒ…å«æ–‡ä»¶ï¼‰
    - è‡ªåŠ¨æŒ‰ä¼˜å…ˆçº§æ’åº

    Returns:
        List[str]: æœ‰æ•ˆçš„å·¥å…·ç›®å½•è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    """
    # åˆ›å»ºæŸ¥æ‰¾é…ç½®ï¼Œä½¿ç”¨ MERGE_ALL ç­–ç•¥åˆå¹¶æ‰€æœ‰æœ‰æ•ˆç›®å½•
    config = FinderConfig(strategy=SearchStrategy.MERGE_ALL)

    current_dir = Path.cwd()
    project_name = get_project_name()  # è·å–å½“å‰ç›®å½•åä½œä¸ºé¡¹ç›®å

    # 1. å½“å‰é¡¹ç›®/.autocodertools (æœ€é«˜ä¼˜å…ˆçº§)
    # ç”¨äºé¡¹ç›®ç‰¹å®šçš„ä¸´æ—¶å·¥å…·æˆ–å®éªŒæ€§å·¥å…·
    config.add_directory(
        str(current_dir / ".autocodertools"),
        priority=1,  # æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
        validation_mode=ValidationMode.HAS_FILES  # å¿…é¡»åŒ…å«æ–‡ä»¶æ‰è®¤ä¸ºæœ‰æ•ˆ
    )

    # 2. .auto-coder/.autocodertools (æ¨èä½ç½®)
    # ç”¨äºé¡¹ç›®é…ç½®çš„å·¥å…·ï¼Œä¼šè¢« git è·Ÿè¸ª
    config.add_directory(
        str(current_dir / ".auto-coder" / ".autocodertools"),
        priority=2,
        validation_mode=ValidationMode.HAS_FILES
    )

    # 3. ~/.auto-coder/.autocodertools (ç”¨æˆ·å…¨å±€å·¥å…·)
    # ç”¨äºç”¨æˆ·è‡ªå®šä¹‰çš„é€šç”¨å·¥å…·
    home_dir = Path.home()
    config.add_directory(
        str(home_dir / ".auto-coder" / ".autocodertools"),
        priority=3,
        validation_mode=ValidationMode.HAS_FILES
    )

    # 4. ~/.auto-coder/.autocodertools/repos/<é¡¹ç›®å> (é¡¹ç›®ç‰¹å®šå…¨å±€)
    # ç”¨äºç‰¹å®šé¡¹ç›®çš„å…¨å±€å·¥å…·ï¼ˆè·¨å·¥ä½œåŒºå…±äº«ï¼‰
    config.add_directory(
        str(home_dir / ".auto-coder" / ".autocodertools" / "repos" / project_name),
        priority=4,
        validation_mode=ValidationMode.HAS_FILES
    )

    # æ‰§è¡ŒæŸ¥æ‰¾
    finder = PriorityDirectoryFinder(config)
    result = finder.find_directories()

    if result.success:
        logger.info(f"æ‰¾åˆ°å·¥å…·ç›®å½•: {result.all_valid_directories}")
        return result.all_valid_directories  # è¿”å›æŒ‰ä¼˜å…ˆçº§æ’åºçš„åˆ—è¡¨
    else:
        logger.warning("æœªæ‰¾åˆ°ä»»ä½•å·¥å…·ç›®å½•")
        return []
```

**å·¥å…·åŠ è½½ä¸å»é‡**:

```python
def load_tools(self, force_reload: bool = False) -> ToolsLoadResult:
    """
    åŠ è½½æ‰€æœ‰å·¥å…·å‘½ä»¤

    å·¥ä½œæµç¨‹ï¼š
    1. æ‰«ææ‰€æœ‰ä¼˜å…ˆçº§ç›®å½•
    2. è¯†åˆ«æœ‰æ•ˆçš„å·¥å…·æ–‡ä»¶ï¼ˆé€šè¿‡ is_tool_command_file åˆ¤æ–­ï¼‰
    3. æå–å¸®åŠ©ä¿¡æ¯ï¼ˆé€šè¿‡ extract_tool_helpï¼‰
    4. å»é‡å¤„ç†ï¼ˆé«˜ä¼˜å…ˆçº§ç›®å½•çš„å·¥å…·è¦†ç›–ä½ä¼˜å…ˆçº§çš„åŒåå·¥å…·ï¼‰

    Args:
        force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½ï¼ˆæ¸…é™¤ç¼“å­˜ï¼‰

    Returns:
        ToolsLoadResult: åŠ è½½ç»“æœ
    """
    # åˆ©ç”¨ç¼“å­˜é¿å…é‡å¤æ‰«æ
    if not force_reload and self._result_cache is not None:
        return self._result_cache

    all_tools = []
    failed_count = 0

    # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ‰«æç›®å½•
    for tools_dir in self.tools_dirs:
        if not os.path.exists(tools_dir):
            continue

        logger.debug(f"æ‰«æå·¥å…·ç›®å½•: {tools_dir}")

        try:
            for item in os.listdir(tools_dir):
                item_path = os.path.join(tools_dir, item)

                # åªå¤„ç†æ–‡ä»¶ï¼ˆä¸é€’å½’å­ç›®å½•ï¼‰
                if os.path.isfile(item_path) and is_tool_command_file(item_path):
                    try:
                        tool = self._create_tool_command(item_path, tools_dir)
                        if tool:
                            all_tools.append(tool)
                            logger.debug(f"åŠ è½½å·¥å…·: {tool.name}")
                        else:
                            failed_count += 1
                    except Exception as e:
                        logger.warning(f"åŠ è½½å·¥å…·æ–‡ä»¶å¤±è´¥ {item_path}: {e}")
                        failed_count += 1

        except OSError as e:
            logger.warning(f"è¯»å–å·¥å…·ç›®å½•å¤±è´¥ {tools_dir}: {e}")
            continue

    # å»é‡ï¼šå¦‚æœå¤šä¸ªç›®å½•ä¸­æœ‰åŒåå·¥å…·ï¼Œä¼˜å…ˆä½¿ç”¨é«˜ä¼˜å…ˆçº§ç›®å½•ä¸­çš„
    unique_tools = self._deduplicate_tools(all_tools)

    result = ToolsLoadResult(
        success=True,
        tools=unique_tools,
        failed_count=failed_count
    )
    # ç¼“å­˜ç»“æœ
    self._result_cache = result

    return result
```

**å·¥å…·æ–‡ä»¶è¯†åˆ«é€»è¾‘**ï¼ˆ`utils.py`ï¼‰:

```python
def is_tool_command_file(file_path: str) -> bool:
    """
    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å·¥å…·å‘½ä»¤æ–‡ä»¶

    åˆ¤æ–­æ ‡å‡†ï¼š
    1. æ–‡ä»¶å¿…é¡»å­˜åœ¨ä¸”æ˜¯æ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
    2. æ–‡ä»¶æ‰©å±•åå¿…é¡»åœ¨æ”¯æŒåˆ—è¡¨ä¸­
    3. å¯æ‰§è¡ŒäºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆæ— æ‰©å±•åï¼‰å¿…é¡»æœ‰æ‰§è¡Œæƒé™
    4. è„šæœ¬æ–‡ä»¶å¿…é¡»æœ‰å¯è¯»æƒé™

    Args:
        file_path: æ–‡ä»¶è·¯å¾„

    Returns:
        bool: æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å·¥å…·å‘½ä»¤æ–‡ä»¶
    """
    try:
        path = Path(file_path)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not path.exists() or not path.is_file():
            return False

        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        valid_extensions = {
            '.py',   # Python è„šæœ¬
            '.sh',   # Shell è„šæœ¬
            '.js',   # JavaScript è„šæœ¬
            '.rb',   # Ruby è„šæœ¬
            '.pl',   # Perl è„šæœ¬
            '.php',  # PHP è„šæœ¬
            '.go',   # Go è„šæœ¬ï¼ˆé€šå¸¸æ˜¯æºç ï¼Œä¸æ¨èï¼‰
            '.rs',   # Rust è„šæœ¬ï¼ˆé€šå¸¸æ˜¯æºç ï¼Œä¸æ¨èï¼‰
            ''       # æ— æ‰©å±•åï¼ˆç¼–è¯‘åçš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ¨èï¼‰
        }

        if path.suffix.lower() not in valid_extensions:
            return False

        # æƒé™æ£€æŸ¥
        if path.suffix == '':
            # æ— æ‰©å±•åæ–‡ä»¶ï¼Œå¿…é¡»å¯æ‰§è¡Œï¼ˆchmod +xï¼‰
            return os.access(file_path, os.X_OK)
        else:
            # è„šæœ¬æ–‡ä»¶ï¼Œå¿…é¡»å¯è¯»
            return os.access(file_path, os.R_OK)

    except Exception as e:
        logger.warning(f"æ£€æŸ¥å·¥å…·å‘½ä»¤æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")
        return False
```

**å¸®åŠ©ä¿¡æ¯æå–**ï¼ˆä¸¤ç§æ–¹å¼ï¼‰:

```python
def extract_tool_help(file_path: str) -> str:
    """
    æå–å·¥å…·å‘½ä»¤çš„å¸®åŠ©ä¿¡æ¯

    å°è¯•é¡ºåºï¼š
    1. å‘½ä»¤è¡Œå¸®åŠ©ï¼ˆæ‰§è¡Œ tool help / tool -h / tool --helpï¼‰
    2. æ–‡ä»¶æ³¨é‡Šå¤´éƒ¨ï¼ˆè§£ææ³¨é‡Šå—ï¼‰

    Args:
        file_path: å·¥å…·å‘½ä»¤æ–‡ä»¶è·¯å¾„

    Returns:
        str: å¸®åŠ©ä¿¡æ¯ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›é»˜è®¤ä¿¡æ¯
    """
    try:
        # æ–¹æ³•1: å°è¯•å‘½ä»¤è¡Œå¸®åŠ©
        help_text = _try_command_line_help(file_path)
        if help_text:
            return help_text

        # æ–¹æ³•2: å›é€€åˆ°æ–‡ä»¶æ³¨é‡Š
        return _extract_help_from_file_comments(file_path)

    except Exception as e:
        logger.debug(f"å¸®åŠ©ä¿¡æ¯æå–å¤±è´¥ {file_path}: {e}")
        return f"å·¥å…·å‘½ä»¤: {Path(file_path).name}"


def _try_command_line_help(file_path: str) -> Optional[str]:
    """
    å°è¯•é€šè¿‡å‘½ä»¤è¡Œè·å–å¸®åŠ©ä¿¡æ¯

    ä¾æ¬¡å°è¯•ä»¥ä¸‹å‘½ä»¤ï¼ˆä»»ä¸€æˆåŠŸå³è¿”å›ï¼‰ï¼š
    1. tool help
    2. tool -h
    3. tool --help

    Args:
        file_path: å·¥å…·æ–‡ä»¶è·¯å¾„

    Returns:
        Optional[str]: å¸®åŠ©ä¿¡æ¯ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›None
    """
    help_commands = [
        [file_path, 'help'],
        [file_path, '-h'],
        [file_path, '--help']
    ]

    for cmd in help_commands:
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,  # æ•è· stdout å’Œ stderr
                text=True,            # ä»¥æ–‡æœ¬æ¨¡å¼è¿”å›
                timeout=5,            # 5ç§’è¶…æ—¶
                cwd=Path(file_path).parent  # åœ¨å·¥å…·æ‰€åœ¨ç›®å½•æ‰§è¡Œ
            )
            # æˆåŠŸæ‰§è¡Œä¸”æœ‰è¾“å‡º
            if result.returncode == 0 and (result.stdout.strip() or result.stderr.strip()):
                return result.stdout.strip() or result.stderr.strip()
        except Exception:
            continue  # å°è¯•ä¸‹ä¸€ä¸ªå‘½ä»¤
    return None


def _extract_help_from_file_comments(file_path: str) -> str:
    """
    ä»æ–‡ä»¶æ³¨é‡Šä¸­æå–å¸®åŠ©ä¿¡æ¯

    æ”¯æŒçš„æ³¨é‡Šç¬¦å·ï¼š
    - Python/Shell/Ruby: #
    - JavaScript/Go/Rust: //

    æå–é€»è¾‘ï¼š
    1. è·³è¿‡ shebang è¡Œï¼ˆ#!/usr/bin/env pythonï¼‰
    2. æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„æ³¨é‡Šè¡Œï¼ˆUsage:, Help:, Description: ç­‰ï¼‰
    3. æå–åç»­è¿ç»­çš„æ³¨é‡Šè¡Œ
    4. é‡åˆ°è¿ç»­ä¸¤ä¸ªç©ºæ³¨é‡Šè¡Œæˆ–éæ³¨é‡Šè¡Œæ—¶åœæ­¢

    Args:
        file_path: æ–‡ä»¶è·¯å¾„

    Returns:
        str: ä»æ³¨é‡Šä¸­æå–çš„å¸®åŠ©ä¿¡æ¯
    """
    try:
        path = Path(file_path)

        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ³¨é‡Šç¬¦å·
        comment_patterns = {
            '.py': '#',
            '.sh': '#',
            '.rb': '#',
            '.pl': '#',
            '.php': '#',
            '.js': '//',
            '.go': '//',
            '.rs': '//',
            '': '#'  # é»˜è®¤ä½¿ç”¨ # æ³¨é‡Š
        }

        comment_char = comment_patterns.get(path.suffix.lower(), '#')

        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        help_lines = []
        in_help_section = False
        empty_comment_count = 0

        # åªæ£€æŸ¥å‰50è¡Œï¼ˆé¿å…æ‰«ææ•´ä¸ªæ–‡ä»¶ï¼‰
        for line in lines[:50]:
            line = line.strip()

            # è·³è¿‡ shebang è¡Œ
            if line.startswith('#!'):
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ³¨é‡Šè¡Œ
            if line.startswith(comment_char):
                comment_text = line[len(comment_char):].strip()

                # æ£€æŸ¥æ˜¯å¦æ˜¯å¸®åŠ©ä¿¡æ¯çš„å¼€å§‹ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
                if any(keyword in comment_text.lower() for keyword in
                       ['usage:', 'help:', 'description:', 'ç”¨æ³•:', 'è¯´æ˜:', 'æè¿°:']):
                    in_help_section = True
                    help_lines.append(comment_text)
                    empty_comment_count = 0
                elif in_help_section:
                    if comment_text:
                        help_lines.append(comment_text)
                        empty_comment_count = 0
                    else:
                        # ç©ºæ³¨é‡Šè¡Œï¼Œè®¡æ•°ä½†ä¸ç«‹å³åœæ­¢
                        empty_comment_count += 1
                        if empty_comment_count >= 2:
                            # è¿ç»­ä¸¤ä¸ªç©ºæ³¨é‡Šè¡Œï¼Œåœæ­¢æå–
                            break
            elif in_help_section:
                # éæ³¨é‡Šè¡Œï¼Œå¸®åŠ©ä¿¡æ¯ç»“æŸ
                break

        if help_lines:
            return '\n'.join(help_lines)
        else:
            return f"å·¥å…·å‘½ä»¤: {path.name}"

    except Exception as e:
        logger.warning(f"ä»æ–‡ä»¶æ³¨é‡Šæå–å¸®åŠ©ä¿¡æ¯æ—¶å‡ºé”™ {file_path}: {e}")
        return f"å·¥å…·å‘½ä»¤: {Path(file_path).name}"
```

**å»é‡é€»è¾‘**:

```python
def _deduplicate_tools(self, tools: List[ToolCommand]) -> List[ToolCommand]:
    """
    å»é‡å·¥å…·åˆ—è¡¨ï¼Œä¿ç•™é«˜ä¼˜å…ˆçº§ç›®å½•ä¸­çš„å·¥å…·

    è§„åˆ™ï¼š
    - åŒåå·¥å…·åªä¿ç•™ä¸€ä¸ª
    - ä¼˜å…ˆä¿ç•™æ¥è‡ªé«˜ä¼˜å…ˆçº§ç›®å½•çš„å·¥å…·
    - è®°å½•è¢«è¦†ç›–çš„å·¥å…·ï¼ˆæ—¥å¿—ï¼‰

    Args:
        tools: å·¥å…·åˆ—è¡¨

    Returns:
        List[ToolCommand]: å»é‡åçš„å·¥å…·åˆ—è¡¨
    """
    # åˆ›å»ºç›®å½•ä¼˜å…ˆçº§æ˜ å°„ï¼ˆç´¢å¼•è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
    dir_priority = {dir_path: idx for idx, dir_path in enumerate(self.tools_dirs)}

    # æŒ‰å·¥å…·åç§°åˆ†ç»„
    tools_by_name: Dict[str, List[ToolCommand]] = {}
    for tool in tools:
        if tool.name not in tools_by_name:
            tools_by_name[tool.name] = []
        tools_by_name[tool.name].append(tool)

    # å¯¹æ¯ä¸ªå·¥å…·åç§°ï¼Œé€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„å·¥å…·
    unique_tools = []
    for name, tool_list in tools_by_name.items():
        if len(tool_list) == 1:
            # åªæœ‰ä¸€ä¸ªï¼Œç›´æ¥æ·»åŠ 
            unique_tools.append(tool_list[0])
        else:
            # é€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„å·¥å…·ï¼ˆdir_priority å€¼æœ€å°ï¼‰
            best_tool = min(
                tool_list,
                key=lambda t: dir_priority.get(t.source_directory, 999)
            )
            unique_tools.append(best_tool)

            # è®°å½•è¢«è¦†ç›–çš„å·¥å…·
            for tool in tool_list:
                if tool != best_tool:
                    logger.debug(
                        f"å·¥å…· {name} åœ¨ {tool.source_directory} "
                        f"è¢« {best_tool.source_directory} ä¸­çš„ç‰ˆæœ¬è¦†ç›–"
                    )

    return unique_tools
```

### 2.4.6.3 ç”Ÿæˆ LLM å‹å¥½çš„æç¤ºè¯

**æ ¸å¿ƒæ–¹æ³•**: `get_tools_prompt()` ä½¿ç”¨ `@byzerllm.prompt()` è£…é¥°å™¨ç”Ÿæˆç»“æ„åŒ–çš„æç¤ºè¯ã€‚

```python
@byzerllm.prompt()
def get_tools_prompt(self) -> str:
    """
    ç”Ÿæˆå·¥å…·åˆ—è¡¨çš„ LLM æç¤ºè¯ï¼ˆJinja2 æ¨¡æ¿ï¼‰

    æ¨¡æ¿ç»“æ„ï¼š
    1. é¡¹ç›®ä¿¡æ¯ï¼ˆé¡¹ç›®åã€è·¯å¾„ã€å·¥å…·æ•°é‡ï¼‰
    2. å·¥å…·ç›®å½•åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    3. å·¥å…·è¯¦ç»†åˆ—è¡¨ï¼ˆæ¯ä¸ªå·¥å…·çš„åç§°ã€è·¯å¾„ã€å¸®åŠ©ä¿¡æ¯ï¼‰
    4. å·¥å…·å¼€å‘æŒ‡å—ï¼ˆå¦‚ä½•åˆ›å»ºæ–°å·¥å…·ï¼‰
    5. é‡è¦è§„åˆ™ï¼ˆå®‰å…¨ã€æœ€ä½³å®è·µï¼‰

    Returns:
        Dict: æ¨¡æ¿å˜é‡å­—å…¸ï¼ˆç”± byzerllm æ¡†æ¶å¤„ç†ï¼‰
    """
    '''
    # Available External Tool Commands

    Project Name: {{ project_name }}
    Current Project Path: {{ project_path }}
    Total Tools: {{ tools_count }}
    {% if failed_count > 0 %}
    Failed to Load: {{ failed_count }} tools
    {% endif %}

    ## Tool Directories
    {% for dir in tools_directories %}
    - {{ dir }}
    {% endfor %}

    ## Tool List

    {% if tools_count == 0 %}
    No available tool commands found.
    {% else %}
    {% for tool in tools_info %}
    ### {{ tool.name }}{{ tool.file_extension }}

    **Source Directory**: {{ tool.source_directory }}
    **Executable**: {% if tool.is_executable %}Yes{% else %}No{% endif %}

    **Usage Instructions**:
    ```
    {{ tool.help_text }}
    ```

    ---
    {% endfor %}
    {% endif %}

    ## How to Create External Tools

    ### Directory Structure (Priority Order)
    Tools are loaded from these directories in priority order (highest to lowest):
    1. **Project-specific**: `./.autocodertools/` (highest priority)
    2. **Project config**: `./.auto-coder/.autocodertools/` (**recommended**)
    3. **Global user**: `~/.auto-coder/.autocodertools/`
    4. **Project-specific global**: `~/.auto-coder/.autocodertools/repos/{{ project_name }}/` (lowest priority)

    > **Note**: Tools with identical names in higher priority directories will override those in lower priority directories.

    ### Supported File Types
    - **Executable binaries** (compiled tools, **recommended**)
    - **Script files** (`.sh`, `.py`, `.js`, `.rb`, etc.)

    ### Tool Development Guidelines

    Please use SubAgent to create new tools. New tools should follow
    the same guidelines as existing tools.

    #### 1. Help Information (Required)
    Your tool must provide help information using one of these methods:

    **Method 1: Command-line help (Recommended)**
    ```bash
    your_tool help
    your_tool -h
    your_tool --help
    ```

    **Method 2: File header comments**
    ```python
    #!/usr/bin/env python3
    # Description: Brief description of your tool
    # Usage: tool_name [options] [arguments]
    #
    # Options:
    #   -h, --help     Show this help message
    #   -v, --verbose  Enable verbose output
    ```

    #### 2. File Permissions
    - **Binary files** (no extension): Must be executable (`chmod +x`)
    - **Script files** (`.py`, `.sh`, etc.): Must be readable (`chmod +r`)

    #### 3. Tool Execution
    Use the built-in `execute_command` tool to run your custom tools.

    #### 4. **Tool is now available** - the AI assistant will discover and use it freely

    ## Important Rules
    1. If you use python, try to use uv to create project {{ autocoder_home }}/.auto-coder/tool_repos and run the tool. (we not recommend using python to build tools, please try to use Go first)
    1. **MANDATORY**: All tools MUST support `help` or `-h` parameter for detailed usage information
    2. **REQUIRED**: Always use a custom sub agent to create tools and set a proper timeout for sub agent task, e.g. 1800s. - never create tools directly
    3. **STRONGLY RECOMMENDED**: Prefer Go for building toolsï¼Œ here is the steps:
       - Create a tool project in {{ autocoder_home }}/.auto-coder/tool_repos
       - Ask the subagent to develop and build the binary in the tool directory (with proper timeout). The command should like this: cd <tool directory> && echo '<prompt>' | auto-coder.run --model <model_name> --is-sub-agent --verbose
       - Copy the final binary to `./.auto-coder/.autocodertools/` after completion
       - If no binary is found in the directory, request the subagent to rebuild the tool
    '''

    # åŠ è½½æ‰€æœ‰å·¥å…·
    result = self.load_tools()

    if not result.success:
        return {
            "project_name": get_project_name(),
            "project_path": os.getcwd(),
            "autocoder_home": os.path.expanduser("~"),
            "tools_count": 0,
            "tools_info": [],
            "failed_count": 0,
            "tools_directories": self.tools_dirs,
            "error_message": result.error_message or "æœªæ‰¾åˆ°ä»»ä½•å·¥å…·"
        }

    # å‡†å¤‡å·¥å…·ä¿¡æ¯åˆ—è¡¨
    tools_info = []
    for tool in result.tools:
        tools_info.append({
            "name": tool.name,
            "help_text": tool.help_text,
            "is_executable": tool.is_executable,
            "file_extension": tool.file_extension,
            "source_directory": tool.source_directory
        })

    project_name = get_project_name()

    return {
        "project_name": project_name,
        "project_path": os.getcwd(),
        "autocoder_home": os.path.expanduser("~"),
        "tools_count": len(result.tools),
        "tools_info": tools_info,
        "failed_count": result.failed_count,
        "tools_directories": self.tools_dirs
    }
```

**ç”Ÿæˆçš„æç¤ºè¯ç¤ºä¾‹**ï¼ˆå‡è®¾æœ‰2ä¸ªå·¥å…·ï¼‰:

```markdown
# Available External Tool Commands

Project Name: cuscli
Current Project Path: /projects/cuscli
Total Tools: 2

## Tool Directories
- /projects/cuscli/.auto-coder/.autocodertools
- /home/user/.auto-coder/.autocodertools

## Tool List

### search-code

**Source Directory**: /projects/cuscli/.auto-coder/.autocodertools
**Executable**: Yes

**Usage Instructions**:
```
Usage: search-code [options] <pattern>
Search for code patterns in the project

Options:
  -h, --help     Show this help message
  -i, --ignore   Case insensitive search
```

---

### deploy.sh

**Source Directory**: /projects/cuscli/.auto-coder/.autocodertools
**Executable**: No

**Usage Instructions**:
```
Description: Deploy the project to production
Usage: bash deploy.sh [environment]
```

---

## How to Create External Tools
...ï¼ˆçœç•¥è¯¦ç»†è¯´æ˜ï¼‰
```

### 2.4.6.4 ä¸ ToolRegistry çš„å…³ç³»å¯¹æ¯”

**å¯¹æ¯”è¡¨æ ¼**:

| **ç»´åº¦**               | **ToolsManager**                                       | **ToolRegistry**                                    |
|----------------------|--------------------------------------------------------|----------------------------------------------------|
| **ç®¡ç†å¯¹è±¡**           | å¤–éƒ¨å·¥å…·å‘½ä»¤ï¼ˆå¯æ‰§è¡Œæ–‡ä»¶ã€è„šæœ¬ï¼‰                       | å†…ç½®å·¥å…·ç±»ï¼ˆPython ç±»ï¼Œç»§æ‰¿ BaseToolï¼‰              |
| **å·¥å…·æ¥æº**           | æ–‡ä»¶ç³»ç»Ÿï¼ˆ.autocodertools ç›®å½•ï¼‰                      | ä»£ç æ³¨å†Œï¼ˆregister_tool æ–¹æ³•ï¼‰                      |
| **å·¥å…·æ ¼å¼**           | ä»»æ„å¯æ‰§è¡Œæ–‡ä»¶ï¼ˆäºŒè¿›åˆ¶ã€Shellã€Python è„šæœ¬ç­‰ï¼‰         | ç»“æ„åŒ– Pydantic æ¨¡å‹ï¼ˆXML åºåˆ—åŒ–ï¼‰                  |
| **ä¼˜å…ˆçº§æœºåˆ¶**         | å¤šå±‚ç›®å½•ä¼˜å…ˆçº§ï¼ˆé¡¹ç›® > å…¨å±€ï¼‰                         | é»˜è®¤å·¥å…· vs æ‰©å±•å·¥å…·                                |
| **æ‰§è¡Œæ–¹å¼**           | é€šè¿‡ execute_command å·¥å…·é—´æ¥è°ƒç”¨                     | é€šè¿‡ Resolver ç›´æ¥æ‰§è¡Œï¼ˆagent.resolve()ï¼‰           |
| **LLM æ„ŸçŸ¥æ–¹å¼**       | ä½œä¸ºæç¤ºè¯çš„ä¸€éƒ¨åˆ†æ³¨å…¥ï¼ˆget_tools_promptï¼‰            | ä½œä¸º XML å·¥å…·æè¿°æ³¨å…¥ï¼ˆToolRegistry.get_all_tool_descriptionsï¼‰ |
| **å…¸å‹ç”¨ä¾‹**           | é¡¹ç›®ç‰¹å®šçš„æ„å»ºã€éƒ¨ç½²ã€æµ‹è¯•è„šæœ¬                         | read_fileã€write_to_fileã€search_files ç­‰é€šç”¨æ“ä½œ  |
| **æ‰©å±•æ€§**             | æ— éœ€ä¿®æ”¹ä»£ç ï¼Œç›´æ¥æ·»åŠ æ–‡ä»¶å³å¯                         | éœ€è¦ç¼–å†™ Tool ç±»å’Œ Resolver ç±»                      |
| **å®‰å…¨æ€§**             | ä¾èµ–æ–‡ä»¶æƒé™æ§åˆ¶ï¼ˆchmodï¼‰                              | é€šè¿‡ Resolver é€»è¾‘æ§åˆ¶                              |

**ååŒå·¥ä½œç¤ºä¾‹**:

```python
# BaseAgent.__init__ ä¸­åŒæ—¶æ³¨å†Œä¸¤ç§å·¥å…·
class BaseAgent:
    def __init__(self, ...):
        # 1. æ³¨å†Œå†…ç½®å·¥å…·ï¼ˆToolRegistryï¼‰
        register_default_tools(params=self._render_context(), default_tools_list=default_tools_list)

        # 2. åŠ è½½å¤–éƒ¨å·¥å…·ï¼ˆToolsManagerï¼‰
        tools_manager = ToolsManager()
        tools_prompt = tools_manager.get_tools_prompt()

        # 3. å°†å¤–éƒ¨å·¥å…·æç¤ºè¯æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯ä¸­
        system_prompt = self._system.prompt(request)  # åŒ…å« ToolRegistry çš„å·¥å…·
        # tools_prompt ä¼šåœ¨ _system æ¨¡æ¿ä¸­é€šè¿‡ extra_docs æˆ–å…¶ä»–æ–¹å¼æ³¨å…¥
```

**LLM ä½¿ç”¨æµç¨‹**:

1. **å†…ç½®å·¥å…·**: LLM ç›´æ¥ç”Ÿæˆ XML â†’ BaseAgent è§£æ â†’ ToolRegistry æŸ¥æ‰¾ Resolver â†’ æ‰§è¡Œ
2. **å¤–éƒ¨å·¥å…·**: LLM ç”Ÿæˆ execute_command å·¥å…·è°ƒç”¨ â†’ ExecuteCommandResolver æ‰§è¡Œ â†’ è°ƒç”¨å¤–éƒ¨å·¥å…·æ–‡ä»¶

---

## 2.4.3 ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£æ³¨å…¥(æ‰©å±•) - LLMFriendlyPackageManager å®ç°

### 2.4.3.1 LLMFriendlyPackageManager ç±»æ¦‚è§ˆ

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/llm_friendly_package/main_manager.py`

LLMFriendlyPackageManager æä¾›äº†ä¸€å¥—å®Œæ•´çš„ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£ç®¡ç†ç³»ç»Ÿï¼Œç”¨äºä¸º LLM æ³¨å…¥å¤–éƒ¨åº“çš„ä½¿ç”¨æ–‡æ¡£ï¼Œå¸®åŠ© LLM ç†è§£å’Œæ­£ç¡®ä½¿ç”¨é¡¹ç›®ä¾èµ–çš„ç¬¬ä¸‰æ–¹åº“ã€‚

**æ ¸å¿ƒåŠŸèƒ½æ¨¡å—**:
1. **åº“ç®¡ç†** (Library Management): æ·»åŠ ã€åˆ é™¤ã€åˆ—å‡ºå·²æ·»åŠ çš„åº“
2. **æ–‡æ¡£ç®¡ç†** (Documentation Management): è·å–åº“çš„æ–‡æ¡£å†…å®¹æˆ–è·¯å¾„
3. **ä»“åº“ç®¡ç†** (Repository Management): å…‹éš†ã€åˆ·æ–°ã€ä»£ç†è®¾ç½®
4. **å±•ç¤ºç®¡ç†** (Display Management): è¡¨æ ¼åŒ–å±•ç¤ºåº“åˆ—è¡¨å’Œæ–‡æ¡£è·¯å¾„

**ä¾èµ–å…³ç³»**:
```python
from autocoder.common.core_config import get_memory_manager  # æŒä¹…åŒ–å­˜å‚¨
from .models import LibraryInfo, LibraryList, DocsList, RepositoryInfo  # æ•°æ®æ¨¡å‹
from rich.console import Console  # ç»ˆç«¯ç¾åŒ–è¾“å‡º
from git import GitCommandError  # Git æ“ä½œ
```

**åˆå§‹åŒ–æµç¨‹**:

```python
def __init__(self, project_root: Optional[str] = None):
    """
    åˆå§‹åŒ–åŒ…ç®¡ç†å™¨

    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•
    """
    self.project_root = project_root or os.getcwd()

    # è·å–æŒä¹…åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆåŸºäºé¡¹ç›®æ ¹ç›®å½•ï¼‰
    self.memory_manager = get_memory_manager(self.project_root)

    # åˆå§‹åŒ– Rich æ§åˆ¶å°ï¼ˆç”¨äºç¾åŒ–è¾“å‡ºï¼‰
    self.console = Console()

    # è®¾ç½®ç›®å½•è·¯å¾„
    # .auto-coder/libs: åº“ç›¸å…³æ–‡ä»¶çš„å­˜å‚¨æ ¹ç›®å½•
    self.lib_dir = os.path.join(self.project_root, ".auto-coder", "libs")

    # .auto-coder/libs/llm_friendly_packages: å…‹éš†çš„æ–‡æ¡£ä»“åº“ç›®å½•
    self.llm_friendly_packages_dir = os.path.join(self.lib_dir, "llm_friendly_packages")

    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    self._ensure_dirs()
```

**ç›®å½•ç»“æ„è®¾è®¡**:
```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ .auto-coder/
â”‚   â”œâ”€â”€ libs/                          # åº“æ–‡ä»¶æ ¹ç›®å½•
â”‚   â”‚   â””â”€â”€ llm_friendly_packages/     # å…‹éš†çš„æ–‡æ¡£ä»“åº“
â”‚   â”‚       â””â”€â”€ github.com/            # åŸŸå
â”‚   â”‚           â””â”€â”€ username/          # ç”¨æˆ·å
â”‚   â”‚               â””â”€â”€ library_name/  # åº“å
â”‚   â”‚                   â”œâ”€â”€ README.md
â”‚   â”‚                   â”œâ”€â”€ usage.md
â”‚   â”‚                   â””â”€â”€ api.md
â”‚   â””â”€â”€ memory/                        # æŒä¹…åŒ–é…ç½®ï¼ˆç”± memory_manager ç®¡ç†ï¼‰
â”‚       â””â”€â”€ libs.json                  # å·²æ·»åŠ çš„åº“åˆ—è¡¨
```

### 2.4.3.2 æ–‡æ¡£ä»“åº“æ¶æ„ä¸å…‹éš†æœºåˆ¶

**é»˜è®¤æ–‡æ¡£ä»“åº“**:

```python
@property
def default_proxy_url(self) -> str:
    """è·å–é»˜è®¤çš„æ–‡æ¡£ä»“åº“ URL"""
    return "https://github.com/allwefantasy/llm_friendly_packages"

def _get_current_proxy(self) -> str:
    """ä» memory_manager ä¸­è·å–å½“å‰é…ç½®çš„ä»“åº“ URL"""
    return self.memory_manager.get_config("lib-proxy", self.default_proxy_url)
```

**ä»“åº“å…‹éš†æµç¨‹**:

```python
def _clone_repository(self) -> bool:
    """
    å…‹éš† llm_friendly_packages æ–‡æ¡£ä»“åº“

    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²å­˜åœ¨ä»“åº“ç›®å½•
    2. å¦‚æœä¸å­˜åœ¨ï¼Œä»é…ç½®çš„ proxy URL å…‹éš†
    3. ä½¿ç”¨ GitPython åº“æ‰§è¡Œå…‹éš†æ“ä½œ

    Returns:
        bool: å…‹éš†æˆåŠŸè¿”å› Trueï¼Œå¤±è´¥è¿”å› False
    """
    # å¦‚æœå·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›æˆåŠŸ
    if os.path.exists(self.llm_friendly_packages_dir):
        return True

    self.console.print("æ­£åœ¨å…‹éš† llm_friendly_packages ä»“åº“...")

    try:
        # è·å–å½“å‰é…ç½®çš„ä»“åº“ URLï¼ˆæ”¯æŒé•œåƒä»£ç†ï¼‰
        proxy_url = self._get_current_proxy()

        # æ‰§è¡Œ git clone æ“ä½œ
        git.Repo.clone_from(proxy_url, self.llm_friendly_packages_dir)

        self.console.print("æˆåŠŸå…‹éš† llm_friendly_packages ä»“åº“")
        return True

    except GitCommandError as e:
        self.console.print(f"å…‹éš†ä»“åº“å¤±è´¥: {e}")
        return False
```

**ä»“åº“åˆ·æ–°æœºåˆ¶**:

```python
def refresh_repository(self) -> bool:
    """
    åˆ·æ–°ä»“åº“ï¼ˆæ‹‰å–æœ€æ–°æ–‡æ¡£ï¼‰

    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æŸ¥ä»“åº“æ˜¯å¦å­˜åœ¨
    2. å¦‚æœ proxy URL å‘ç”Ÿå˜åŒ–ï¼Œæ›´æ–° remote URL
    3. æ‰§è¡Œ git pull æ‹‰å–æœ€æ–°æ›´æ”¹

    Returns:
        bool: åˆ·æ–°æˆåŠŸè¿”å› Trueï¼Œå¤±è´¥è¿”å› False
    """
    if not os.path.exists(self.llm_friendly_packages_dir):
        self.console.print(
            "llm_friendly_packages ä»“åº“ä¸å­˜åœ¨ï¼Œè¯·å…ˆè°ƒç”¨ add_library() å…‹éš†ä»“åº“"
        )
        return False

    try:
        # æ‰“å¼€æœ¬åœ° Git ä»“åº“
        repo = git.Repo(self.llm_friendly_packages_dir)
        origin = repo.remotes.origin

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–° remote URLï¼ˆæ”¯æŒåˆ‡æ¢é•œåƒï¼‰
        proxy_url = self._get_current_proxy()
        current_url = origin.url

        if proxy_url and proxy_url != current_url:
            origin.set_url(proxy_url)
            self.console.print(f"æ›´æ–° remote URL ä¸º: {proxy_url}")

        # æ‹‰å–æœ€æ–°æ›´æ”¹
        origin.pull()
        self.console.print("æˆåŠŸæ›´æ–° llm_friendly_packages ä»“åº“")
        return True

    except GitCommandError as e:
        self.console.print(f"æ›´æ–°ä»“åº“å¤±è´¥: {e}")
        return False
```

**ä»£ç†è®¾ç½®æ”¯æŒ**:

```python
def set_proxy(self, proxy_url: Optional[str] = None) -> str:
    """
    è®¾ç½®æˆ–è·å–ä»“åº“ä»£ç† URL

    ç”¨é€”ï¼šæ”¯æŒä½¿ç”¨é•œåƒç«™ç‚¹åŠ é€Ÿä»“åº“è®¿é—®ï¼ˆå¦‚ Giteeã€GitLabï¼‰

    Args:
        proxy_url: æ–°çš„ä»£ç† URLï¼Œå¦‚æœä¸º None åˆ™åªè¿”å›å½“å‰é…ç½®

    Returns:
        str: å½“å‰çš„ä»£ç† URL
    """
    if proxy_url is None:
        # åªæŸ¥è¯¢å½“å‰é…ç½®
        current_proxy = self._get_current_proxy()
        self.console.print(f"å½“å‰ä»£ç†: {current_proxy}")
        return current_proxy

    # ä¿å­˜æ–°çš„ä»£ç† URL åˆ°æŒä¹…åŒ–é…ç½®
    self.memory_manager.set_config("lib-proxy", proxy_url)
    self.console.print(f"å·²è®¾ç½®ä»£ç†ä¸º: {proxy_url}")
    return proxy_url
```

### 2.4.3.3 æ–‡æ¡£åŠ è½½ä¸æ ¼å¼åŒ–

**æ ¸å¿ƒæ–¹æ³•: get_docs()**

è¿™æ˜¯æ–‡æ¡£ç®¡ç†çš„æ ¸å¿ƒæ–¹æ³•ï¼Œè´Ÿè´£ä»å·²æ·»åŠ çš„åº“ä¸­æå– Markdown æ–‡æ¡£å†…å®¹æˆ–è·¯å¾„ï¼š

```python
def get_docs(self, package_name: Optional[str] = None, return_paths: bool = False) -> DocsList:
    """
    è·å–åº“çš„æ–‡æ¡£å†…å®¹æˆ–è·¯å¾„

    Args:
        package_name: æŒ‡å®šåº“åï¼ˆNone è¡¨ç¤ºè·å–æ‰€æœ‰å·²æ·»åŠ åº“çš„æ–‡æ¡£ï¼‰
        return_paths: True è¿”å›æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ŒFalse è¿”å›æ–‡ä»¶å†…å®¹åˆ—è¡¨

    Returns:
        DocsList: æ–‡æ¡£å†…å®¹åˆ—è¡¨æˆ–è·¯å¾„åˆ—è¡¨

    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æŸ¥ä»“åº“ç›®å½•æ˜¯å¦å­˜åœ¨
    2. è·å–å·²æ·»åŠ çš„åº“åˆ—è¡¨ï¼ˆä» memory_managerï¼‰
    3. éå†ä»“åº“ç›®å½•ç»“æ„ï¼šdomain/username/lib_name/
    4. å¯¹åŒ¹é…çš„åº“ï¼Œé€’å½’æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶
    5. æ ¹æ® return_paths å‚æ•°è¿”å›è·¯å¾„æˆ–å†…å®¹
    """
    docs = []

    # æ£€æŸ¥ä»“åº“æ˜¯å¦å­˜åœ¨
    if not os.path.exists(self.llm_friendly_packages_dir):
        return docs

    # è·å–å·²æ·»åŠ çš„åº“åˆ—è¡¨ï¼ˆåªå¤„ç†ç”¨æˆ·æ˜¾å¼æ·»åŠ çš„åº“ï¼‰
    libs = list(self.memory_manager.get_libs().keys())

    # éå†ä»“åº“çš„ä¸‰å±‚ç›®å½•ç»“æ„
    for domain in os.listdir(self.llm_friendly_packages_dir):
        domain_path = os.path.join(self.llm_friendly_packages_dir, domain)
        if not os.path.isdir(domain_path):
            continue

        for username in os.listdir(domain_path):
            username_path = os.path.join(domain_path, username)
            if not os.path.isdir(username_path):
                continue

            for lib_name in os.listdir(username_path):
                lib_path = os.path.join(username_path, lib_name)

                if not os.path.isdir(lib_path):
                    continue

                # æ£€æŸ¥æ˜¯å¦æ˜¯è¯·æ±‚çš„åº“ï¼ˆæ”¯æŒ "lib_name" æˆ– "username/lib_name"ï¼‰
                if package_name is not None:
                    if not (lib_name == package_name or
                           package_name == os.path.join(username, lib_name)):
                        continue

                # æ£€æŸ¥åº“æ˜¯å¦åœ¨å·²æ·»åŠ åˆ—è¡¨ä¸­
                if lib_name not in libs:
                    continue

                # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶
                for root, _, files in os.walk(lib_path):
                    for file in files:
                        if file.endswith(".md"):
                            file_path = os.path.join(root, file)

                            if return_paths:
                                # è¿”å›è·¯å¾„æ¨¡å¼
                                docs.append(file_path)
                            else:
                                # è¿”å›å†…å®¹æ¨¡å¼
                                try:
                                    with open(file_path, "r", encoding="utf-8") as f:
                                        docs.append(f.read())
                                except Exception as e:
                                    self.console.print(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    return docs
```

**ä¾¿æ·æ–¹æ³•**:

```python
def get_library_docs_paths(self, package_name: str) -> List[str]:
    """è·å–æŒ‡å®šåº“çš„æ–‡æ¡£è·¯å¾„åˆ—è¡¨"""
    return self.get_docs(package_name, return_paths=True)

def get_library_docs_content(self, package_name: str) -> List[str]:
    """è·å–æŒ‡å®šåº“çš„æ–‡æ¡£å†…å®¹åˆ—è¡¨"""
    return self.get_docs(package_name, return_paths=False)
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# åˆå§‹åŒ–ç®¡ç†å™¨
pkg_manager = LLMFriendlyPackageManager()

# æ·»åŠ åº“ï¼ˆä¼šè‡ªåŠ¨å…‹éš†ä»“åº“ï¼‰
pkg_manager.add_library("byzerllm")

# è·å–åº“çš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼ˆç”¨äºæ³¨å…¥åˆ° LLM æç¤ºè¯ï¼‰
docs_content = pkg_manager.get_library_docs_content("byzerllm")
# è¿”å›: ["# ByzerLLM\n\n...", "## API Reference\n\n..."]

# è·å–åº“çš„æ‰€æœ‰æ–‡æ¡£è·¯å¾„ï¼ˆç”¨äºæ˜¾ç¤ºæˆ–è¿›ä¸€æ­¥å¤„ç†ï¼‰
docs_paths = pkg_manager.get_library_docs_paths("byzerllm")
# è¿”å›: ["/path/to/.auto-coder/libs/llm_friendly_packages/github.com/allwefantasy/byzerllm/README.md", ...]

# è·å–æ‰€æœ‰å·²æ·»åŠ åº“çš„æ–‡æ¡£ï¼ˆä¸æŒ‡å®š package_nameï¼‰
all_docs = pkg_manager.get_docs()
```

**æ–‡æ¡£æ³¨å…¥åˆ°æç¤ºè¯**:

åœ¨ `AgenticEdit._analyze()` æ–¹æ³•ä¸­ï¼Œä¼šè°ƒç”¨ `get_library_docs_content()` è·å–æ‰€æœ‰å·²æ·»åŠ åº“çš„æ–‡æ¡£å†…å®¹ï¼Œå¹¶æ ¼å¼åŒ–åæ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯çš„ `{{lib_docs}}` å ä½ç¬¦ä¸­ï¼š

```python
# ä¼ªä»£ç ç¤ºä¾‹
lib_docs_content = []
for lib in pkg_manager.list_added_libraries():
    docs = pkg_manager.get_library_docs_content(lib)
    lib_docs_content.extend(docs)

# æ ¼å¼åŒ–ä¸ºæç¤ºè¯æ®µè½
lib_docs_section = "\n\n".join([
    f"## Library: {lib}\n\n{doc}"
    for lib, doc in zip(libs, lib_docs_content)
])

# æ³¨å…¥åˆ°æ¨¡æ¿å˜é‡
template_vars["lib_docs"] = lib_docs_section
```

è¿™æ ·ï¼ŒLLM å°±èƒ½å¤Ÿåœ¨æ‰§è¡Œä»»åŠ¡æ—¶å‚è€ƒè¿™äº›ç¬¬ä¸‰æ–¹åº“çš„æ–‡æ¡£ï¼Œæ­£ç¡®ä½¿ç”¨åº“çš„ API å’ŒåŠŸèƒ½ã€‚

---
## 2.4.4 ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™æ³¨å…¥(æ‰©å±•) - Rules æ–‡ä»¶æ ¼å¼è¯¦è§£

### 2.4.4.1 AutocoderRulesManager ç±»è¯¦è§£

**æºæ–‡ä»¶ä½ç½®**: `/projects/cuscli/autocoder/common/rulefiles/core/manager.py`

AutocoderRulesManager è´Ÿè´£åŠ è½½ã€ç›‘æ§å’Œç®¡ç†è§„åˆ™æ–‡ä»¶ï¼ˆMarkdown æ ¼å¼ + YAML metadataï¼‰ï¼Œå®ç°å•ä¾‹æ¨¡å¼ç¡®ä¿å…¨å±€å”¯ä¸€ã€‚

**æ ¸å¿ƒè®¾è®¡**:

```python
class AutocoderRulesManager:
    """
    ç®¡ç† autocoderrules ç›®å½•ä¸­çš„è§„åˆ™æ–‡ä»¶ã€‚

    å®ç°å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªè§„åˆ™ç®¡ç†å®ä¾‹ã€‚
    æ¯æ¬¡è®¿é—®æ—¶éƒ½ä¼šé‡æ–°åŠ è½½è§„åˆ™æ–‡ä»¶ï¼ˆæ”¯æŒçƒ­æ›´æ–°ï¼‰ã€‚
    """
    _instance = None
    _lock = Lock()  # çº¿ç¨‹é”ï¼Œä¿æŠ¤å•ä¾‹åˆ›å»º

    def __new__(cls, project_root: Optional[str] = None):
        """å•ä¾‹æ¨¡å¼å®ç°"""
        if not cls._instance:
            with cls._lock:
                if not cls._instance:  # åŒé‡æ£€æŸ¥é”å®š
                    cls._instance = super(AutocoderRulesManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self, project_root: Optional[str] = None):
        """
        åˆå§‹åŒ–è§„åˆ™ç®¡ç†å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•
        """
        if self._initialized:
            return  # é¿å…é‡å¤åˆå§‹åŒ–
        self._initialized = True

        # å†…éƒ¨çŠ¶æ€
        self._rules: Dict[str, str] = {}  # å­˜å‚¨è§„åˆ™æ–‡ä»¶å†…å®¹: {file_path: content}
        self._rules_dir: Optional[str] = None  # å½“å‰ä½¿ç”¨çš„è§„åˆ™ç›®å½•
        self._project_root = project_root if project_root is not None else os.getcwd()

        # é¦–æ¬¡åŠ è½½è§„åˆ™
        self._load_rules()
```

**è§„åˆ™åŠ è½½é€»è¾‘**ï¼ˆä¸‰å±‚ä¼˜å…ˆçº§ï¼‰:

```python
def _load_rules(self):
    """
    é‡æ–°å®ç°çš„è§„åˆ™åŠ è½½é€»è¾‘ï¼Œä¸ä½¿ç”¨ FinderConfigã€‚

    åŠ è½½é¡ºåºï¼š
    1. é¡¹ç›®çº§è§„åˆ™æ–‡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
       - .autocoderrules/
       - .auto-coder/.autocoderrules/
       - .auto-coder/autocoderrules/
    2. å…¨å±€è§„åˆ™æ–‡ä»¶
       - ~/.auto-coder/autocoderrules/
    3. å…¨å±€ repos å­ç›®å½•è§„åˆ™ï¼ˆåŸºäºå½“å‰ç›®å½•åï¼‰
       - ~/.auto-coder/autocoderrules/repos/<é¡¹ç›®å>/

    ç¡®ä¿ä¸é‡å¤åŠ è½½ç›¸åŒçš„æ–‡ä»¶ï¼ˆé€šè¿‡è§„èŒƒåŒ–è·¯å¾„ï¼‰ã€‚
    """
    self._rules = {}
    loaded_files: Set[str] = set()  # è·Ÿè¸ªå·²åŠ è½½çš„æ–‡ä»¶ï¼Œé¿å…é‡å¤

    # 1. åŠ è½½é¡¹ç›®çº§è§„åˆ™æ–‡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    self._load_project_rules(loaded_files)

    # 2. åŠ è½½å…¨å±€è§„åˆ™æ–‡ä»¶
    self._load_global_rules(loaded_files)

    # 3. åŠ è½½å…¨å±€ repos å­ç›®å½•è§„åˆ™
    self._load_global_repos_rules(loaded_files)

    logger.info(f"æ€»å…±åŠ è½½äº† {len(self._rules)} ä¸ªè§„åˆ™æ–‡ä»¶")

def _load_project_rules(self, loaded_files: Set[str]):
    """
    åŠ è½½é¡¹ç›®çº§è§„åˆ™æ–‡ä»¶ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåº

    ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. .autocoderrules/
    2. .auto-coder/.autocoderrules/
    3. .auto-coder/autocoderrules/

    åªä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ…å« .md æ–‡ä»¶çš„ç›®å½•ã€‚
    """
    project_root = self._project_root

    # æŒ‰ä¼˜å…ˆçº§å®šä¹‰é¡¹ç›®çº§è§„åˆ™ç›®å½•
    project_dirs = [
        os.path.join(project_root, ".autocoderrules"),
        os.path.join(project_root, ".auto-coder", ".autocoderrules"),
        os.path.join(project_root, ".auto-coder", "autocoderrules")
    ]

    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ…å« .md æ–‡ä»¶çš„ç›®å½•
    for rules_dir in project_dirs:
        if self._has_md_files(rules_dir):
            self._rules_dir = rules_dir
            logger.info(f"æ‰¾åˆ°é¡¹ç›®è§„åˆ™ç›®å½•: {rules_dir}")
            self._load_rules_from_directory(rules_dir, loaded_files)
            return  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆç›®å½•

    logger.info("æœªæ‰¾åˆ°é¡¹ç›®çº§è§„åˆ™ç›®å½•")

def _load_global_rules(self, loaded_files: Set[str]):
    """
    åŠ è½½å…¨å±€è§„åˆ™æ–‡ä»¶ (~/.auto-coder/autocoderrules)

    å…¨å±€è§„åˆ™é€‚ç”¨äºæ‰€æœ‰é¡¹ç›®ï¼Œé€šå¸¸åŒ…å«ï¼š
    - ç¼–ç è§„èŒƒ
    - é€šç”¨å®‰å…¨è§„åˆ™
    - å›¢é˜Ÿåä½œçº¦å®š
    """
    home_dir = os.path.expanduser("~")
    global_rules_dir = os.path.join(home_dir, ".auto-coder", "autocoderrules")

    if self._has_md_files(global_rules_dir):
        logger.info(f"æ‰¾åˆ°å…¨å±€è§„åˆ™ç›®å½•: {global_rules_dir}")
        self._load_rules_from_directory(global_rules_dir, loaded_files)
    else:
        logger.info("æœªæ‰¾åˆ°å…¨å±€è§„åˆ™ç›®å½•")

def _load_global_repos_rules(self, loaded_files: Set[str]):
    """
    åŠ è½½å…¨å±€ repos å­ç›®å½•è§„åˆ™ï¼ˆåŸºäºå½“å‰ç›®å½•åï¼‰

    ç›®å½•ç»“æ„ï¼š~/.auto-coder/autocoderrules/repos/<é¡¹ç›®å>/

    é€‚ç”¨åœºæ™¯ï¼š
    - ç‰¹å®šé¡¹ç›®çš„å…¨å±€è§„åˆ™ï¼ˆè·¨å·¥ä½œåŒºå…±äº«ï¼‰
    - å¤šäººåä½œæ—¶çš„é¡¹ç›®ç‰¹å®šè§„èŒƒ
    """
    home_dir = os.path.expanduser("~")
    global_rules_dir = os.path.join(home_dir, ".auto-coder", "autocoderrules")
    repos_dir = os.path.join(global_rules_dir, "repos")

    if not os.path.isdir(repos_dir):
        logger.info("æœªæ‰¾åˆ°å…¨å±€ repos ç›®å½•")
        return

    # è·å–å½“å‰ç›®å½•åä½œä¸ºé¡¹ç›®å
    current_dir_name = os.path.basename(self._project_root)
    repo_specific_dir = os.path.join(repos_dir, current_dir_name)

    if self._has_md_files(repo_specific_dir):
        logger.info(f"æ‰¾åˆ°ä»“åº“ç‰¹å®šè§„åˆ™ç›®å½•: {repo_specific_dir}")
        self._load_rules_from_directory(repo_specific_dir, loaded_files)
    else:
        logger.info(f"æœªæ‰¾åˆ°ä»“åº“ç‰¹å®šè§„åˆ™ç›®å½•: {repo_specific_dir}")

def _has_md_files(self, directory: str) -> bool:
    """
    æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å« .md æ–‡ä»¶

    Args:
        directory: ç›®å½•è·¯å¾„

    Returns:
        bool: æ˜¯å¦åŒ…å« .md æ–‡ä»¶
    """
    if not os.path.isdir(directory):
        return False

    try:
        for fname in os.listdir(directory):
            if fname.endswith(".md"):
                return True
        return False
    except Exception as e:
        logger.warning(f"æ£€æŸ¥ç›®å½• {directory} æ—¶å‡ºé”™: {e}")
        return False

def _load_rules_from_directory(self, rules_dir: str, loaded_files: Set[str]):
    """
    ä»æŒ‡å®šç›®å½•åŠ è½½è§„åˆ™æ–‡ä»¶ï¼Œé¿å…é‡å¤åŠ è½½

    Args:
        rules_dir: è§„åˆ™ç›®å½•è·¯å¾„
        loaded_files: å·²åŠ è½½æ–‡ä»¶çš„è§„èŒƒåŒ–è·¯å¾„é›†åˆï¼ˆç”¨äºå»é‡ï¼‰
    """
    logger.info(f"æ‰«æè§„åˆ™ç›®å½•: {rules_dir}")
    try:
        for fname in os.listdir(rules_dir):
            if fname.endswith(".md"):
                fpath = os.path.join(rules_dir, fname)

                # ä½¿ç”¨è§„èŒƒåŒ–è·¯å¾„é¿å…é‡å¤åŠ è½½
                normalized_path = os.path.normpath(os.path.abspath(fpath))
                if normalized_path in loaded_files:
                    logger.info(f"è·³è¿‡é‡å¤æ–‡ä»¶: {fpath}")
                    continue

                try:
                    with open(fpath, "r", encoding="utf-8") as f:
                        content = f.read()
                        self._rules[fpath] = content
                        loaded_files.add(normalized_path)
                        logger.info(f"å·²åŠ è½½è§„åˆ™æ–‡ä»¶: {fpath}")
                except Exception as e:
                    logger.warning(f"åŠ è½½è§„åˆ™æ–‡ä»¶ {fpath} æ—¶å‡ºé”™: {e}")
                    continue
    except Exception as e:
        logger.warning(f"è¯»å–è§„åˆ™ç›®å½• {rules_dir} æ—¶å‡ºé”™: {e}")
```

### 2.4.4.2 Rules æ–‡ä»¶æ ¼å¼è§„èŒƒ

**æ ‡å‡†æ ¼å¼**: Markdown + YAML metadataï¼ˆå‰ç½®å…ƒæ•°æ®ï¼‰

```markdown
---
description: "Python ç¼–ç è§„èŒƒ"
globs:
  - "**/*.py"
alwaysApply: false
---

# Python ç¼–ç è§„èŒƒ

## å‘½åçº¦å®š

### å‡½æ•°å‘½å
- ä½¿ç”¨ snake_case é£æ ¼
- åŠ¨è¯å¼€å¤´ï¼Œæ¸…æ™°è¡¨è¾¾åŠŸèƒ½

**ç¤ºä¾‹**:
```python
def calculate_total_price(items):
    pass

def validate_user_input(data):
    pass
```

### ç±»å‘½å
- ä½¿ç”¨ PascalCase é£æ ¼
- åè¯æ€§çŸ­è¯­

**ç¤ºä¾‹**:
```python
class UserManager:
    pass

class DatabaseConnection:
    pass
```

## æ–‡æ¡£å­—ç¬¦ä¸²

æ‰€æœ‰å…¬å…±å‡½æ•°å’Œç±»å¿…é¡»åŒ…å« docstringã€‚

**ç¤ºä¾‹**:
```python
def process_data(input_data: List[Dict]) -> Dict:
    """
    å¤„ç†è¾“å…¥æ•°æ®å¹¶è¿”å›æ±‡æ€»ç»“æœ

    Args:
        input_data: åŒ…å«åŸå§‹æ•°æ®çš„å­—å…¸åˆ—è¡¨

    Returns:
        Dict: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸

    Raises:
        ValueError: å½“è¾“å…¥æ•°æ®æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    pass
```

## ç±»å‹æ³¨è§£

Python 3.6+ å¿…é¡»ä½¿ç”¨ç±»å‹æ³¨è§£ã€‚

**ç¤ºä¾‹**:
```python
from typing import List, Dict, Optional

def find_user(user_id: int) -> Optional[Dict[str, Any]]:
    pass
```
```

**YAML Metadata å­—æ®µè¯´æ˜**:

| **å­—æ®µ**       | **ç±»å‹**        | **è¯´æ˜**                                                                 | **ç¤ºä¾‹**                        |
|--------------|---------------|------------------------------------------------------------------------|-------------------------------|
| `description` | `str`         | è§„åˆ™çš„ç®€çŸ­æè¿°ï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰                                         | "Python ç¼–ç è§„èŒƒ"              |
| `globs`       | `List[str]`   | æ–‡ä»¶åŒ¹é…æ¨¡å¼åˆ—è¡¨ï¼ˆglob æ ¼å¼ï¼‰ï¼Œå†³å®šè§„åˆ™åº”ç”¨äºå“ªäº›æ–‡ä»¶                    | `["**/*.py", "**/*.pyi"]`     |
| `alwaysApply` | `bool`        | æ˜¯å¦æ€»æ˜¯åº”ç”¨è¯¥è§„åˆ™ï¼ˆä¸å— globs é™åˆ¶ï¼‰<br>true: å¿…éœ€è§„åˆ™<br>false: æ¡ä»¶è§„åˆ™ | `false`                       |

**æ•°æ®æ¨¡å‹å®šä¹‰**ï¼ˆ`models/rule_file.py`ï¼‰:

```python
from typing import List
from pydantic import BaseModel, Field

class RuleFile(BaseModel):
    """è§„åˆ™æ–‡ä»¶çš„Pydanticæ¨¡å‹"""
    description: str = Field(default="", description="è§„åˆ™çš„æè¿°")
    globs: List[str] = Field(default_factory=list, description="æ–‡ä»¶åŒ¹é…æ¨¡å¼åˆ—è¡¨")
    always_apply: bool = Field(default=False, description="æ˜¯å¦æ€»æ˜¯åº”ç”¨è§„åˆ™")
    content: str = Field(default="", description="è§„åˆ™æ–‡ä»¶çš„æ­£æ–‡å†…å®¹ï¼ˆMarkdownï¼‰")
    file_path: str = Field(default="", description="è§„åˆ™æ–‡ä»¶çš„è·¯å¾„")
```

### 2.4.4.3 è§„åˆ™æ–‡ä»¶è§£æä»£ç 

**è§£ææ–¹æ³•**:

```python
def parse_rule_file(self, file_path: str) -> RuleFile:
    """
    è§£æè§„åˆ™æ–‡ä»¶å¹¶è¿”å›ç»“æ„åŒ–çš„Pydanticæ¨¡å‹å¯¹è±¡

    è§£ææ­¥éª¤ï¼š
    1. è¯»å–æ–‡ä»¶å†…å®¹
    2. æå– YAML å¤´éƒ¨ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
    3. è§£æ YAML ä¸ºå­—å…¸
    4. æå– Markdown æ­£æ–‡ï¼ˆç§»é™¤ YAML éƒ¨åˆ†ï¼‰
    5. åˆ›å»º RuleFile æ¨¡å‹

    Args:
        file_path: è§„åˆ™æ–‡ä»¶çš„è·¯å¾„

    Returns:
        RuleFile: åŒ…å«è§„åˆ™æ–‡ä»¶ç»“æ„åŒ–å†…å®¹çš„Pydanticæ¨¡å‹
    """
    if not os.path.exists(file_path) or not file_path.endswith('.md'):
        logger.warning(f"æ— æ•ˆçš„è§„åˆ™æ–‡ä»¶è·¯å¾„: {file_path}")
        return RuleFile(file_path=file_path)

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… YAML å¤´éƒ¨ï¼ˆ---\n...\n---\nï¼‰
        yaml_pattern = re.compile(r'^---\s*\n(.*?)\n---\s*\n', re.DOTALL)
        yaml_match = yaml_pattern.search(content)

        metadata = {}
        markdown_content = content

        if yaml_match:
            yaml_content = yaml_match.group(1)
            try:
                # è§£æ YAML
                metadata = yaml.safe_load(yaml_content)
                # ç§»é™¤YAMLéƒ¨åˆ†ï¼Œä»…ä¿ç•™Markdownå†…å®¹
                markdown_content = content[yaml_match.end():]
            except Exception as e:
                logger.warning(f"è§£æè§„åˆ™æ–‡ä»¶YAMLå¤´éƒ¨æ—¶å‡ºé”™: {e}")

        # åˆ›å»ºå¹¶è¿”å›Pydanticæ¨¡å‹
        rule = RuleFile(
            description=metadata.get('description', ''),
            globs=metadata.get('globs', []),
            always_apply=metadata.get('alwaysApply', False),
            content=markdown_content.strip(),
            file_path=file_path
        )
        return rule

    except Exception as e:
        logger.warning(f"è§£æè§„åˆ™æ–‡ä»¶æ—¶å‡ºé”™: {file_path}, é”™è¯¯: {e}")
        return RuleFile(file_path=file_path)
```

**è·å–è§£æåçš„è§„åˆ™**:

```python
def get_parsed_rules(self) -> List[RuleFile]:
    """
    è·å–æ‰€æœ‰è§£æåçš„è§„åˆ™æ–‡ä»¶ï¼Œæ€»æ˜¯é‡æ–°åŠ è½½

    Returns:
        List[RuleFile]: è§£æåçš„è§„åˆ™æ–‡ä»¶åˆ—è¡¨
    """
    self._load_rules()  # æ€»æ˜¯é‡æ–°åŠ è½½ï¼ˆæ”¯æŒçƒ­æ›´æ–°ï¼‰
    parsed_rules = []
    for file_path in self._rules:
        parsed_rule = self.parse_rule_file(file_path)
        parsed_rules.append(parsed_rule)
    return parsed_rules
```

### 2.4.4.4 å¿…éœ€è§„åˆ™ vs æ¡ä»¶è§„åˆ™

**åˆ†ç±»é€»è¾‘**ï¼ˆåœ¨ `utils/rule_utils.py` æˆ–è°ƒç”¨ä»£ç ä¸­ï¼‰:

```python
def categorize_rules(rules: List[RuleFile], target_files: List[str]) -> Dict[str, List[RuleFile]]:
    """
    åˆ†ç±»è§„åˆ™ä¸ºå¿…éœ€è§„åˆ™å’Œæ¡ä»¶è§„åˆ™

    Args:
        rules: æ‰€æœ‰è§„åˆ™æ–‡ä»¶åˆ—è¡¨
        target_files: ç›®æ ‡æ–‡ä»¶åˆ—è¡¨ï¼ˆç”¨äº glob åŒ¹é…ï¼‰

    Returns:
        Dict: {"required": [...], "conditional": [...]}
    """
    required_rules = []
    conditional_rules = []

    for rule in rules:
        if rule.always_apply:
            # alwaysApply=trueï¼Œå¿…éœ€è§„åˆ™
            required_rules.append(rule)
        else:
            # alwaysApply=falseï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡æ–‡ä»¶
            if matches_any_file(rule.globs, target_files):
                conditional_rules.append(rule)

    return {
        "required": required_rules,
        "conditional": conditional_rules
    }

def matches_any_file(globs: List[str], target_files: List[str]) -> bool:
    """
    æ£€æŸ¥è§„åˆ™çš„ globs æ˜¯å¦åŒ¹é…ä»»ä½•ç›®æ ‡æ–‡ä»¶

    Args:
        globs: glob æ¨¡å¼åˆ—è¡¨
        target_files: ç›®æ ‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨

    Returns:
        bool: æ˜¯å¦åŒ¹é…
    """
    import fnmatch
    for pattern in globs:
        for file_path in target_files:
            if fnmatch.fnmatch(file_path, pattern):
                return True
    return False
```

**ä½¿ç”¨åœºæ™¯**:

- **å¿…éœ€è§„åˆ™** (`alwaysApply=true`):
  - é€‚ç”¨äºæ‰€æœ‰æ–‡ä»¶çš„é€šç”¨è§„èŒƒï¼ˆå¦‚ç¼–ç é£æ ¼ã€å®‰å…¨è§„åˆ™ï¼‰
  - å§‹ç»ˆæ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯ä¸­
  - ç¤ºä¾‹ï¼š`security-rules.md`, `code-style.md`

- **æ¡ä»¶è§„åˆ™** (`alwaysApply=false`):
  - ä»…é€‚ç”¨äºç‰¹å®šæ–‡ä»¶ç±»å‹çš„è§„åˆ™
  - æ ¹æ®å½“å‰æ“ä½œçš„æ–‡ä»¶åŠ¨æ€æ³¨å…¥
  - ç¤ºä¾‹ï¼š`python-rules.md` (globs: `["**/*.py"]`), `react-rules.md` (globs: `["**/*.jsx", "**/*.tsx"]`)

### 2.4.4.5 è§„åˆ™ç›®å½•ä¼˜å…ˆçº§

**ä¼˜å…ˆçº§è¡¨æ ¼**:

| **ä¼˜å…ˆçº§** | **ç›®å½•è·¯å¾„**                                            | **é€‚ç”¨åœºæ™¯**                                 | **ç¤ºä¾‹**                                    |
|----------|-------------------------------------------------------|-------------------------------------------|-------------------------------------------|
| **1ï¼ˆæœ€é«˜ï¼‰** | `.autocoderrules/`                                    | é¡¹ç›®æ ¹ç›®å½•çš„è§„åˆ™ï¼ˆæœ€å¿«è®¿é—®ï¼‰                 | é¡¹ç›®ç‰¹å®šçš„ä¸´æ—¶è§„åˆ™æˆ–å®éªŒæ€§è§„èŒƒ              |
| **2**    | `.auto-coder/.autocoderrules/`                        | é¡¹ç›®é…ç½®ç›®å½•çš„è§„åˆ™ï¼ˆæ¨èï¼‰                   | å›¢é˜Ÿåä½œçš„é¡¹ç›®è§„èŒƒï¼ˆä¼šè¢« git è·Ÿè¸ªï¼‰         |
| **3**    | `.auto-coder/autocoderrules/`                         | å¤‡é€‰é¡¹ç›®é…ç½®ç›®å½•ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰               | ä¸ä¼˜å…ˆçº§2ç›¸åŒï¼Œä½†è·¯å¾„ç¨æœ‰ä¸åŒ               |
| **4**    | `~/.auto-coder/autocoderrules/`                       | ç”¨æˆ·å…¨å±€è§„åˆ™                                 | ä¸ªäººç¼–ç ä¹ æƒ¯ã€é€šç”¨å®‰å…¨è§„èŒƒ                  |
| **5ï¼ˆæœ€ä½ï¼‰** | `~/.auto-coder/autocoderrules/repos/<é¡¹ç›®å>/`       | é¡¹ç›®ç‰¹å®šçš„å…¨å±€è§„åˆ™                           | è·¨å·¥ä½œåŒºå…±äº«çš„é¡¹ç›®è§„èŒƒ                      |

**ä¼˜å…ˆçº§è§„åˆ™**:
1. **é¡¹ç›®çº§è§„åˆ™åªä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆç›®å½•**ï¼ˆä¼˜å…ˆçº§1-3ä¸­çš„ç¬¬ä¸€ä¸ªåŒ…å« .md æ–‡ä»¶çš„ç›®å½•ï¼‰
2. **å…¨å±€è§„åˆ™å’Œ repos è§„åˆ™ä¼šåˆå¹¶åŠ è½½**ï¼ˆä¸å†²çªï¼‰
3. **å»é‡æœºåˆ¶**: åŒä¸€æ–‡ä»¶è·¯å¾„åªåŠ è½½ä¸€æ¬¡ï¼ˆé€šè¿‡è§„èŒƒåŒ–è·¯å¾„åˆ¤æ–­ï¼‰

**å®é™…ä½¿ç”¨å»ºè®®**:

```bash
# æ¨èçš„é¡¹ç›®ç»“æ„
my-project/
â”œâ”€â”€ .auto-coder/
â”‚   â””â”€â”€ .autocoderrules/        # é¡¹ç›®è§„èŒƒï¼ˆæ¨èï¼‰
â”‚       â”œâ”€â”€ index.md            # å¿…éœ€è§„åˆ™ç´¢å¼•ï¼ˆalwaysApply=trueï¼‰
â”‚       â”œâ”€â”€ python-rules.md     # Python è§„åˆ™ï¼ˆalwaysApply=false, globs: ["**/*.py"]ï¼‰
â”‚       â”œâ”€â”€ react-rules.md      # React è§„åˆ™ï¼ˆalwaysApply=false, globs: ["**/*.jsx", "**/*.tsx"]ï¼‰
â”‚       â””â”€â”€ security.md         # å®‰å…¨è§„åˆ™ï¼ˆalwaysApply=trueï¼‰
â”œâ”€â”€ .git/
â””â”€â”€ src/

# ç”¨æˆ·å…¨å±€è§„èŒƒ
~/.auto-coder/
â””â”€â”€ autocoderrules/
    â”œâ”€â”€ personal-style.md       # ä¸ªäººç¼–ç é£æ ¼ï¼ˆalwaysApply=trueï¼‰
    â””â”€â”€ repos/
        â””â”€â”€ my-project/         # é¡¹ç›®ç‰¹å®šå…¨å±€è§„èŒƒï¼ˆè·¨å·¥ä½œåŒºï¼‰
            â””â”€â”€ team-conventions.md
```

---

## 2.4.7 æ³¨å…¥é¡ºåºå’Œä¼˜å…ˆçº§(å…¨æ–°ç« èŠ‚)

### 2.4.7.1 å››å±‚ä¸Šä¸‹æ–‡çš„æ³¨å…¥é¡ºåº

**å®Œæ•´ä»£ç æµç¨‹**ï¼ˆåŸºäº `BaseAgent._system` æ–¹æ³•ï¼‰:

```python
@byzerllm.prompt()
def _system(self, request: AgentRequest) -> str:
    """
    ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆJinja2 æ¨¡æ¿ï¼‰

    æ³¨å…¥é¡ºåºï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰ï¼š
    1. ç³»ç»Ÿçº§æç¤ºï¼ˆcustom_system_promptï¼‰
    2. å·¥å…·æè¿°ï¼ˆToolRegistryï¼‰
    3. MCP æœåŠ¡ä¿¡æ¯
    4. Agent ä¿¡æ¯
    5. ç¾¤ç»„ä¿¡æ¯
    6. å·¥å…·ä½¿ç”¨ç¤ºä¾‹
    7. å·¥å…·ä½¿ç”¨æŒ‡å—
    8. å·¥å…·ç”¨ä¾‹æ–‡æ¡£
    9. é¡¹ç›®åŒ…ä¸Šä¸‹æ–‡ï¼ˆactive.mdï¼‰
    10. èƒ½åŠ›è¯´æ˜ï¼ˆCAPABILITIESï¼‰
    11. è§„åˆ™æ–‡ä»¶ï¼ˆextra_docsï¼‰
    12. ç³»ç»Ÿä¿¡æ¯ï¼ˆæ“ä½œç³»ç»Ÿã€Shell ç±»å‹ç­‰ï¼‰
    13. ä»»åŠ¡ç›®æ ‡ï¼ˆOBJECTIVEï¼‰
    14. å½“å‰å…³æ³¨æ–‡ä»¶åˆ—è¡¨ï¼ˆfile_paths_strï¼‰
    """
    '''
    {{system_prompt}}  # 1. è‡ªå®šä¹‰ç³»ç»Ÿæç¤º

    ====

    TOOL USE  # 2. å·¥å…·æè¿°

    You have access to a set of tools...

    # Tool Use Formatting
    ...

    # Tools  # 3. å·¥å…·åˆ—è¡¨ï¼ˆToolRegistryï¼‰

    {% for tool_tag, tool_description in tool_descriptions.items() %}
    ## {{ tool_tag }}
    {{ tool_description.description }}
    {% endfor %}

    {%if mcp_server_info %}  # 4. MCP æœåŠ¡ä¿¡æ¯
    ### MCP_SERVER_LIST
    {{mcp_server_info}}
    {%endif%}

    {%if agent_info %}  # 5. Agent ä¿¡æ¯
    ### AVAILABLE_AGENTS
    {{agent_info}}
    {%endif%}

    {%if group_info %}  # 6. ç¾¤ç»„ä¿¡æ¯
    ### AVAILABLE_GROUPS
    {{group_info}}
    {%endif%}

    # Tool Use Examples  # 7. å·¥å…·ç¤ºä¾‹
    {% for tool_tag, example in tool_examples.items() %}
    ## Example: {{ example.title }}
    {{ example.body }}
    {% endfor %}

    # Tool Use Guidelines  # 8. å·¥å…·æŒ‡å—
    {% for tool_name, guideline in tool_guidelines.items() %}
    {{ loop.index }}. **{{ tool_name }}**: {{ guideline }}
    {% endfor %}

    {% for case_name, case_info in tool_case_docs.items() %}  # 9. å·¥å…·ç”¨ä¾‹
    # {{ case_name | upper }}
    {{ case_info.doc }}
    {% endfor %}

    {% if enable_active_context_in_generate %}  # 10. é¡¹ç›®åŒ…ä¸Šä¸‹æ–‡
    ====
    PROJECT PACKAGE CONTEXT
    ...
    {% endif %}

    ====
    CAPABILITIES  # 11. èƒ½åŠ›è¯´æ˜
    ...

    ====
    RULES  # 12. è§„åˆ™æ–‡ä»¶

    {% if extra_docs %}
    ====
    RULES OR DOCUMENTS PROVIDED BY USER
    {% for key, value in extra_docs.items() %}
    ##File: {{ key }}
    {{ value }}
    {% endfor %}
    {% endif %}

    ====
    SYSTEM INFORMATION  # 13. ç³»ç»Ÿä¿¡æ¯
    Operating System: {{os_distribution}}
    Default Shell: {{shell_type}}
    ...

    ====
    OBJECTIVE  # 14. ä»»åŠ¡ç›®æ ‡
    You accomplish a given task iteratively...

    {% if file_paths_str %}  # 15. å½“å‰å…³æ³¨æ–‡ä»¶
    ====
    <files>
    {{file_paths_str}}
    </files>
    {% endif %}
    '''
    return self._render_context()
```

**_render_context æ–¹æ³•**ï¼ˆå‡†å¤‡æ¨¡æ¿å˜é‡ï¼‰:

```python
def _render_context(self):
    """
    å‡†å¤‡ç³»ç»Ÿæç¤ºè¯çš„æ‰€æœ‰å˜é‡

    Returns:
        Dict: æ¨¡æ¿å˜é‡å­—å…¸
    """
    # 1. è·å–å·¥å…·æè¿°å’Œç¤ºä¾‹ï¼ˆToolRegistryï¼‰
    tool_descriptions = ToolRegistry.get_all_tool_descriptions()
    tool_examples = ToolRegistry.get_all_tool_examples()
    tool_case_docs = ToolRegistry.get_all_tools_case_docs()
    tool_guidelines = ToolRegistry.get_all_tool_use_guidelines()

    # 2. è·å–è§„åˆ™æ–‡ä»¶ï¼ˆAutocoderRulesManagerï¼‰
    extra_docs = get_required_and_index_rules()

    # 3. è·å–ç¯å¢ƒä¿¡æ¯
    env_info = detect_env()
    shell_type = "bash"
    if shells.is_running_in_cmd():
        shell_type = "cmd"
    elif shells.is_running_in_powershell():
        shell_type = "powershell"

    # 4. è·å–å½“å‰å…³æ³¨çš„æ–‡ä»¶åˆ—è¡¨
    file_paths_str = "\n".join([file_source.module_name for file_source in self.files.sources])

    # 5. è·å–ä»£ç†ä¿¡æ¯ï¼ˆAgentHubï¼‰
    agent_info = ""
    agent_names = AgentHub.list_agents()
    if agent_names:
        agent_info = "Available Agents:\n"
        for name in agent_names:
            agent = AgentHub.get_agent(name)
            if agent:
                role = getattr(agent, "custom_system_prompt", "No description")
                if name == self.name:
                    agent_info += f"- {name} (This is you, do not talk to yourself): {role[:100]}{'...' if len(role) > 100 else ''}\n"
                else:
                    agent_info += f"- {name}: {role[:100]}{'...' if len(role) > 100 else ''}\n"

    # 6. è·å–ç¾¤ç»„ä¿¡æ¯ï¼ˆAgentHubï¼‰
    group_info = ""
    groups = AgentHub.get_all_groups()
    if groups:
        group_info = "Available Groups:\n"
        for group in groups:
            members = []
            with group._members_lock:
                members = [member.name for member in group.members]
            group_info += f"- {group.name}: {len(members)} members ({', '.join(members)})\n"

    # 7. è¿”å›æ‰€æœ‰å˜é‡
    return {
        "conversation_history": self.conversation_history,
        "env_info": env_info,
        "shell_type": shell_type,
        "shell_encoding": shells.get_terminal_encoding(),
        "conversation_safe_zone_tokens": self._get_parsed_safe_zone_tokens(),
        "os_distribution": shells.get_os_distribution(),
        "current_user": shells.get_current_username(),
        "current_project": os.path.abspath(self.args.source_dir),
        "home_dir": os.path.expanduser("~"),
        "files": self.files.to_str(),
        "mcp_server_info": self.mcp_server_info,
        "agent_info": agent_info,
        "group_info": group_info,
        "enable_active_context_in_generate": self.args.enable_active_context_in_generate,
        "extra_docs": extra_docs,
        "file_paths_str": file_paths_str,
        "tool_descriptions": tool_descriptions,
        "tool_examples": tool_examples,
        "tool_case_docs": tool_case_docs,
        "tool_guidelines": tool_guidelines,
        "system_prompt": self.custom_system_prompt,
        "name": self.name
    }
```

**æ³¨å…¥é¡ºåºçš„å®é™…æ‰§è¡Œ**ï¼ˆ`agentic_run` æ–¹æ³•ï¼‰:

```python
def agentic_run(self, request: AgentRequest) -> Generator[...]:
    """
    æ‰§è¡Œ Agent æµç¨‹

    æ­¥éª¤ï¼š
    1. ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆ_system.prompt()ï¼‰
    2. æ„å»ºå¯¹è¯å†å²ï¼ˆconversationsï¼‰
    3. æ·»åŠ ç”¨æˆ·è¾“å…¥
    4. è°ƒç”¨ LLM
    5. è§£æå“åº”å¹¶æ‰§è¡Œå·¥å…·
    """
    # 1. ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«æ‰€æœ‰æ³¨å…¥çš„ä¸Šä¸‹æ–‡ï¼‰
    system_prompt = self._system.prompt(request)
    logger.info(f"Generated system prompt with length: {len(system_prompt)}")

    # 2. æ„å»ºå¯¹è¯åˆ—è¡¨
    conversations = [
        {"role": "system", "content": system_prompt},  # ç³»ç»Ÿæç¤ºè¯
    ]

    # 3. æ¢å¤å¯¹è¯å†å²
    if self.conversation_history:
        for message in self.conversation_history:
            conversations.append({
                "role": message['role'],
                "content": message['content']
            })

    # 4. æ·»åŠ ç”¨æˆ·è¾“å…¥
    conversations.append({
        "role": "user", "content": request.user_input
    })

    # 5. è°ƒç”¨ LLM
    llm_response_gen = stream_chat_with_continue(
        llm=self.llm,
        conversations=conversations,
        llm_config={},
        args=self.args
    )

    # 6. è§£æå“åº”å¹¶æ‰§è¡Œå·¥å…·
    parsed_events = self.stream_and_parse_llm_response(llm_response_gen)
    for event in parsed_events:
        # å¤„ç†äº‹ä»¶...
        yield event
```

### 2.4.7.2 ä¼˜å…ˆçº§è®¾è®¡åŸåˆ™

**ä¼˜å…ˆçº§åˆ†å±‚**ï¼ˆä»é«˜åˆ°ä½ï¼‰:

| **å±‚çº§** | **å†…å®¹**                          | **ç›®çš„**                                                                 | **å¯è¦†ç›–æ€§** |
|---------|----------------------------------|------------------------------------------------------------------------|-------------|
| **P0**  | ç³»ç»Ÿçº§æç¤ºï¼ˆcustom_system_promptï¼‰ | å®šä¹‰ Agent çš„æ ¸å¿ƒèº«ä»½å’Œè¡Œä¸ºæ¨¡å¼                                         | ä¸å¯è¦†ç›–    |
| **P1**  | å·¥å…·å®šä¹‰ï¼ˆToolRegistryï¼‰          | æä¾›å¯ç”¨å·¥å…·çš„æ ‡å‡†æ¥å£                                                  | ä¸å¯è¦†ç›–    |
| **P2**  | è§„åˆ™æ–‡ä»¶ï¼ˆextra_docsï¼‰            | é¡¹ç›®ç‰¹å®šçš„ç¼–ç è§„èŒƒã€å®‰å…¨è§„åˆ™                                            | å¯è¡¥å……      |
| **P3**  | é¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆactive.md, filesï¼‰    | å½“å‰é¡¹ç›®çš„ç»“æ„å’Œæ–‡ä»¶å†…å®¹                                                | åŠ¨æ€æ›´æ–°    |
| **P4**  | å¯¹è¯å†å²ï¼ˆconversation_historyï¼‰  | ä¹‹å‰çš„äº¤äº’è®°å½•                                                          | åŠ¨æ€æ›´æ–°    |
| **P5**  | ç”¨æˆ·è¾“å…¥ï¼ˆrequest.user_inputï¼‰    | å½“å‰ä»»åŠ¡çš„å…·ä½“è¦æ±‚                                                      | æ¯æ¬¡ä¸åŒ    |

**è®¾è®¡åŸåˆ™**:

1. **é™æ€ > åŠ¨æ€**: é™æ€é…ç½®ï¼ˆç³»ç»Ÿæç¤ºã€å·¥å…·å®šä¹‰ï¼‰ä¼˜å…ˆçº§é«˜äºåŠ¨æ€å†…å®¹ï¼ˆå¯¹è¯å†å²ã€ç”¨æˆ·è¾“å…¥ï¼‰
2. **é€šç”¨ > ç‰¹å®š**: é€šç”¨è§„åˆ™ï¼ˆç³»ç»Ÿçº§ï¼‰ä¼˜å…ˆçº§é«˜äºç‰¹å®šè§„åˆ™ï¼ˆé¡¹ç›®çº§ã€æ–‡ä»¶çº§ï¼‰
3. **å¼ºåˆ¶ > å»ºè®®**: å¼ºåˆ¶æ€§çº¦æŸï¼ˆå®‰å…¨è§„åˆ™ã€API é™åˆ¶ï¼‰ä¼˜å…ˆçº§é«˜äºå»ºè®®æ€§è§„èŒƒï¼ˆç¼–ç é£æ ¼ï¼‰
4. **è¿‘ > è¿œ**: æœ€è¿‘çš„ä¿¡æ¯ï¼ˆå½“å‰æ–‡ä»¶ã€æœ€æ–°å¯¹è¯ï¼‰ä¼˜å…ˆçº§é«˜äºå†å²ä¿¡æ¯

### 2.4.7.3 æ³¨å…¥é¡ºåºå¯¹ LLM ç†è§£çš„å½±å“

**ä½ç½®æ•ˆåº”**:

1. **é¦–å› æ•ˆåº”**ï¼ˆPrimacy Effectï¼‰:
   - **ç°è±¡**: ç³»ç»Ÿæç¤ºè¯å¼€å¤´çš„å†…å®¹å¯¹ LLM è¡Œä¸ºå½±å“æœ€å¤§
   - **åº”ç”¨**: å°†æ ¸å¿ƒèº«ä»½å®šä¹‰ï¼ˆcustom_system_promptï¼‰æ”¾åœ¨æœ€å‰é¢
   - **ç¤ºä¾‹**: "You are a highly skilled software engineer..." ç¡®å®šäº† Agent çš„åŸºæœ¬è§’è‰²

2. **è¿‘å› æ•ˆåº”**ï¼ˆRecency Effectï¼‰:
   - **ç°è±¡**: ç³»ç»Ÿæç¤ºè¯æœ«å°¾çš„å†…å®¹å¯¹å½“å‰ä»»åŠ¡å½±å“æœ€å¤§
   - **åº”ç”¨**: å°†å½“å‰ä»»åŠ¡ç›®æ ‡ï¼ˆOBJECTIVEï¼‰å’Œå…³æ³¨æ–‡ä»¶ï¼ˆfile_paths_strï¼‰æ”¾åœ¨æœ«å°¾
   - **ç¤ºä¾‹**: `<files>src/main.py</files>` æç¤º LLM é‡ç‚¹å…³æ³¨è¿™ä¸ªæ–‡ä»¶

3. **ä¸­é—´é—å¿˜**:
   - **ç°è±¡**: ç³»ç»Ÿæç¤ºè¯ä¸­é—´çš„å†…å®¹å®¹æ˜“è¢«å¿½ç•¥
   - **åº”å¯¹**: ä½¿ç”¨åˆ†éš”ç¬¦ï¼ˆ`====`ï¼‰å’Œæ ‡é¢˜ï¼ˆ`# SECTION`ï¼‰å¢å¼ºç»“æ„
   - **ç¤ºä¾‹**: `==== TOOL USE ====` æ¸…æ™°åˆ†éš”ä¸åŒéƒ¨åˆ†

**Token é¢„ç®—åˆ†é…**:

```python
# å‡è®¾æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ä¸º 128K tokensï¼Œåˆ†é…ç­–ç•¥ï¼š

ç³»ç»Ÿæç¤ºè¯ï¼ˆ_systemï¼‰          : 20K tokens  (15%)  # é™æ€å†…å®¹ï¼Œå¯ç¼“å­˜
â”œâ”€â”€ ç³»ç»Ÿçº§æç¤º                 : 1K tokens
â”œâ”€â”€ å·¥å…·æè¿°                   : 5K tokens
â”œâ”€â”€ è§„åˆ™æ–‡ä»¶ï¼ˆextra_docsï¼‰     : 8K tokens
â”œâ”€â”€ é¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆactive.mdï¼‰    : 3K tokens
â””â”€â”€ ç³»ç»Ÿä¿¡æ¯                   : 3K tokens

å¯¹è¯å†å²ï¼ˆconversation_historyï¼‰: 60K tokens (47%)  # åŠ¨æ€å†…å®¹
â”œâ”€â”€ å†å²æ¶ˆæ¯                   : 50K tokens
â”œâ”€â”€ å·¥å…·è°ƒç”¨è®°å½•               : 5K tokens
â””â”€â”€ ç»“æœåé¦ˆ                   : 5K tokens

ç”¨æˆ·è¾“å…¥ï¼ˆuser_inputï¼‰         : 5K tokens   (4%)   # å½“å‰ä»»åŠ¡

è¾“å‡ºä¿ç•™ï¼ˆresponseï¼‰           : 43K tokens  (34%)  # ä¸º LLM ç”Ÿæˆç•™ç©ºé—´
```

### 2.4.7.4 ä¼˜å…ˆçº§å†²çªå¤„ç†

**å†²çªç±»å‹ä¸è§£å†³ç­–ç•¥**:

| **å†²çªç±»å‹**             | **ç¤ºä¾‹**                                           | **è§£å†³ç­–ç•¥**                                    | **å®ç°ä½ç½®**                          |
|------------------------|--------------------------------------------------|-----------------------------------------------|-------------------------------------|
| **å·¥å…·æè¿°å†²çª**         | ToolRegistry å’Œ ToolsManager å®šä¹‰åŒåå·¥å…·          | ToolRegistry ä¼˜å…ˆï¼ˆå†…ç½®å·¥å…·ï¼‰                  | `_system` æ¨¡æ¿ï¼ˆå…ˆæ³¨å…¥ ToolRegistryï¼‰ |
| **è§„åˆ™æ–‡ä»¶å†²çª**         | é¡¹ç›®è§„åˆ™ vs å…¨å±€è§„åˆ™å¯¹åŒä¸€é—®é¢˜ç»™å‡ºä¸åŒæŒ‡å¯¼         | é¡¹ç›®è§„åˆ™ä¼˜å…ˆï¼ˆAutocoderRulesManager åŠ è½½é¡ºåºï¼‰ | `_load_rules` æ–¹æ³•                   |
| **ç³»ç»Ÿæç¤º vs ç”¨æˆ·è¾“å…¥** | ç³»ç»Ÿæç¤ºç¦æ­¢åˆ é™¤ï¼Œç”¨æˆ·è¦æ±‚åˆ é™¤æ–‡ä»¶                 | ç³»ç»Ÿæç¤ºä¼˜å…ˆï¼ˆLLM è‡ªä¸»åˆ¤æ–­ï¼‰                   | `_system` æ¨¡æ¿ï¼ˆç³»ç»Ÿæç¤ºåœ¨å‰ï¼‰        |
| **å¯¹è¯å†å² vs å½“å‰ä»»åŠ¡** | å†å²å¯¹è¯æ¶‰åŠæ–‡ä»¶ Aï¼Œå½“å‰ä»»åŠ¡æ¶‰åŠæ–‡ä»¶ B            | å½“å‰ä»»åŠ¡ä¼˜å…ˆï¼ˆæ–‡ä»¶åˆ—è¡¨æ”¾åœ¨æœ«å°¾ï¼‰               | `_system` æ¨¡æ¿ï¼ˆfile_paths_str æœ«å°¾ï¼‰|

**å†²çªå¤„ç†ç¤ºä¾‹**:

```python
# åœºæ™¯ï¼šç”¨æˆ·åœ¨è§„åˆ™æ–‡ä»¶ä¸­ç¦æ­¢ä½¿ç”¨ evalï¼Œä½†åœ¨å¯¹è¯ä¸­è¦æ±‚ä½¿ç”¨ eval

# è§„åˆ™æ–‡ä»¶ï¼ˆ.auto-coder/.autocoderrules/security.mdï¼‰
---
alwaysApply: true
---
# Security Rules
- NEVER use `eval()` or `exec()` in production code

# ç”¨æˆ·è¾“å…¥
"è¯·ä½¿ç”¨ eval() è§£æè¿™ä¸ªå­—ç¬¦ä¸²"

# LLM ç†è§£ï¼ˆåŸºäºæ³¨å…¥é¡ºåºï¼‰
1. ç³»ç»Ÿæç¤ºè¯ä¸­åŒ…å«å®‰å…¨è§„åˆ™ï¼ˆextra_docsï¼‰
2. ç”¨æˆ·è¾“å…¥è¦æ±‚ä½¿ç”¨ eval
3. LLM è‡ªä¸»åˆ¤æ–­ï¼šä¼˜å…ˆéµå®ˆå®‰å…¨è§„åˆ™ï¼Œæ‹’ç»ä½¿ç”¨ eval
4. å›å¤ï¼š
   <attempt_completion>
   <result>
   æ ¹æ®é¡¹ç›®å®‰å…¨è§„åˆ™ï¼Œä¸èƒ½ä½¿ç”¨ eval()ã€‚å»ºè®®ä½¿ç”¨ json.loads() æˆ– ast.literal_eval() ä½œä¸ºå®‰å…¨æ›¿ä»£æ–¹æ¡ˆã€‚
   </result>
   </attempt_completion>
```

**å†²çªæ£€æµ‹æœºåˆ¶**ï¼ˆå¯é€‰çš„æœªæ¥æ”¹è¿›ï¼‰:

```python
def detect_context_conflicts(system_prompt: str, user_input: str) -> List[str]:
    """
    æ£€æµ‹ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·è¾“å…¥ä¹‹é—´çš„æ½œåœ¨å†²çª

    Args:
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        user_input: ç”¨æˆ·è¾“å…¥

    Returns:
        List[str]: å†²çªè­¦å‘Šåˆ—è¡¨
    """
    conflicts = []

    # æ£€æµ‹ç¦æ­¢æ“ä½œ
    forbidden_patterns = [
        (r"NEVER.*delete", r"delete|remove|rm\s+"),
        (r"NEVER.*eval", r"eval\(|exec\("),
        (r"NEVER.*sudo", r"sudo\s+"),
    ]

    for forbidden_pattern, user_pattern in forbidden_patterns:
        if re.search(forbidden_pattern, system_prompt, re.IGNORECASE):
            if re.search(user_pattern, user_input, re.IGNORECASE):
                conflicts.append(
                    f"ç”¨æˆ·è¾“å…¥å¯èƒ½è¿åç³»ç»Ÿè§„åˆ™: "
                    f"è§„åˆ™ç¦æ­¢ '{forbidden_pattern}'ï¼Œä½†ç”¨æˆ·è¾“å…¥åŒ…å« '{user_pattern}'"
                )

    return conflicts
```

### 2.4.7.5 æ³¨å…¥é¡ºåºå¯è§†åŒ–

**ASCII Art æµç¨‹å›¾**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BaseAgent.agentic_run()                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Step 1: ç”Ÿæˆç³»ç»Ÿæç¤ºè¯                          â”‚
â”‚              system_prompt = _system.prompt(request)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    _system() æ¨¡æ¿æ¸²æŸ“æµç¨‹             â”‚
        â”‚    ï¼ˆæŒ‰ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºæ³¨å…¥ï¼‰           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                     â”‚
        â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. custom_      â”‚                 â”‚ 2. Tool         â”‚
â”‚    system_      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”‚    Descriptions â”‚
â”‚    prompt       â”‚          â”‚      â”‚    (Registry)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 3. MCP Server   â”‚
                    â”‚    Info         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 4. Agent Info   â”‚
                    â”‚ 5. Group Info   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 6. Tool         â”‚
                    â”‚    Examples     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 7. Tool         â”‚
                    â”‚    Guidelines   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 8. Tool Case    â”‚
                    â”‚    Docs         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 9. Project      â”‚
                    â”‚    Package      â”‚
                    â”‚    Context      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 10. CAPABILITIESâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 11. RULES       â”‚
                    â”‚     (extra_docs)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 12. SYSTEM INFO â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 13. OBJECTIVE   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 14. Current     â”‚
                    â”‚     Focus Files â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       ç”Ÿæˆçš„ç³»ç»Ÿæç¤ºè¯                  â”‚
        â”‚       (çº¦ 20K-30K tokens)              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Step 2: æ„å»ºå¯¹è¯å†å²                            â”‚
â”‚              conversations = [                              â”‚
â”‚                  {"role": "system", "content": system_prompt}â”‚
â”‚                  + conversation_history                     â”‚
â”‚                  + {"role": "user", "content": user_input}  â”‚
â”‚              ]                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Step 3: è°ƒç”¨ LLM                                â”‚
â”‚              stream_chat_with_continue(llm, conversations)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.4.7.6 æœ€ä½³å®è·µå»ºè®®

**1. ä¼˜åŒ–æ³¨å…¥å†…å®¹çš„è´¨é‡**:

```python
# âœ… å¥½çš„å®è·µï¼šç®€æ´æ˜äº†
custom_system_prompt = """
You are a senior Python developer specializing in backend APIs.
Focus on code quality, security, and performance.
"""

# âŒ ä¸å¥½çš„å®è·µï¼šå†—é•¿é‡å¤
custom_system_prompt = """
You are a software engineer. You are a very good software engineer.
You know Python. You know how to write Python code. You also know
how to write backend code. And you care about quality. And security.
And performance. You are very experienced...
"""
```

**2. åˆç†åˆ†é… Token é¢„ç®—**:

```python
# åœ¨ BaseAgent åˆå§‹åŒ–æ—¶è®¾ç½® token é™åˆ¶
self.max_system_prompt_tokens = 30000  # ç³»ç»Ÿæç¤ºè¯æœ€å¤§ token æ•°
self.max_conversation_history = 20     # æœ€å¤šä¿ç•™ 20 è½®å¯¹è¯
self.conversation_safe_zone_tokens = 10000  # å¯¹è¯å†å²å®‰å…¨åŒº token æ•°

# åŠ¨æ€è£å‰ªå¯¹è¯å†å²
if total_tokens > context_window - self.conversation_safe_zone_tokens:
    # ä½¿ç”¨ AgenticConversationPruner è£å‰ªå†å²
    pruned_history = prune_conversation(
        self.conversation_history,
        target_tokens=self.conversation_safe_zone_tokens
    )
```

**3. ä½¿ç”¨åˆ†éš”ç¬¦å¢å¼ºç»“æ„**:

```python
# åœ¨ _system æ¨¡æ¿ä¸­ä½¿ç”¨æ¸…æ™°çš„åˆ†éš”ç¬¦
"""
{{system_prompt}}

====  # æ˜æ˜¾çš„åˆ†éš”

TOOL USE

====  # å†æ¬¡åˆ†éš”

RULES
"""
```

**4. åŠ¨æ€è°ƒæ•´æ³¨å…¥å†…å®¹**:

```python
# æ ¹æ®ä»»åŠ¡ç±»å‹åŠ¨æ€é€‰æ‹©è§„åˆ™æ–‡ä»¶
def get_required_and_index_rules(task_type: str) -> Dict[str, str]:
    """æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ€§åŠ è½½è§„åˆ™"""
    all_rules = AutocoderRulesManager().get_parsed_rules()

    if task_type == "code_review":
        # ä»£ç å®¡æŸ¥ä»»åŠ¡ï¼ŒåªåŠ è½½å®¡æŸ¥ç›¸å…³è§„åˆ™
        return {rule.file_path: rule.content
                for rule in all_rules
                if "review" in rule.description.lower()}
    elif task_type == "bug_fix":
        # Bug ä¿®å¤ä»»åŠ¡ï¼ŒåªåŠ è½½è°ƒè¯•ç›¸å…³è§„åˆ™
        return {rule.file_path: rule.content
                for rule in all_rules
                if "debug" in rule.description.lower() or rule.always_apply}
    else:
        # é»˜è®¤åŠ è½½æ‰€æœ‰å¿…éœ€è§„åˆ™
        return {rule.file_path: rule.content
                for rule in all_rules
                if rule.always_apply}
```

**5. ç›‘æ§æ³¨å…¥æ•ˆæœ**:

```python
# è®°å½•ç³»ç»Ÿæç¤ºè¯é•¿åº¦
logger.info(f"System prompt length: {len(system_prompt)} characters")
logger.info(f"Estimated tokens: {len(system_prompt) / 4}")  # ç²—ç•¥ä¼°è®¡

# ç›‘æ§ LLM å“åº”è´¨é‡
if "I don't understand" in llm_response or "unclear" in llm_response:
    logger.warning("LLM å¯èƒ½æœªæ­£ç¡®ç†è§£ç³»ç»Ÿæç¤ºè¯ï¼Œè€ƒè™‘ä¼˜åŒ–æ³¨å…¥å†…å®¹")
```

---

## 3.1.6 å±‚æ¬¡é—´çš„äº¤äº’å’Œä¼ é€’(å…¨æ–°ç« èŠ‚)

### 3.1.6.1 å››å±‚ä¿¡æ¯æµå‘

**å±‚æ¬¡å®šä¹‰**ï¼ˆå›é¡¾ï¼‰:

1. **System Layer**: ç³»ç»Ÿçº§ä¸Šä¸‹æ–‡ï¼ˆå·¥å…·å®šä¹‰ã€ç³»ç»Ÿæç¤ºã€ç¯å¢ƒä¿¡æ¯ï¼‰
2. **Documentation Layer**: æ–‡æ¡£å±‚ï¼ˆè§„åˆ™æ–‡ä»¶ã€é¡¹ç›®ç»“æ„ã€active.mdï¼‰
3. **History Layer**: å†å²å±‚ï¼ˆå¯¹è¯å†å²ã€å·¥å…·è°ƒç”¨è®°å½•ï¼‰
4. **Current Layer**: å½“å‰å±‚ï¼ˆç”¨æˆ·è¾“å…¥ã€å½“å‰ä»»åŠ¡ã€å…³æ³¨æ–‡ä»¶ï¼‰

**ä¿¡æ¯æµå‘å›¾**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      System Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Tool        â”‚  â”‚ System      â”‚  â”‚ Environment â”‚           â”‚
â”‚  â”‚ Definitions â”‚  â”‚ Prompt      â”‚  â”‚ Info        â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ â”‚               â”‚
          â–¼ â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Documentation Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Rules Files â”‚  â”‚ Project     â”‚  â”‚ Active      â”‚           â”‚
â”‚  â”‚ (extra_docs)â”‚  â”‚ Structure   â”‚  â”‚ Context     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚    â”‚            â”‚
          â–¼    â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      History Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Conversationâ”‚  â”‚ Tool Call   â”‚  â”‚ File Change â”‚           â”‚
â”‚  â”‚ History     â”‚  â”‚ Records     â”‚  â”‚ Records     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚         â”‚       â”‚
          â–¼         â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Current Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ User Input  â”‚  â”‚ Current     â”‚  â”‚ Focus Files â”‚           â”‚
â”‚  â”‚             â”‚  â”‚ Task        â”‚  â”‚ (file_paths)â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  LLM Request  â”‚
                â”‚  (Merged)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  LLM Response â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                â”‚
        â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Update Historyâ”‚              â”‚ Execute Tool  â”‚
â”‚ Layer         â”‚              â”‚ (affects      â”‚
â”‚               â”‚              â”‚ Current Layer)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…·ä½“äº¤äº’æµç¨‹**:

```python
def agentic_run(self, request: AgentRequest):
    """
    å®Œæ•´çš„å››å±‚äº¤äº’æµç¨‹
    """
    # ============ æ„å»ºé˜¶æ®µ ============

    # 1. System Layer â†’ Documentation Layer
    # ç³»ç»Ÿå±‚æä¾›å·¥å…·å®šä¹‰ï¼Œæ–‡æ¡£å±‚æä¾›è§„åˆ™çº¦æŸ
    system_prompt = self._system.prompt(request)  # åŒ…å« System + Documentation

    # 2. Documentation Layer â†’ History Layer
    # æ–‡æ¡£å±‚çš„è§„åˆ™æŒ‡å¯¼å†å²å¯¹è¯çš„è£å‰ªç­–ç•¥
    pruned_history = self._prune_conversation_history(
        rules=get_required_and_index_rules(),  # Documentation Layer
        max_tokens=self.conversation_safe_zone_tokens
    )

    # 3. History Layer â†’ Current Layer
    # å†å²å±‚æä¾›ä¸Šä¸‹æ–‡ï¼Œå½“å‰å±‚èšç„¦å…·ä½“ä»»åŠ¡
    conversations = [
        {"role": "system", "content": system_prompt},  # System + Documentation
        *pruned_history,                               # History
        {"role": "user", "content": request.user_input} # Current
    ]

    # ============ æ‰§è¡Œé˜¶æ®µ ============

    # 4. Current Layer â†’ LLM
    llm_response = stream_chat_with_continue(self.llm, conversations)

    # 5. LLM â†’ Current Layer (Tool Execution)
    for event in self.stream_and_parse_llm_response(llm_response):
        if isinstance(event, ToolCallEvent):
            # å·¥å…·æ‰§è¡Œå½±å“å½“å‰å±‚ï¼ˆæ–‡ä»¶å˜æ›´ã€å‘½ä»¤è¾“å‡ºï¼‰
            tool_result = self._execute_tool(event.tool)

            # 6. Current Layer â†’ History Layer (è®°å½•)
            self.conversation_history.append({
                "role": "assistant",
                "content": self._reconstruct_tool_xml(event.tool)
            })
            self.conversation_history.append({
                "role": "user",
                "content": self._format_tool_result(tool_result)
            })

    # ============ åé¦ˆé˜¶æ®µ ============

    # 7. History Layer â†’ Documentation Layer (å¯é€‰)
    # æ ¹æ®å†å²å¯¹è¯æ›´æ–° active.mdï¼ˆå¦‚æœå¯ç”¨ active contextï¼‰
    if self.args.enable_active_context:
        self._update_active_context(self.file_changes)

    # 8. Current Layer â†’ System Layer (å¯é€‰)
    # æ–‡ä»¶å˜æ›´è§¦å‘ FileMonitorï¼Œå½±å“ä¸‹ä¸€æ¬¡çš„ç³»ç»Ÿå±‚ï¼ˆç´¢å¼•æ›´æ–°ï¼‰
    # ï¼ˆè¿™æ˜¯éšå¼çš„ï¼Œé€šè¿‡ FileMonitor å®ç°ï¼‰
```

### 3.1.6.2 è·¨å±‚å¼•ç”¨æœºåˆ¶

**å¼•ç”¨ç±»å‹**:

| **å¼•ç”¨ç±»å‹**           | **æºå±‚**              | **ç›®æ ‡å±‚**            | **å®ç°æ–¹å¼**                                    | **ç¤ºä¾‹**                                      |
|----------------------|---------------------|---------------------|-----------------------------------------------|---------------------------------------------|
| **å·¥å…·è°ƒç”¨å¼•ç”¨**       | Current Layer       | System Layer        | é€šè¿‡ XML æ ‡ç­¾åå¼•ç”¨å·¥å…·å®šä¹‰                     | `<read_file>` â†’ ToolRegistry.get_model_for_tag("read_file") |
| **è§„åˆ™æ–‡ä»¶å¼•ç”¨**       | Documentation Layer | Current Layer       | é€šè¿‡ `index.md` å¼•ç”¨å…¶ä»–è§„åˆ™æ–‡ä»¶                | "Make sure you always start your task by using the read_file tool to get the relevant RULE files listed in index.md" |
| **æ–‡ä»¶è·¯å¾„å¼•ç”¨**       | Current Layer       | Documentation Layer | é€šè¿‡ `file_paths_str` å¼•ç”¨é¡¹ç›®æ–‡ä»¶              | `<files>src/main.py</files>` â†’ è¯»å–å®é™…æ–‡ä»¶å†…å®¹ |
| **å¯¹è¯å†å²å¼•ç”¨**       | History Layer       | Current Layer       | é€šè¿‡ Message ID å¼•ç”¨ç‰¹å®šå†å²æ¶ˆæ¯                | `<message_ids>9226b3a4</message_ids>` â†’ åˆ é™¤æŒ‡å®šæ¶ˆæ¯ |
| **Active Context å¼•ç”¨** | Documentation Layer | Current Layer       | é€šè¿‡ç›¸å¯¹è·¯å¾„å¼•ç”¨ active.md                     | `.auto-coder/active-context/src/abc/active.md` |

**å¼•ç”¨å®ç°ç¤ºä¾‹**:

```python
# 1. å·¥å…·è°ƒç”¨å¼•ç”¨ï¼ˆSystem Layer â†’ Current Layerï¼‰
class BaseAgent:
    def _execute_tool(self, tool: BaseTool) -> ToolResult:
        """
        æ‰§è¡Œå·¥å…·ï¼ˆè·¨å±‚å¼•ç”¨ï¼‰

        æµç¨‹ï¼š
        1. Current Layer æä¾›å·¥å…·å®ä¾‹ï¼ˆtoolï¼‰
        2. System Layer æä¾›å·¥å…·å®šä¹‰ï¼ˆToolRegistryï¼‰
        3. è§£æå™¨æ‰§è¡Œå·¥å…·å¹¶è¿”å›ç»“æœ
        """
        # æŸ¥æ‰¾ Resolverï¼ˆSystem Layerï¼‰
        resolver_cls = ToolRegistry.get_resolver_for_tool(tool)
        if not resolver_cls:
            return ToolResult(success=False, message="Tool resolver not found")

        # åˆ›å»º Resolver å®ä¾‹
        resolver = resolver_cls(agent=self, tool=tool, args=self.args)

        # æ‰§è¡Œå·¥å…·ï¼ˆCurrent Layerï¼‰
        result = resolver.resolve()

        return result


# 2. è§„åˆ™æ–‡ä»¶å¼•ç”¨ï¼ˆDocumentation Layer â†’ Current Layerï¼‰
def get_required_and_index_rules() -> Dict[str, str]:
    """
    è·å–å¿…éœ€è§„åˆ™å’Œç´¢å¼•è§„åˆ™

    å¼•ç”¨æœºåˆ¶ï¼š
    - index.md ä½œä¸ºå…¥å£æ–‡ä»¶ï¼ˆalwaysApply=trueï¼‰
    - LLM æ ¹æ® index.md çš„æŒ‡å¼•è¯»å–å…¶ä»–è§„åˆ™æ–‡ä»¶
    - å®ç°äº†å»¶è¿ŸåŠ è½½ï¼ˆåªåœ¨éœ€è¦æ—¶è¯»å–ï¼‰
    """
    manager = AutocoderRulesManager()
    all_rules = manager.get_parsed_rules()

    required_rules = {}
    for rule in all_rules:
        if rule.always_apply or rule.file_path.endswith("index.md"):
            required_rules[rule.file_path] = rule.content

    return required_rules


# 3. å¯¹è¯å†å²å¼•ç”¨ï¼ˆHistory Layer â†’ Current Layerï¼‰
class ConversationMessageIdsWriteResolver(BaseToolResolver):
    """
    å¤„ç† Message ID å¼•ç”¨

    å¼•ç”¨æµç¨‹ï¼š
    1. LLM åœ¨ Current Layer è¯†åˆ«éœ€è¦åˆ é™¤çš„æ¶ˆæ¯ï¼ˆé€šè¿‡ Message IDï¼‰
    2. è°ƒç”¨ conversation_message_ids_write å·¥å…·
    3. Resolver åœ¨ History Layer æŸ¥æ‰¾å¹¶æ ‡è®°æ¶ˆæ¯
    4. ä¸‹ä¸€è½®å¯¹è¯æ—¶ï¼ŒAgenticConversationPruner æ‰§è¡Œåˆ é™¤
    """
    def resolve(self) -> ToolResult:
        message_ids = self.tool.message_ids.split(",")
        action = self.tool.action  # "delete"

        # æŸ¥æ‰¾å†å²æ¶ˆæ¯ï¼ˆHistory Layerï¼‰
        for msg_id in message_ids:
            for message in self.agent.conversation_history:
                if message.get("message_id", "").startswith(msg_id):
                    # æ ‡è®°ä¸ºåˆ é™¤
                    message["_marked_for_deletion"] = True

        return ToolResult(
            success=True,
            message=f"Marked {len(message_ids)} messages for deletion"
        )
```

### 3.1.6.3 å±‚æ¬¡åä½œæ¨¡å¼

**åä½œæ¨¡å¼1: å±‚æ¬¡çº§è”æ›´æ–°**ï¼ˆTop-Downï¼‰

```python
# åœºæ™¯ï¼šç”¨æˆ·ä¿®æ”¹äº†è§„åˆ™æ–‡ä»¶ï¼Œå½±å“æ‰€æœ‰å±‚æ¬¡

# 1. System Layer: é‡æ–°åŠ è½½è§„åˆ™
AutocoderRulesManager.reset_instance()  # æ¸…é™¤å•ä¾‹ç¼“å­˜
manager = AutocoderRulesManager()
manager._load_rules()  # é‡æ–°åŠ è½½è§„åˆ™æ–‡ä»¶

# 2. Documentation Layer: æ›´æ–° extra_docs
extra_docs = get_required_and_index_rules()

# 3. History Layer: è£å‰ªå†å²å¯¹è¯ï¼ˆè§„åˆ™å¯èƒ½å½±å“è£å‰ªç­–ç•¥ï¼‰
pruned_history = self._prune_conversation_history(
    rules=extra_docs,
    max_tokens=self.conversation_safe_zone_tokens
)

# 4. Current Layer: åº”ç”¨æ–°è§„åˆ™åˆ°å½“å‰ä»»åŠ¡
system_prompt = self._system.prompt(request)  # åŒ…å«æ–°è§„åˆ™
conversations = [
    {"role": "system", "content": system_prompt},
    *pruned_history,
    {"role": "user", "content": request.user_input}
]
```

**åä½œæ¨¡å¼2: å±‚æ¬¡åé¦ˆå¾ªç¯**ï¼ˆBottom-Upï¼‰

```python
# åœºæ™¯ï¼šå·¥å…·æ‰§è¡Œç»“æœå½±å“ä¸Šå±‚å†³ç­–

# 1. Current Layer: æ‰§è¡Œå·¥å…·
tool_result = self._execute_tool(ReadFileTool(path="src/main.py"))

# 2. History Layer: è®°å½•ç»“æœ
self.conversation_history.append({
    "role": "user",
    "content": f"<tool_result success='true'>{tool_result.content}</tool_result>"
})

# 3. Documentation Layer: æ›´æ–° active.mdï¼ˆå¦‚æœå¯ç”¨ï¼‰
if self.args.enable_active_context:
    active_context_manager = ActiveContextManager(self.llm, self.args.source_dir)
    active_context_manager.update_file_summary("src/main.py", tool_result.content)

# 4. System Layer: è§¦å‘ FileMonitorï¼ˆå¦‚æœæ–‡ä»¶è¢«ä¿®æ”¹ï¼‰
# ï¼ˆéšå¼è§¦å‘ï¼Œæ— éœ€æ˜¾å¼ä»£ç ï¼‰
```

**åä½œæ¨¡å¼3: å±‚æ¬¡å¹¶è¡ŒæŸ¥è¯¢**ï¼ˆParallelï¼‰

```python
# åœºæ™¯ï¼šLLM åŒæ—¶ä»å¤šä¸ªå±‚æ¬¡è·å–ä¿¡æ¯

# ä¼ªä»£ç ï¼šLLM çš„æ¨ç†è¿‡ç¨‹
"""
<thinking>
æˆ‘éœ€è¦ä¿®å¤ src/main.py ä¸­çš„ bugã€‚è®©æˆ‘å…ˆï¼š

1. ä» Current Layer è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆread_fileï¼‰
2. ä» Documentation Layer æŸ¥çœ‹ç¼–ç è§„èŒƒï¼ˆè¯»å– rules/python-rules.mdï¼‰
3. ä» History Layer å›é¡¾ä¹‹å‰çš„ä¿®å¤è®°å½•ï¼ˆå¯¹è¯å†å²ï¼‰
4. ä» System Layer æŸ¥çœ‹å¯ç”¨å·¥å…·ï¼ˆsearch_filesï¼‰
</thinking>

<read_file>
<path>src/main.py</path>
</read_file>
"""

# å®é™…æ‰§è¡Œï¼ˆé¡ºåºæ‰§è¡Œï¼Œä½†é€»è¾‘ä¸Šæ˜¯å¹¶è¡ŒæŸ¥è¯¢ï¼‰
```

### 3.1.6.4 å±‚æ¬¡é—´æ•°æ®å…±äº«

**å…±äº«æ•°æ®ç»“æ„**:

```python
class BaseAgent:
    """
    BaseAgent ä½œä¸ºæ•°æ®å…±äº«ä¸­å¿ƒ
    """
    def __init__(self, ...):
        # ========== System Layer æ•°æ® ==========
        self.llm = llm                        # è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯
        self.args = args                      # é…ç½®å‚æ•°
        self.project_type_analyzer = ...      # é¡¹ç›®ç±»å‹åˆ†æå™¨

        # ========== Documentation Layer æ•°æ® ==========
        self.files = files                    # é¡¹ç›®æ–‡ä»¶åˆ—è¡¨
        self.mcp_server_info = ...            # MCP æœåŠ¡ä¿¡æ¯
        # extra_docs é€šè¿‡ get_required_and_index_rules() åŠ¨æ€è·å–

        # ========== History Layer æ•°æ® ==========
        self.conversation_history = []        # å¯¹è¯å†å²
        self.file_changes = {}                # æ–‡ä»¶å˜æ›´è®°å½•
        self.agentic_conversations = []       # å½“å‰ä¼šè¯çš„å®Œæ•´å¯¹è¯

        # ========== Current Layer æ•°æ® ==========
        # é€šè¿‡ AgentRequest ä¼ å…¥
        # request.user_input: ç”¨æˆ·è¾“å…¥
        # request.file_paths: å½“å‰å…³æ³¨æ–‡ä»¶

        # ========== è·¨å±‚å…±äº«æ•°æ® ==========
        self.name = name                      # Agent åç§°ï¼ˆæ‰€æœ‰å±‚éƒ½ä¼šç”¨åˆ°ï¼‰
        self.custom_system_prompt = ...       # è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºï¼ˆå½±å“æ‰€æœ‰å±‚ï¼‰
```

**æ•°æ®è®¿é—®æ¨¡å¼**:

| **æ•°æ®ç±»å‹**           | **å­˜å‚¨ä½ç½®**                  | **è®¿é—®æ–¹å¼**                              | **æ›´æ–°é¢‘ç‡**       |
|----------------------|-----------------------------|-----------------------------------------|------------------|
| **å·¥å…·å®šä¹‰**          | ToolRegistryï¼ˆç±»å˜é‡ï¼‰       | `ToolRegistry.get_model_for_tag()`      | é™æ€ï¼ˆå¯åŠ¨æ—¶ï¼‰    |
| **è§„åˆ™æ–‡ä»¶**          | AutocoderRulesManager       | `get_required_and_index_rules()`        | åŠ¨æ€ï¼ˆæ¯æ¬¡è°ƒç”¨ï¼‰  |
| **å¯¹è¯å†å²**          | `self.conversation_history` | ç›´æ¥è®¿é—®                                 | æ¯è½®å¯¹è¯åæ›´æ–°    |
| **æ–‡ä»¶å˜æ›´**          | `self.file_changes`         | `self.record_file_change()`             | æ¯æ¬¡å·¥å…·æ‰§è¡Œå    |
| **é¡¹ç›®æ–‡ä»¶**          | `self.files`                | `self.files.to_str()`                   | åˆå§‹åŒ–æ—¶åŠ è½½      |
| **å½“å‰ä»»åŠ¡**          | `AgentRequest`              | é€šè¿‡æ–¹æ³•å‚æ•°ä¼ é€’                         | æ¯æ¬¡è¯·æ±‚ä¸åŒ      |

### 3.1.6.5 å±‚æ¬¡éš”ç¦»ä¸ä¿æŠ¤

**éš”ç¦»æœºåˆ¶**:

1. **åªè¯»ä¿æŠ¤**ï¼ˆSystem Layerï¼‰:

```python
# ToolRegistry ä½¿ç”¨ç±»å˜é‡ï¼Œé˜²æ­¢å®ä¾‹çº§åˆ«çš„ä¿®æ”¹
class ToolRegistry:
    _tool_resolver_map: ClassVar[Dict[...]] = {}  # ç±»å˜é‡ï¼Œå…¨å±€å…±äº«

    @classmethod
    def register_tool(cls, ...):
        """åªèƒ½é€šè¿‡ç±»æ–¹æ³•ä¿®æ”¹ï¼Œé˜²æ­¢æ„å¤–è¦†ç›–"""
        cls._tool_resolver_map[tool_cls] = resolver_cls
```

2. **å•ä¾‹ä¿æŠ¤**ï¼ˆDocumentation Layerï¼‰:

```python
# AutocoderRulesManager ä½¿ç”¨å•ä¾‹æ¨¡å¼ + çº¿ç¨‹é”
class AutocoderRulesManager:
    _instance = None
    _lock = Lock()

    def __new__(cls, ...):
        """ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹"""
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super().__new__(cls)
        return cls._instance
```

3. **æ·±æ‹·è´ä¿æŠ¤**ï¼ˆHistory Layerï¼‰:

```python
# å¯¹è¯å†å²è£å‰ªæ—¶ä½¿ç”¨æ·±æ‹·è´ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
def _prune_conversation_history(self, rules, max_tokens):
    """è£å‰ªå¯¹è¯å†å²ï¼ˆä¸ä¿®æ”¹åŸå§‹æ•°æ®ï¼‰"""
    import copy
    pruned = copy.deepcopy(self.conversation_history)
    # åœ¨å‰¯æœ¬ä¸Šè¿›è¡Œè£å‰ª...
    return pruned
```

4. **å‚æ•°éªŒè¯**ï¼ˆCurrent Layerï¼‰:

```python
# å·¥å…·å‚æ•°ä½¿ç”¨ Pydantic éªŒè¯ï¼Œé˜²æ­¢éæ³•è¾“å…¥
class ReadFileTool(BaseTool):
    path: str  # å¿…éœ€å‚æ•°ï¼Œè‡ªåŠ¨éªŒè¯ç±»å‹

    @validator('path')
    def validate_path(cls, v):
        """è‡ªå®šä¹‰éªŒè¯ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»"""
        if ".." in v or v.startswith("/"):
            raise ValueError("Invalid path: path traversal detected")
        return v
```

**ä¿æŠ¤ç­–ç•¥**:

```python
# ç¤ºä¾‹ï¼šé˜²æ­¢ History Layer çš„å¯¹è¯å†å²è¢«æ„å¤–æ¸…ç©º
class BaseAgent:
    def __init__(self, ...):
        self._conversation_history_lock = threading.RLock()
        self._conversation_history = []

    @property
    def conversation_history(self):
        """åªè¯»è®¿é—®"""
        with self._conversation_history_lock:
            return self._conversation_history.copy()  # è¿”å›å‰¯æœ¬

    def append_to_history(self, message: Dict):
        """å—ä¿æŠ¤çš„è¿½åŠ æ–¹æ³•"""
        with self._conversation_history_lock:
            # éªŒè¯æ¶ˆæ¯æ ¼å¼
            if not isinstance(message, dict) or 'role' not in message or 'content' not in message:
                raise ValueError("Invalid message format")
            self._conversation_history.append(message)

    def clear_history(self):
        """å—ä¿æŠ¤çš„æ¸…ç©ºæ–¹æ³•ï¼ˆéœ€è¦æ˜¾å¼è°ƒç”¨ï¼‰"""
        with self._conversation_history_lock:
            logger.warning("Clearing conversation history")
            self._conversation_history.clear()
```

---

## 3.1.7 ä¸Šä¸‹æ–‡å®Œæ•´æ€§æ ¡éªŒ(å…¨æ–°ç« èŠ‚)

### 3.1.7.1 æ ¡éªŒæœºåˆ¶æ¦‚è¿°

**æ ¡éªŒç›®æ ‡**:

1. **å®Œæ•´æ€§**: ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ä¸Šä¸‹æ–‡éƒ½å·²åŠ è½½
2. **ä¸€è‡´æ€§**: ç¡®ä¿ä¸åŒå±‚æ¬¡çš„ä¿¡æ¯ä¸å†²çª
3. **å¯ç”¨æ€§**: ç¡®ä¿ LLM èƒ½å¤Ÿç†è§£å’Œä½¿ç”¨æ³¨å…¥çš„ä¸Šä¸‹æ–‡
4. **åˆè§„æ€§**: ç¡®ä¿ä¸Šä¸‹æ–‡ç¬¦åˆ Token é¢„ç®—å’Œå®‰å…¨è§„èŒƒ

**æ ¡éªŒæ—¶æœº**:

```python
def agentic_run(self, request: AgentRequest):
    """
    åœ¨å…³é”®èŠ‚ç‚¹æ‰§è¡Œæ ¡éªŒ
    """
    # 1. æ„å»ºå‰æ ¡éªŒ
    self._validate_initialization()

    # 2. æ³¨å…¥åæ ¡éªŒ
    system_prompt = self._system.prompt(request)
    self._validate_system_prompt(system_prompt)

    # 3. å¯¹è¯å‰æ ¡éªŒ
    conversations = self._build_conversations(system_prompt, request)
    self._validate_conversations(conversations)

    # 4. æ‰§è¡Œä¸­æ ¡éªŒ
    for event in self.stream_and_parse_llm_response(llm_response):
        self._validate_event(event)

    # 5. å®Œæˆåæ ¡éªŒ
    self._validate_completion()
```

**æ ¡éªŒå®ç°**:

```python
def _validate_initialization(self):
    """
    æ ¡éªŒåˆå§‹åŒ–çŠ¶æ€
    """
    # æ ¡éªŒå¿…éœ€ç»„ä»¶
    assert self.llm is not None, "LLM client not initialized"
    assert self.args is not None, "Args not initialized"
    assert self.files is not None, "Files not initialized"

    # æ ¡éªŒ ToolRegistry
    registered_tools = ToolRegistry.get_all_registered_tools()
    assert len(registered_tools) > 0, "No tools registered in ToolRegistry"
    logger.info(f"Validated: {len(registered_tools)} tools registered")

    # æ ¡éªŒè§„åˆ™æ–‡ä»¶
    manager = AutocoderRulesManager()
    rules = manager.get_parsed_rules()
    logger.info(f"Validated: {len(rules)} rules loaded")

def _validate_system_prompt(self, system_prompt: str):
    """
    æ ¡éªŒç³»ç»Ÿæç¤ºè¯
    """
    # æ ¡éªŒé•¿åº¦
    estimated_tokens = len(system_prompt) / 4  # ç²—ç•¥ä¼°è®¡
    max_system_tokens = 30000
    if estimated_tokens > max_system_tokens:
        logger.warning(
            f"System prompt too long: {estimated_tokens:.0f} tokens "
            f"(max: {max_system_tokens})"
        )

    # æ ¡éªŒå¿…éœ€å†…å®¹
    required_sections = [
        "TOOL USE",
        "CAPABILITIES",
        "RULES",
        "SYSTEM INFORMATION",
        "OBJECTIVE"
    ]
    for section in required_sections:
        if section not in system_prompt:
            logger.error(f"Missing required section: {section}")
            raise ValueError(f"System prompt validation failed: missing {section}")

    # æ ¡éªŒå·¥å…·å®šä¹‰
    tool_tags = ToolRegistry.get_all_registered_tools()
    for tag in tool_tags:
        if f"## {tag}" not in system_prompt:
            logger.warning(f"Tool {tag} not found in system prompt")

    logger.info("System prompt validation passed")

def _validate_conversations(self, conversations: List[Dict]):
    """
    æ ¡éªŒå¯¹è¯åˆ—è¡¨
    """
    # æ ¡éªŒæ ¼å¼
    for i, conv in enumerate(conversations):
        if not isinstance(conv, dict):
            raise ValueError(f"Conversation {i} is not a dict")
        if 'role' not in conv or 'content' not in conv:
            raise ValueError(f"Conversation {i} missing 'role' or 'content'")
        if conv['role'] not in ['system', 'user', 'assistant']:
            raise ValueError(f"Conversation {i} has invalid role: {conv['role']}")

    # æ ¡éªŒé¡ºåº
    if conversations[0]['role'] != 'system':
        raise ValueError("First conversation must be 'system' role")
    if conversations[-1]['role'] != 'user':
        raise ValueError("Last conversation must be 'user' role")

    # æ ¡éªŒæ€» Token æ•°
    total_tokens = sum(len(conv['content']) / 4 for conv in conversations)
    context_window = 128000  # å‡è®¾ 128K ä¸Šä¸‹æ–‡çª—å£
    if total_tokens > context_window * 0.8:  # ä½¿ç”¨ 80% ä¸Šé™
        logger.warning(
            f"Conversations too long: {total_tokens:.0f} tokens "
            f"(80% of {context_window})"
        )

    logger.info(f"Validated: {len(conversations)} conversations, ~{total_tokens:.0f} tokens")
```

### 3.1.7.2 Token æ•°é‡ç›‘æ§

**Token è®¡æ•°ç­–ç•¥**:

```python
class TokenCounter:
    """
    Token è®¡æ•°å™¨ï¼ˆåŸºäº tiktoken æˆ– tokenizersï¼‰
    """
    def __init__(self, model_name: str = "gpt-4"):
        import tiktoken
        try:
            self.encoding = tiktoken.encoding_for_model(model_name)
        except KeyError:
            # ä½¿ç”¨é»˜è®¤ç¼–ç 
            self.encoding = tiktoken.get_encoding("cl100k_base")

    def count_tokens(self, text: str) -> int:
        """ç²¾ç¡®è®¡æ•° Token æ•°é‡"""
        return len(self.encoding.encode(text))

    def count_messages_tokens(self, messages: List[Dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„ Token æ•°é‡"""
        total = 0
        for message in messages:
            # æ¯æ¡æ¶ˆæ¯çš„å…ƒæ•°æ®å¼€é”€ï¼ˆroleã€åˆ†éš”ç¬¦ç­‰ï¼‰
            total += 4  # åŸºç¡€å¼€é”€
            total += self.count_tokens(message.get('role', ''))
            total += self.count_tokens(message.get('content', ''))
        total += 2  # å¯¹è¯ç»“æŸæ ‡è®°
        return total


# ä½¿ç”¨ç¤ºä¾‹
class BaseAgent:
    def __init__(self, ...):
        self.token_counter = TokenCounter(model_name=args.code_model)

    def _validate_conversations(self, conversations: List[Dict]):
        """ä½¿ç”¨ç²¾ç¡® Token è®¡æ•°"""
        total_tokens = self.token_counter.count_messages_tokens(conversations)
        context_window = self._get_context_window()

        logger.info(
            f"Token usage: {total_tokens} / {context_window} "
            f"({total_tokens / context_window * 100:.1f}%)"
        )

        if total_tokens > context_window * 0.9:  # 90% é¢„è­¦é˜ˆå€¼
            logger.error(
                f"Token limit exceeded: {total_tokens} > {context_window * 0.9}"
            )
            raise ValueError("Context window overflow")

    def _get_context_window(self) -> int:
        """æ ¹æ®æ¨¡å‹è·å–ä¸Šä¸‹æ–‡çª—å£å¤§å°"""
        model_name = self.args.code_model
        # ä»é…ç½®æˆ–æ¨¡å‹ä¿¡æ¯è·å–
        from autocoder.utils import llms as llm_utils
        model_info = llm_utils.get_model_info(model_name, self.args.product_mode)
        return model_info.get("context_window", 128000)
```

**Token é¢„ç®—åˆ†é…ç›‘æ§**:

```python
class TokenBudgetMonitor:
    """
    Token é¢„ç®—ç›‘æ§å™¨
    """
    def __init__(self, total_budget: int):
        self.total_budget = total_budget
        self.allocations = {}
        self.used = 0

    def allocate(self, category: str, tokens: int):
        """åˆ†é… Token é¢„ç®—"""
        if self.used + tokens > self.total_budget:
            raise ValueError(
                f"Budget exceeded: {self.used + tokens} > {self.total_budget}"
            )
        self.allocations[category] = tokens
        self.used += tokens
        logger.info(f"Allocated {tokens} tokens to {category} (total: {self.used})")

    def get_remaining(self) -> int:
        """è·å–å‰©ä½™é¢„ç®—"""
        return self.total_budget - self.used

    def report(self):
        """ç”Ÿæˆé¢„ç®—æŠ¥å‘Š"""
        report = "Token Budget Report:\n"
        for category, tokens in self.allocations.items():
            percentage = tokens / self.total_budget * 100
            report += f"  {category}: {tokens} ({percentage:.1f}%)\n"
        report += f"  Remaining: {self.get_remaining()} ({self.get_remaining() / self.total_budget * 100:.1f}%)\n"
        logger.info(report)


# ä½¿ç”¨ç¤ºä¾‹
def agentic_run(self, request: AgentRequest):
    # åˆ›å»ºé¢„ç®—ç›‘æ§å™¨ï¼ˆå‡è®¾ 128K ä¸Šä¸‹æ–‡çª—å£ï¼‰
    budget = TokenBudgetMonitor(total_budget=128000)

    # åˆ†é…ç³»ç»Ÿæç¤ºè¯é¢„ç®—
    system_prompt = self._system.prompt(request)
    system_tokens = self.token_counter.count_tokens(system_prompt)
    budget.allocate("system_prompt", system_tokens)

    # åˆ†é…å¯¹è¯å†å²é¢„ç®—
    history_tokens = self.token_counter.count_messages_tokens(self.conversation_history)
    budget.allocate("conversation_history", history_tokens)

    # åˆ†é…ç”¨æˆ·è¾“å…¥é¢„ç®—
    user_tokens = self.token_counter.count_tokens(request.user_input)
    budget.allocate("user_input", user_tokens)

    # é¢„ç•™è¾“å‡ºé¢„ç®—ï¼ˆçº¦ 30%ï¼‰
    output_budget = int(budget.total_budget * 0.3)
    budget.allocate("output_reserve", output_budget)

    # ç”ŸæˆæŠ¥å‘Š
    budget.report()

    # ç»§ç»­æ‰§è¡Œ...
```

### 3.1.7.3 ä¸Šä¸‹æ–‡æº¢å‡ºå¤„ç†

**æº¢å‡ºæ£€æµ‹**:

```python
def _check_context_overflow(self, conversations: List[Dict]) -> bool:
    """
    æ£€æµ‹ä¸Šä¸‹æ–‡æ˜¯å¦æº¢å‡º

    Returns:
        bool: True è¡¨ç¤ºæº¢å‡ºï¼Œéœ€è¦å¤„ç†
    """
    total_tokens = self.token_counter.count_messages_tokens(conversations)
    context_window = self._get_context_window()
    safe_threshold = context_window * 0.9  # 90% å®‰å…¨é˜ˆå€¼

    if total_tokens > safe_threshold:
        logger.warning(
            f"Context overflow detected: {total_tokens} > {safe_threshold}"
        )
        return True
    return False
```

**æº¢å‡ºå¤„ç†ç­–ç•¥**:

```python
def _handle_context_overflow(self, conversations: List[Dict]) -> List[Dict]:
    """
    å¤„ç†ä¸Šä¸‹æ–‡æº¢å‡º

    ç­–ç•¥ï¼š
    1. è£å‰ªå¯¹è¯å†å²ï¼ˆä¿ç•™æœ€è¿‘çš„Nè½®ï¼‰
    2. å‹ç¼©ç³»ç»Ÿæç¤ºè¯ï¼ˆç§»é™¤éå¿…éœ€éƒ¨åˆ†ï¼‰
    3. æå–å…³é”®ä¿¡æ¯ï¼ˆæ‘˜è¦ï¼‰

    Args:
        conversations: åŸå§‹å¯¹è¯åˆ—è¡¨

    Returns:
        List[Dict]: å¤„ç†åçš„å¯¹è¯åˆ—è¡¨
    """
    context_window = self._get_context_window()
    target_tokens = int(context_window * 0.8)  # ç›®æ ‡ 80%

    # ç­–ç•¥1: è£å‰ªå¯¹è¯å†å²
    system_msg = conversations[0]
    user_msg = conversations[-1]
    history_msgs = conversations[1:-1]

    # ä¿ç•™ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·è¾“å…¥ï¼Œè£å‰ªå†å²
    system_tokens = self.token_counter.count_tokens(system_msg['content'])
    user_tokens = self.token_counter.count_tokens(user_msg['content'])
    available_for_history = target_tokens - system_tokens - user_tokens

    if available_for_history < 0:
        logger.error("System prompt + user input exceeds context window")
        # ç­–ç•¥2: å‹ç¼©ç³»ç»Ÿæç¤ºè¯
        system_msg['content'] = self._compress_system_prompt(system_msg['content'])
        system_tokens = self.token_counter.count_tokens(system_msg['content'])
        available_for_history = target_tokens - system_tokens - user_tokens

    # ä»æœ€è¿‘çš„æ¶ˆæ¯å¼€å§‹ä¿ç•™
    pruned_history = []
    history_tokens = 0
    for msg in reversed(history_msgs):
        msg_tokens = self.token_counter.count_tokens(msg['content'])
        if history_tokens + msg_tokens > available_for_history:
            break
        pruned_history.insert(0, msg)
        history_tokens += msg_tokens

    logger.info(
        f"Pruned conversation history: {len(history_msgs)} â†’ {len(pruned_history)} messages"
    )

    return [system_msg] + pruned_history + [user_msg]


def _compress_system_prompt(self, system_prompt: str) -> str:
    """
    å‹ç¼©ç³»ç»Ÿæç¤ºè¯

    ç­–ç•¥ï¼š
    1. ç§»é™¤å·¥å…·ç¤ºä¾‹ï¼ˆä¿ç•™å·¥å…·å®šä¹‰ï¼‰
    2. ç§»é™¤éå¿…éœ€è§„åˆ™æ–‡ä»¶
    3. ç®€åŒ–æè¿°æ–‡å­—

    Args:
        system_prompt: åŸå§‹ç³»ç»Ÿæç¤ºè¯

    Returns:
        str: å‹ç¼©åçš„ç³»ç»Ÿæç¤ºè¯
    """
    import re

    # ç§»é™¤å·¥å…·ç¤ºä¾‹éƒ¨åˆ†ï¼ˆä¿ç•™å·¥å…·å®šä¹‰ï¼‰
    compressed = re.sub(
        r'# Tool Use Examples.*?(?=====)',
        '',
        system_prompt,
        flags=re.DOTALL
    )

    # ç§»é™¤é¡¹ç›®åŒ…ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    compressed = re.sub(
        r'PROJECT PACKAGE CONTEXT.*?(?=====)',
        '',
        compressed,
        flags=re.DOTALL
    )

    logger.info(
        f"Compressed system prompt: {len(system_prompt)} â†’ {len(compressed)} chars"
    )

    return compressed
```

**è‡ªåŠ¨æ¢å¤æœºåˆ¶**:

```python
def agentic_run(self, request: AgentRequest):
    """
    å¸¦è‡ªåŠ¨æ¢å¤çš„ Agent æ‰§è¡Œæµç¨‹
    """
    try:
        # æ„å»ºå¯¹è¯
        conversations = self._build_conversations(request)

        # æ£€æµ‹æº¢å‡º
        if self._check_context_overflow(conversations):
            # è‡ªåŠ¨å¤„ç†æº¢å‡º
            conversations = self._handle_context_overflow(conversations)

            # äºŒæ¬¡æ£€æµ‹
            if self._check_context_overflow(conversations):
                # ä»ç„¶æº¢å‡ºï¼Œä½¿ç”¨æç«¯ç­–ç•¥
                logger.error("Context still overflow after compression")
                conversations = self._extreme_compression(conversations)

        # æ‰§è¡Œ LLM è°ƒç”¨
        llm_response = stream_chat_with_continue(self.llm, conversations, self.args)

        # å¤„ç†å“åº”...

    except Exception as e:
        logger.exception("Error in agentic_run")
        # å‘é€é”™è¯¯äº‹ä»¶
        yield ErrorEvent(message=str(e))


def _extreme_compression(self, conversations: List[Dict]) -> List[Dict]:
    """
    æç«¯å‹ç¼©ç­–ç•¥ï¼ˆæœ€åæ‰‹æ®µï¼‰

    åªä¿ç•™ï¼š
    1. æ ¸å¿ƒç³»ç»Ÿæç¤ºï¼ˆå·¥å…·å®šä¹‰ + åŸºæœ¬è§„åˆ™ï¼‰
    2. æœ€è¿‘1è½®å¯¹è¯
    3. å½“å‰ç”¨æˆ·è¾“å…¥
    """
    system_msg = conversations[0]
    user_msg = conversations[-1]

    # æåº¦ç®€åŒ–ç³»ç»Ÿæç¤º
    core_prompt = self._extract_core_system_prompt(system_msg['content'])

    # åªä¿ç•™æœ€è¿‘1è½®åŠ©æ‰‹å›å¤
    assistant_msg = None
    for msg in reversed(conversations[1:-1]):
        if msg['role'] == 'assistant':
            assistant_msg = msg
            break

    compressed = [
        {"role": "system", "content": core_prompt},
    ]
    if assistant_msg:
        compressed.append(assistant_msg)
    compressed.append(user_msg)

    logger.warning(f"Extreme compression: {len(conversations)} â†’ {len(compressed)} messages")

    return compressed
```

---

# é˜¶æ®µä¸€æ€»ç»“

## å®Œæˆçš„å†…å®¹

âœ… **ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•´ä½“æ¶æ„è®¾è®¡**
- åŒå±‚æ¶æ„ä½“ç³»ï¼ˆBaseAgent + AgenticEditï¼‰
- 7ä¸ªæ ¸å¿ƒç»„ä»¶çš„è¯¦ç»†åˆ†æ
- ç»„ä»¶äº¤äº’æµç¨‹å›¾
- æ¶æ„ä¼˜åŠ¿ä¸æ”¹è¿›æ–¹å‘

âœ… **ç¬¬äºŒéƒ¨åˆ†ï¼šæç¤ºè¯å·¥ç¨‹**(å«è¡¥å……ç« èŠ‚)
- @byzerllm.prompt() è£…é¥°å™¨æœºåˆ¶
- ç»“æ„åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆ7å¤§éƒ¨åˆ†ï¼‰
- å·¥å…·æè¿°è®¾è®¡
- **2.3.4 é‡è¦å·¥å…·æè¿°æ¨¡æ¿å±•ç¤º**(æ–°å¢)
  - 5ä¸ªæ ¸å¿ƒå·¥å…·çš„å®Œæ•´æè¿°æ¨¡æ¿
  - å·¥å…·æè¿°çš„é€šç”¨è®¾è®¡æ¨¡å¼
- **2.4.3 ç¬¬ä¸‰æ–¹åº“æ–‡æ¡£æ³¨å…¥(æ‰©å±•)**(æ–°å¢)
  - LLMFriendlyPackageManager è¯¦ç»†å®ç°
  - æ–‡æ¡£ä»“åº“æ¶æ„ä¸å…‹éš†æœºåˆ¶
- **2.4.4 ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™æ³¨å…¥(æ‰©å±•)**(æ–°å¢)
  - AutocoderRulesManager å•ä¾‹å®ç°
  - Rules æ–‡ä»¶æ ¼å¼è§„èŒƒ(Markdown + YAML)
  - å¿…éœ€è§„åˆ™ vs æ¡ä»¶è§„åˆ™
- **2.4.5 Sub Agents ä¿¡æ¯æ³¨å…¥(æ‰©å±•)**(æ–°å¢)
  - AgentManager è¯¦ç»†å®ç°
  - Agent æ–‡ä»¶æ ¼å¼å’Œä¼˜å…ˆçº§æœºåˆ¶
- **2.4.6 å·¥å…·ä½¿ç”¨ä¿¡æ¯æ³¨å…¥(æ‰©å±•)**(æ–°å¢)
  - ToolsManager åŠ¨æ€å·¥å…·å‘ç°æœºåˆ¶
  - å¤šä¼˜å…ˆçº§ç›®å½•ç®¡ç†
  - ä¸ ToolRegistry çš„å…³ç³»å¯¹æ¯”
- **2.4.7 æ³¨å…¥é¡ºåºå’Œä¼˜å…ˆçº§(å…¨æ–°ç« èŠ‚)**(æ–°å¢)
  - å››å±‚ä¸Šä¸‹æ–‡çš„è¯¦ç»†æ³¨å…¥é¡ºåº
  - ä¼˜å…ˆçº§è®¾è®¡åŸåˆ™
  - æ³¨å…¥é¡ºåºå¯¹ LLM ç†è§£çš„å½±å“
  - æœ€ä½³å®è·µå»ºè®®

âœ… **ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡å·¥ç¨‹**(å«è¡¥å……ç« èŠ‚)
- å››å±‚ä¸Šä¸‹æ–‡æ„å»ºï¼ˆSystem/Documentation/History/Currentï¼‰
- Message ID ç³»ç»Ÿï¼ˆç”Ÿæˆ/åµŒå…¥/åˆ é™¤ï¼‰
- å¯¹è¯æŒä¹…åŒ–å’Œæ¢å¤
- **3.1.6 å±‚æ¬¡é—´çš„äº¤äº’å’Œä¼ é€’(å…¨æ–°ç« èŠ‚)**(æ–°å¢)
  - å››å±‚ä¿¡æ¯æµå‘
  - è·¨å±‚å¼•ç”¨æœºåˆ¶
  - å±‚æ¬¡åä½œæ¨¡å¼
  - å±‚æ¬¡é—´æ•°æ®å…±äº«
  - å±‚æ¬¡éš”ç¦»ä¸ä¿æŠ¤
- **3.1.7 ä¸Šä¸‹æ–‡å®Œæ•´æ€§æ ¡éªŒ(å…¨æ–°ç« èŠ‚)**(æ–°å¢)
  - æ ¡éªŒæœºåˆ¶æ¦‚è¿°
  - Token æ•°é‡ç›‘æ§
  - ä¸Šä¸‹æ–‡æº¢å‡ºå¤„ç†
- **3.3.1 å¯¹è¯æŒä¹…åŒ–å’Œæ¢å¤(æ‰©å±•)**(æ–°å¢)
  - ConversationManager å•ä¾‹æ¨¡å¼å®ç°
  - ConversationManagerConfig è¯¦ç»†é…ç½®
  - æ ¸å¿ƒæ–¹æ³•å®ç°å’Œå¹¶å‘å®‰å…¨
- å‘½åç©ºé—´éš”ç¦»
- Token ç»Ÿè®¡å›å†™

## æ ¸å¿ƒå‘ç°

### 1. æ¶æ„è®¾è®¡çš„ç²¾å¦™ä¹‹å¤„

- **åŒå±‚åˆ†ç¦»**ï¼šBaseAgent æä¾›åŸºç¡€èƒ½åŠ›ï¼ŒAgenticEdit æä¾›é«˜çº§åŠŸèƒ½
- **ç»„åˆæ¨¡å¼**ï¼šå¤§é‡ä½¿ç”¨ç»„åˆè€Œéç»§æ‰¿ï¼Œæé«˜çµæ´»æ€§
- **äº‹ä»¶é©±åŠ¨**ï¼šé€šè¿‡äº‹ä»¶æµå®ç°ç»„ä»¶è§£è€¦
- **æ’ä»¶ç³»ç»Ÿ**ï¼šæ”¯æŒå‰åç½®é’©å­ï¼Œæ˜“äºæ‰©å±•

### 2. æç¤ºè¯å·¥ç¨‹çš„åˆ›æ–°

- **è£…é¥°å™¨æ¨¡å¼**ï¼šæç¤ºè¯ä¸ä»£ç å®Œç¾åˆ†ç¦»
- **ç»“æ„åŒ–è®¾è®¡**ï¼š7å¤§éƒ¨åˆ†ï¼Œå±‚æ¬¡æ¸…æ™°
- **XML æ ¼å¼**ï¼šé€‚åˆå¤šè¡Œå†…å®¹ï¼Œæµå¼è§£æå‹å¥½
- **åŠ¨æ€æ³¨å…¥**ï¼šå·¥å…·ã€æ–‡æ¡£ã€è§„åˆ™åŠ¨æ€æ³¨å…¥

### 3. ä¸Šä¸‹æ–‡å·¥ç¨‹çš„å·§æ€

- **å››å±‚æ¶æ„**ï¼šSystem â†’ Documentation â†’ History â†’ Current
- **é¢„è½®æ¬¡å­¦ä¹ **ï¼šé€šè¿‡é¢„è®¾å“åº”è®© LLM "è®°ä½"æ–‡æ¡£
- **Message ID**ï¼šæ”¯æŒç²¾ç¡®åˆ é™¤ï¼Œä¸å½±å“å…¶ä»–æ¶ˆæ¯
- **å‘½åç©ºé—´**ï¼šå¤šé¡¹ç›®éš”ç¦»ï¼Œäº’ä¸å¹²æ‰°

## è®¾è®¡å“²å­¦æ€»ç»“

1. **å…³æ³¨ç‚¹åˆ†ç¦»ï¼ˆSeparation of Concernsï¼‰**
   - æ¯ä¸ªç»„ä»¶èŒè´£å•ä¸€æ˜ç¡®
   - æ˜“äºç†è§£å’Œç»´æŠ¤

2. **å¯æ‰©å±•æ€§ï¼ˆExtensibilityï¼‰**
   - å·¥å…·åŠ¨æ€æ³¨å†Œ
   - æ’ä»¶ç³»ç»Ÿ
   - å›è°ƒæœºåˆ¶

3. **å¯é æ€§ï¼ˆReliabilityï¼‰**
   - å¯¹è¯æŒä¹…åŒ–
   - æ–­ç‚¹ç»­ä¼ 
   - é”™è¯¯å¤„ç†å’Œé‡è¯•

4. **æ€§èƒ½ä¼˜åŒ–ï¼ˆPerformanceï¼‰**
   - æ™ºèƒ½ä¸Šä¸‹æ–‡å‰ªè£
   - å¤šçº§ç¼“å­˜
   - å¹¶è¡Œæ‰§è¡Œ

## ä¸‹ä¸€æ­¥ç ”ç©¶æ–¹å‘

é˜¶æ®µäºŒå°†æ·±å…¥ç ”ç©¶ï¼š
- ç¬¬å››éƒ¨åˆ†ï¼šå¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡å‰ªè£ï¼ˆæ ¸å¿ƒäº®ç‚¹ï¼‰
- ç¬¬äº”éƒ¨åˆ†ï¼šæµå¼å“åº”è§£æï¼ˆæ ¸å¿ƒæŠ€æœ¯ï¼‰
- ç¬¬å…­éƒ¨åˆ†ï¼šå·¥å…·ç³»ç»Ÿè®¾è®¡

---

**é˜¶æ®µä¸€ç ”ç©¶å®Œæˆæ—¶é—´**: 2025-10-16
**åŸå§‹å†…å®¹**: ~15,000 å­— (3,082è¡Œ)
**è¡¥å……å†…å®¹**: ~30,000 å­— (5,338è¡Œ)
**æ€»å­—æ•°**: ~45,000 å­— (8,420è¡Œ)
**ä»£ç ç¤ºä¾‹**: 100+ ä¸ª
**è¡¥å……ç« èŠ‚**: 10ä¸ªæ ¸å¿ƒç« èŠ‚
**ç ”ç©¶æ·±åº¦**: â˜…â˜…â˜…â˜…â˜…

**è¡¥å……è¯´æ˜**: æœ¬æ¬¡è¡¥å……æ·±åŒ–äº†ç¬¬äºŒã€ç¬¬ä¸‰éƒ¨åˆ†çš„å…³é”®å®ç°ç»†èŠ‚ï¼ŒåŒ…æ‹¬:
- ToolsManagerã€AutocoderRulesManagerã€AgentManagerã€ConversationManager ç­‰æ ¸å¿ƒç±»çš„å®Œæ•´å®ç°
- æ³¨å…¥é¡ºåºå’Œä¼˜å…ˆçº§çš„è¯¦ç»†åˆ†æ
- å±‚æ¬¡é—´äº¤äº’å’Œä¸Šä¸‹æ–‡å®Œæ•´æ€§æ ¡éªŒæœºåˆ¶
- 5ä¸ªé‡è¦å·¥å…·çš„å®Œæ•´æè¿°æ¨¡æ¿
- æ‰€æœ‰ä»£ç ç¤ºä¾‹å‡æ¥è‡ªå®é™…æºç ï¼Œé…æœ‰è¯¦ç»†ä¸­æ–‡æ³¨é‡Š

**çŠ¶æ€**: âœ… é˜¶æ®µä¸€å®Œæˆ(åŒ…å«æ·±åº¦è¡¥å……)


---

# ç¬¬å››éƒ¨åˆ†ï¼šå¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡å‰ªè£ï¼ˆæ ¸å¿ƒäº®ç‚¹ï¼‰

## ç ”ç©¶ç›®æ ‡

æ·±å…¥ç ”ç©¶ autocoder çš„ä¸Šä¸‹æ–‡å‰ªè£æœºåˆ¶ï¼Œè¿™æ˜¯ agentic agent èŒƒå¼ä¸­æœ€å…³é”®çš„æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ä¹‹ä¸€ã€‚é€šè¿‡æ™ºèƒ½å‰ªè£ï¼Œç³»ç»Ÿèƒ½å¤Ÿåœ¨ä¿æŒå¯¹è¯è¿è´¯æ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆæ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…è¶…å‡ºæ¨¡å‹é™åˆ¶ï¼Œé™ä½ API æˆæœ¬ã€‚

## æ ¸å¿ƒæ–‡ä»¶

- `autocoder/common/pruner/agentic_conversation_pruner.py` (747è¡Œ) - ä¸»å‰ªè£å™¨
- `autocoder/common/pruner/conversation_message_ids_pruner.py` (473è¡Œ) - ç²¾ç¡®åˆ é™¤å‰ªè£å™¨  
- `autocoder/common/pruner/tool_content_detector.py` (227è¡Œ) - å·¥å…·å†…å®¹æ£€æµ‹å™¨
- `autocoder/common/pruner/conversation_message_ids_manager.py` (347è¡Œ) - æ¶ˆæ¯IDç®¡ç†å™¨
- `autocoder/common/v2/agent/agentic_edit_tools/conversation_message_ids_write_tool_resolver.py` (300è¡Œ) - å·¥å…·é›†æˆ

## 4.1 AgenticConversationPruner ç±»è®¾è®¡

### 4.1.1 ç±»èŒè´£å’Œæ¶æ„

`AgenticConversationPruner` æ˜¯ agentic å¯¹è¯åœºæ™¯ä¸‹çš„ä¸“ç”¨å‰ªè£å™¨ï¼Œé‡‡ç”¨**åŒç­–ç•¥ç»„åˆ**çš„è®¾è®¡ï¼š

```
AgenticConversationPruner
    â”œâ”€â”€ Message IDs Pruningï¼ˆç²¾ç¡®åˆ é™¤ï¼‰
    â”‚   â””â”€â”€ åŸºäº LLM ä¸»åŠ¨æ ‡è®°çš„æ¶ˆæ¯IDï¼Œç²¾ç¡®åˆ é™¤æŒ‡å®šæ¶ˆæ¯
    â””â”€â”€ Tool Cleanup Pruningï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰
        â””â”€â”€ è‡ªåŠ¨è¯†åˆ«å·¥å…·è°ƒç”¨å’Œç»“æœï¼Œå‹ç¼©å¤§å†…å®¹å­—æ®µ
```

**è®¾è®¡ç‰¹ç‚¹**ï¼š
1. **æ¸è¿›å¼å‰ªè£**ï¼šå…ˆå°è¯•ç²¾ç¡®åˆ é™¤ï¼Œä¸å¤Ÿå†æ™ºèƒ½å‹ç¼©
2. **ä¿æŠ¤æœºåˆ¶**ï¼šä¿ç•™æœ€å°æ¶ˆæ¯æ•°ï¼ˆ6æ¡ï¼‰ï¼Œé¿å…è¿‡åº¦å‰ªè£
3. **ç»Ÿè®¡ç›‘æ§**ï¼šå®Œæ•´çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œä¾¿äºåˆ†æå’Œè°ƒä¼˜
4. **å®‰å…¨å…œåº•**ï¼šè¶…é™åæç¤º LLM ä¸»åŠ¨æ¸…ç†

### 4.1.2 ç±»ç»“æ„å’Œåˆå§‹åŒ–

```python
class AgenticConversationPruner:
    """
    Agentic å¯¹è¯ä¸“ç”¨å‰ªè£å™¨ï¼Œæ”¯æŒå·¥å…·è¾“å‡ºæ¸…ç†
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ¸…ç†å·¥å…·ç»“æœæ¶ˆæ¯ï¼ˆrole='user', åŒ…å« '<tool_result>'ï¼‰
    2. æ¸…ç†å·¥å…·è°ƒç”¨å†…å®¹ï¼ˆrole='assistant', åŒ…å«å¤§å†…å®¹å·¥å…·è°ƒç”¨ï¼‰
    3. åŸºäºæ¶ˆæ¯IDçš„ç²¾ç¡®åˆ é™¤
    """
    
    def __init__(self, args: AutoCoderArgs, 
                 llm: Union[byzerllm.ByzerLLM, byzerllm.SimpleByzerLLM, None], 
                 conversation_id: Optional[str] = None):
        if conversation_id is None:
            raise ValueError("conversation_id is required in AgenticConversationPruner")
        
        self.args = args
        self.llm = llm
        self.conversation_id = conversation_id
        self.printer = Printer()
        
        # æ›¿æ¢æ¶ˆæ¯æ¨¡æ¿
        self.replacement_message = "This message has been cleared. If you still want to get this information, you can call the tool again to retrieve it."
        
        # åˆå§‹åŒ–å‚æ•°è§£æå™¨ï¼ˆæ”¯æŒçµæ´»çš„å‚æ•°æ ¼å¼ï¼‰
        self.args_parser = AutoCoderArgsParser()
        
        # åˆå§‹åŒ–å·¥å…·å†…å®¹æ£€æµ‹å™¨
        self.tool_content_detector = ToolContentDetector(
            replacement_message="Content cleared to save tokens"
        )
        
        # åˆå§‹åŒ–åŸºäºæ¶ˆæ¯IDçš„å‰ªè£ç»„ä»¶
        self.message_ids_api = get_conversation_message_ids_api()
        self.message_ids_pruner = ConversationMessageIdsPruner()
        
        # å‰ªè£ç»Ÿè®¡ä¿¡æ¯
        self.pruning_stats = {
            "range_pruning_applied": False,      # æ˜¯å¦åº”ç”¨äº†æ¶ˆæ¯IDå‰ªè£
            "range_pruning_success": False,      # æ¶ˆæ¯IDå‰ªè£æ˜¯å¦æˆåŠŸ
            "original_length": 0,                # åŸå§‹æ¶ˆæ¯æ•°
            "after_range_pruning": 0,            # æ¶ˆæ¯IDå‰ªè£åæ¶ˆæ¯æ•°
            "after_tool_cleanup": 0,             # å·¥å…·æ¸…ç†åæ¶ˆæ¯æ•°
            "total_compression_ratio": 1.0       # æ€»å‹ç¼©æ¯”
        }
```

**å…³é”®è®¾è®¡ç‚¹**ï¼š
1. **conversation_id å¿…éœ€**ï¼šå‰ªè£å™¨å¿…é¡»ç»‘å®šåˆ°ç‰¹å®šä¼šè¯ï¼Œç”¨äºæ¶ˆæ¯IDè¿½è¸ª
2. **ç»„åˆæ¨¡å¼**ï¼šç»„åˆäº† ToolContentDetector å’Œ MessageIdsPruner
3. **ç»Ÿè®¡ä¼˜å…ˆ**ï¼šå†…ç½®è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œä¾¿äºç›‘æ§å’Œè°ƒä¼˜
4. **çµæ´»é…ç½®**ï¼šé€šè¿‡ AutoCoderArgsParser æ”¯æŒå¤šç§å‚æ•°æ ¼å¼

### 4.1.3 æ ¸å¿ƒæ–¹æ³•ï¼šprune_conversations

ä¸»å‰ªè£æ–¹æ³•ï¼Œæ‰§è¡ŒåŒç­–ç•¥å‰ªè£æµç¨‹ï¼š

```python
def prune_conversations(self, conversations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    åº”ç”¨åŒç­–ç•¥å‰ªè£ï¼šå…ˆåŸºäºæ¶ˆæ¯IDç²¾ç¡®åˆ é™¤ï¼Œå†æ™ºèƒ½æ¸…ç†å·¥å…·å†…å®¹
    
    Args:
        conversations: åŸå§‹å¯¹è¯åˆ—è¡¨
    
    Returns:
        å‰ªè£åçš„å¯¹è¯åˆ—è¡¨
    """
    safe_zone_tokens = self._get_parsed_safe_zone_tokens()
    original_length = len(conversations)
    
    # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
    self.pruning_stats["original_length"] = original_length
    
    # æ£€æŸ¥å½“å‰tokenæ•°
    current_tokens = count_string_tokens(
        json.dumps(conversations, ensure_ascii=False))
    
    # å¦‚æœå·²åœ¨å®‰å…¨åŒºå†…ï¼Œæ— éœ€å‰ªè£
    if current_tokens <= safe_zone_tokens:
        self.pruning_stats.update({
            "after_range_pruning": original_length,
            "after_tool_cleanup": original_length,
            "total_compression_ratio": 1.0
        })
        return conversations
    
    # æ­¥éª¤1: åº”ç”¨æ¶ˆæ¯IDå‰ªè£ï¼ˆå¦‚æœæœ‰é…ç½®ï¼‰
    processed_conversations = self._apply_message_ids_pruning(conversations)
    logger.info(
        f"After Message IDs pruning: {len(conversations)} -> {len(processed_conversations)} messages")
    
    # é‡æ–°æ£€æŸ¥tokenæ•°
    current_tokens = count_string_tokens(json.dumps(
        processed_conversations, ensure_ascii=False))
    
    # æ­¥éª¤2: å¦‚æœä»è¶…é™ï¼Œåº”ç”¨å·¥å…·å†…å®¹æ¸…ç†
    if current_tokens > safe_zone_tokens:
        config = {"safe_zone_tokens": safe_zone_tokens}
        processed_conversations = self._unified_tool_cleanup_prune(
            processed_conversations, config)
    
    # æ›´æ–°æœ€ç»ˆç»Ÿè®¡
    final_length = len(processed_conversations)
    self.pruning_stats["after_tool_cleanup"] = final_length
    self.pruning_stats["total_compression_ratio"] = final_length / \
        original_length if original_length > 0 else 1.0
    
    # è®°å½•æ•´ä½“å‰ªè£ç»“æœ
    logger.info(f"Complete pruning: {original_length} -> {final_length} messages "
                f"(total compression: {self.pruning_stats['total_compression_ratio']:.2%})")
    
    # å…œåº•æœºåˆ¶ï¼šå¦‚æœä»ç„¶è¶…é™ï¼Œæç¤ºLLMä¸»åŠ¨æ¸…ç†
    final_tokens = count_string_tokens(json.dumps(
        processed_conversations, ensure_ascii=False))
    if final_tokens > safe_zone_tokens:
        cleanup_message = "The conversation is still too long, please use conversation_message_ids_write tool to save the message ids to be deleted."
        
        # ä½¿ç”¨æ ‡å‡†åŒ–çš„æç¤ºåˆå¹¶æ¨¡å—
        processed_conversations = merge_with_last_user_message(
            processed_conversations, cleanup_message)
    
    # ä¿å­˜å‰ªè£åçš„å¯¹è¯åˆ°æ—¥å¿—ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
    save_formatted_log(self.args.source_dir, json.dumps(processed_conversations, ensure_ascii=False),
                       "agentic_pruned_conversation", conversation_id=self._get_current_conversation_id())
    
    return processed_conversations
```

**æµç¨‹å›¾**ï¼š

```
å¼€å§‹
  â†“
è®¡ç®—å½“å‰tokenæ•°
  â†“
tokenæ•° â‰¤ å®‰å…¨åŒº? â”€â”€Yesâ”€â”€> ç›´æ¥è¿”å›
  â†“ No
åº”ç”¨ Message IDs Pruningï¼ˆç²¾ç¡®åˆ é™¤ï¼‰
  â†“
é‡æ–°è®¡ç®—tokenæ•°
  â†“
tokenæ•° â‰¤ å®‰å…¨åŒº? â”€â”€Yesâ”€â”€> è¿”å›å‰ªè£ç»“æœ
  â†“ No
åº”ç”¨ Tool Cleanup Pruningï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰
  â†“
é‡æ–°è®¡ç®—tokenæ•°
  â†“
tokenæ•° â‰¤ å®‰å…¨åŒº? â”€â”€Yesâ”€â”€> è¿”å›å‰ªè£ç»“æœ
  â†“ No
æç¤ºLLMä¸»åŠ¨æ¸…ç†ï¼ˆå…œåº•æœºåˆ¶ï¼‰
  â†“
è¿”å›å‰ªè£ç»“æœ + æç¤ºæ¶ˆæ¯
  â†“
ç»“æŸ
```

**å…³é”®ç‰¹æ€§**ï¼š
1. **æ¸è¿›å¼ç­–ç•¥**ï¼šä¼˜å…ˆçº§ä»é«˜åˆ°ä½å°è¯•ä¸åŒç­–ç•¥
2. **å®‰å…¨æ£€æŸ¥**ï¼šæ¯ä¸€æ­¥éƒ½æ£€æŸ¥tokenæ•°ï¼Œé¿å…è¿‡åº¦å‰ªè£
3. **å…œåº•æœºåˆ¶**ï¼šå¦‚æœæ‰€æœ‰è‡ªåŠ¨ç­–ç•¥éƒ½ä¸å¤Ÿï¼Œæç¤ºLLMä¸»åŠ¨å‚ä¸
4. **å®Œæ•´æ—¥å¿—**ï¼šä¿å­˜å‰ªè£åçš„å®Œæ•´å¯¹è¯ï¼Œä¾¿äºè°ƒè¯•å’Œåˆ†æ


## 4.2 Message IDs Pruningï¼ˆç²¾ç¡®åˆ é™¤ï¼‰

### 4.2.1 è®¾è®¡ç†å¿µ

Message IDs Pruning æ˜¯ä¸€ç§**LLMä¸»å¯¼çš„ç²¾ç¡®åˆ é™¤æœºåˆ¶**ï¼Œè®© LLM è‡ªå·±å†³å®šå“ªäº›æ¶ˆæ¯å¯ä»¥åˆ é™¤ï¼Œè€Œä¸æ˜¯ç”±ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­ã€‚è¿™ç§è®¾è®¡æœ‰å‡ ä¸ªä¼˜åŠ¿ï¼š

1. **æ™ºèƒ½å†³ç­–**ï¼šLLM ç†è§£ä¸Šä¸‹æ–‡ï¼ŒçŸ¥é“å“ªäº›æ¶ˆæ¯å·²ç»ä¸å†éœ€è¦
2. **ç²¾ç¡®æ§åˆ¶**ï¼šåŸºäºæ¶ˆæ¯IDç²¾ç¡®åˆ é™¤ï¼Œä¸ä¼šè¯¯åˆ é‡è¦ä¿¡æ¯
3. **åä½œå¼**ï¼šç³»ç»Ÿæä¾›å·¥å…·ï¼ŒLLM ä¸»åŠ¨ä½¿ç”¨ï¼Œå½¢æˆé—­ç¯

### 4.2.2 ConversationMessageIdsPruner ç±»

è¿™æ˜¯å®ç°ç²¾ç¡®åˆ é™¤çš„æ ¸å¿ƒç±»ï¼š

```python
class ConversationMessageIdsPruner:
    """ä¼šè¯æ¶ˆæ¯IDå‰ªè£å™¨
    
    æ”¯æŒä¸¤ç§å‰ªè£æ¨¡å¼ï¼š
    1. æˆå¯¹è£å‰ªï¼ˆpreserve_pairs=Trueï¼‰ï¼šä¿è¯ user/assistant æ¶ˆæ¯æˆå¯¹åˆ é™¤
    2. ç®€å•è£å‰ªï¼ˆpreserve_pairs=Falseï¼‰ï¼šç›´æ¥æŒ‰æ¶ˆæ¯IDåˆ é™¤
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å‰ªè£å™¨ï¼ˆæ— çŠ¶æ€è®¾è®¡ï¼‰"""
        pass
    
    def prune_conversations(
        self, 
        conversations: List[Dict[str, Any]], 
        conversation_message_ids: ConversationMessageIds
    ) -> MessageIdsPruningResult:
        """æ ¹æ®æ¶ˆæ¯IDé…ç½®è£å‰ªä¼šè¯
        
        Args:
            conversations: åŸå§‹ä¼šè¯åˆ—è¡¨
            conversation_message_ids: æ¶ˆæ¯IDé…ç½®å¯¹è±¡
        
        Returns:
            MessageIdsPruningResult: åŒ…å«å‰ªè£ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
        """
        try:
            original_length = len(conversations)
            
            # ç©ºå¯¹è¯å¤„ç†
            if not conversations:
                return MessageIdsPruningResult(
                    success=True,
                    pruned_conversations=[],
                    original_length=0,
                    pruned_length=0,
                    message_ids_applied=[],
                    preserve_pairs=conversation_message_ids.preserve_pairs
                )
            
            # éªŒè¯æ¶ˆæ¯IDï¼ˆå…è®¸éƒ¨åˆ†ç¼ºå¤±ï¼‰
            api = get_conversation_message_ids_api()
            
            # æå–å¯¹è¯ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ID
            conversation_msg_ids = []
            for conv in conversations:
                extracted_id = self._extract_message_id(conv)
                if extracted_id is not None:                    
                    conversation_msg_ids.append(extracted_id)
            
            # éªŒè¯æ¶ˆæ¯IDï¼ˆè‡ªåŠ¨ä¿®å¤ï¼Œå…è®¸ç¼ºå¤±ï¼‰
            validation_result = api.validate_message_ids(
                conversation_message_ids.message_ids, 
                conversation_msg_ids,
                auto_fix=True,      # è‡ªåŠ¨ä¿®å¤æ ¼å¼é—®é¢˜
                allow_missing=True  # å…è®¸æŸäº›æ¶ˆæ¯IDä¸å­˜åœ¨
            )
            
            # éªŒè¯å¤±è´¥å¤„ç†
            if not validation_result.is_valid:
                return MessageIdsPruningResult(
                    success=False,
                    pruned_conversations=conversations,
                    original_length=original_length,
                    pruned_length=original_length,
                    message_ids_applied=[],
                    preserve_pairs=conversation_message_ids.preserve_pairs,
                    error_message=validation_result.error_message
                )
            
            # ä½¿ç”¨éªŒè¯åçš„æœ‰æ•ˆæ¶ˆæ¯IDåˆ—è¡¨
            effective_message_ids = validation_result.normalized_message_ids or []
            
            # å¦‚æœæ‰€æœ‰æ¶ˆæ¯IDéƒ½è¢«è¿‡æ»¤äº†ï¼Œç›´æ¥è¿”å›
            if not effective_message_ids:
                logger.info("No valid message IDs found in conversation, skipping pruning")
                return MessageIdsPruningResult(
                    success=True,
                    pruned_conversations=conversations,
                    original_length=original_length,
                    pruned_length=original_length,
                    message_ids_applied=[],
                    preserve_pairs=conversation_message_ids.preserve_pairs,
                    warnings=validation_result.warnings
                )
            
            # æ ¹æ®é…ç½®é€‰æ‹©å‰ªè£ç­–ç•¥
            if conversation_message_ids.preserve_pairs:
                result = self._prune_with_pair_preservation(conversations, effective_message_ids)
            else:
                result = self._prune_simple(conversations, effective_message_ids)
            
            # æ›´æ–°ç»“æœä¿¡æ¯
            result.original_length = original_length
            result.preserve_pairs = conversation_message_ids.preserve_pairs
            result.message_ids_applied = effective_message_ids
            result.warnings = (result.warnings or []) + (validation_result.warnings or [])
            
            logger.info(f"Message IDs pruning completed: {original_length} -> {result.pruned_length} messages "
                       f"(compression: {result.compression_ratio:.2%})")
            
            return result
            
        except Exception as e:
            error_msg = f"Message IDs pruning failed: {str(e)}"
            logger.error(error_msg)
            return MessageIdsPruningResult(
                success=False,
                pruned_conversations=conversations,
                original_length=len(conversations),
                pruned_length=len(conversations),
                message_ids_applied=[],
                preserve_pairs=conversation_message_ids.preserve_pairs,
                error_message=error_msg
            )
```

### 4.2.3 Message ID æå–æœºåˆ¶

ä»æ¶ˆæ¯ä¸­æå–8ä½æ¶ˆæ¯IDçš„å…³é”®æ–¹æ³•ï¼š

```python
def _extract_message_id(self, conversation: Dict[str, Any]) -> Optional[str]:
    """ä»ä¼šè¯ä¸­æå–æ¶ˆæ¯IDï¼ˆå‰8ä¸ªå­—ç¬¦ï¼‰
    
    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. ç›´æ¥ä» message_id å­—æ®µè·å–
    2. ä» content ä¸­æå– [[message_id: xxxxxxxx]] æ ¼å¼
    
    Args:
        conversation: ä¼šè¯å­—å…¸
    
    Returns:
        æ¶ˆæ¯IDï¼ˆå‰8ä¸ªå­—ç¬¦ï¼‰æˆ– None
    """
    # æ–¹æ³•1: ç›´æ¥ä»message_idå­—æ®µè·å–
    message_id = conversation.get("message_id", "")
    if isinstance(message_id, str) and len(message_id) >= 8:
        return message_id[:8]
    
    # æ–¹æ³•2: ä»contentä¸­æå–hintæ ¼å¼çš„message_id
    content = conversation.get("content", "")
    if isinstance(content, str):
        import re
        # åŒ¹é… [[message_id: xxxxxxxx]] æ ¼å¼ï¼ˆæ ‡å‡†æ ¼å¼ï¼‰
        pattern1 = r'\[\[message_id:\s*([a-fA-F0-9]{8})\]\]'
        match1 = re.search(pattern1, content)
        if match1:
            return match1.group(1).lower()
        
        # åŒ¹é… message_id: xxxxxxxx æ ¼å¼ï¼ˆå…¼å®¹æ ¼å¼ï¼‰
        pattern2 = r'message_id:\s*([a-fA-F0-9]{8})'
        match2 = re.search(pattern2, content)
        if match2:
            return match2.group(1).lower()
    
    return None
```

**è®¾è®¡è¦ç‚¹**ï¼š
1. **å¤šæ ¼å¼æ”¯æŒ**ï¼šæ”¯æŒå­—æ®µå’Œå†…å®¹åµŒå…¥ä¸¤ç§æ ¼å¼
2. **å‰8ä½æˆªå–**ï¼šUUIDé€šå¸¸å¾ˆé•¿ï¼Œåªä½¿ç”¨å‰8ä½å³å¯å”¯ä¸€è¯†åˆ«
3. **å¤§å°å†™å¤„ç†**ï¼šç»Ÿä¸€è½¬ä¸ºå°å†™ï¼Œé¿å…å¤§å°å†™ä¸åŒ¹é…

### 4.2.4 æˆå¯¹è£å‰ªç®—æ³•ï¼ˆpreserve_pairs=Trueï¼‰

æˆå¯¹è£å‰ªä¿è¯ user/assistant æ¶ˆæ¯æˆå¯¹åˆ é™¤ï¼Œç»´æŠ¤å¯¹è¯å®Œæ•´æ€§ï¼š

```python
def _prune_with_pair_preservation(
    self, 
    conversations: List[Dict[str, Any]], 
    message_ids_to_delete: List[str]
) -> MessageIdsPruningResult:
    """æˆå¯¹è£å‰ªç®—æ³• - ä¿è¯user/assistantæˆå¯¹
    
    ç®—æ³•æ­¥éª¤ï¼š
    1. åˆ†æä¼šè¯é…å¯¹ç»“æ„
    2. è°ƒæ•´åˆ é™¤åˆ—è¡¨ä»¥ä¿è¯é…å¯¹å®Œæ•´æ€§
    3. æ‰§è¡Œåˆ é™¤æ“ä½œ
    """
    try:
        # æ­¥éª¤1: åˆ†æä¼šè¯é…å¯¹ç»“æ„
        pairs = self._analyze_conversation_pairs(conversations)
        
        # æ­¥éª¤2: è°ƒæ•´æ¶ˆæ¯IDä»¥ä¿è¯é…å¯¹å®Œæ•´æ€§
        adjusted_message_ids, warnings = self._adjust_message_ids_for_pairs(
            message_ids_to_delete, pairs, conversations
        )
        
        # æ­¥éª¤3: åˆ é™¤è°ƒæ•´åçš„æ¶ˆæ¯
        pruned_conversations = self._remove_conversations_by_message_ids(
            conversations, adjusted_message_ids
        )
        
        return MessageIdsPruningResult(
            success=True,
            pruned_conversations=pruned_conversations,
            original_length=len(conversations),
            pruned_length=len(pruned_conversations),
            message_ids_applied=adjusted_message_ids,
            preserve_pairs=True,
            warnings=warnings
        )
        
    except Exception as e:
        return MessageIdsPruningResult(
            success=False,
            pruned_conversations=conversations,
            original_length=len(conversations),
            pruned_length=len(conversations),
            message_ids_applied=message_ids_to_delete,
            preserve_pairs=True,
            error_message=f"Pair preservation pruning failed: {str(e)}"
        )
```

**é…å¯¹åˆ†ææ–¹æ³•**ï¼š

```python
def _analyze_conversation_pairs(self, conversations: List[Dict[str, Any]]) -> List[MessagePair]:
    """åˆ†æä¼šè¯çš„é…å¯¹ç»“æ„
    
    é…å¯¹è§„åˆ™ï¼š
    - æ¯ä¸ª user æ¶ˆæ¯ä¸ç´§éšå…¶åçš„ç¬¬ä¸€ä¸ª assistant æ¶ˆæ¯é…å¯¹
    - åªæœ‰å½“ä¸¤ä¸ªæ¶ˆæ¯éƒ½æœ‰IDæ—¶æ‰åˆ›å»ºé…å¯¹
    - æœªé…å¯¹çš„æ¶ˆæ¯å•ç‹¬å¤„ç†
    
    Returns:
        MessagePair åˆ—è¡¨
    """
    pairs = []
    
    i = 0
    while i < len(conversations):
        current_msg = conversations[i]
        current_role = current_msg.get("role", "")
        
        if current_role == "user":
            # æŸ¥æ‰¾å¯¹åº”çš„assistantæ¶ˆæ¯
            assistant_index = None
            for j in range(i + 1, len(conversations)):
                if conversations[j].get("role") == "assistant":
                    assistant_index = j
                    break
            
            if assistant_index is not None:
                # æå–æ¶ˆæ¯ID
                user_msg_id = self._extract_message_id(conversations[i])
                assistant_msg_id = self._extract_message_id(conversations[assistant_index])
                
                # åªæœ‰ä¸¤ä¸ªIDéƒ½å­˜åœ¨æ—¶æ‰åˆ›å»ºé…å¯¹
                if user_msg_id is not None and assistant_msg_id is not None:
                    pair = MessagePair(
                        user_index=i,
                        assistant_index=assistant_index,
                        user_message_id=user_msg_id,
                        assistant_message_id=assistant_msg_id,
                        pair_start=i,
                        pair_end=assistant_index
                    )
                    pairs.append(pair)
                i = assistant_index + 1  # è·³åˆ°ä¸‹ä¸€ä¸ªå¯èƒ½çš„useræ¶ˆæ¯
            else:
                # æ²¡æœ‰æ‰¾åˆ°é…å¯¹çš„assistant
                i += 1
        else:
            # éuseræ¶ˆæ¯ï¼Œå•ç‹¬å¤„ç†
            i += 1
    
    logger.debug(f"Found {len(pairs)} conversation pairs in {len(conversations)} messages")
    return pairs
```

**é…å¯¹è°ƒæ•´æ–¹æ³•**ï¼š

```python
def _adjust_message_ids_for_pairs(
    self, 
    message_ids_to_delete: List[str], 
    pairs: List[MessagePair],
    conversations: List[Dict[str, Any]]
) -> tuple[List[str], List[str]]:
    """è°ƒæ•´æ¶ˆæ¯IDåˆ—è¡¨ä»¥ä¿è¯é…å¯¹å®Œæ•´æ€§
    
    è°ƒæ•´è§„åˆ™ï¼š
    - å¦‚æœåˆ é™¤ user æ¶ˆæ¯ï¼Œä¹Ÿåˆ é™¤å¯¹åº”çš„ assistant æ¶ˆæ¯
    - å¦‚æœåˆ é™¤ assistant æ¶ˆæ¯ï¼Œä¹Ÿåˆ é™¤å¯¹åº”çš„ user æ¶ˆæ¯
    - è¿™æ ·ä¿è¯åˆ é™¤åä¸ä¼šå‡ºç°å­¤ç«‹çš„ user æˆ– assistant æ¶ˆæ¯
    
    Returns:
        (è°ƒæ•´åçš„æ¶ˆæ¯IDåˆ—è¡¨, è­¦å‘Šä¿¡æ¯åˆ—è¡¨)
    """
    adjusted_message_ids = set(message_ids_to_delete)
    warnings = []
    
    # æ£€æŸ¥æ¯ä¸ªé…å¯¹
    for pair in pairs:
        user_id = pair.user_message_id
        assistant_id = pair.assistant_message_id
        
        user_to_delete = user_id in adjusted_message_ids
        assistant_to_delete = assistant_id in adjusted_message_ids
        
        # å¦‚æœåªåˆ é™¤é…å¯¹ä¸­çš„ä¸€ä¸ªæ¶ˆæ¯ï¼Œéœ€è¦è°ƒæ•´
        if user_to_delete and not assistant_to_delete:
            # ç”¨æˆ·æ¶ˆæ¯è¦åˆ é™¤ä½†åŠ©æ‰‹æ¶ˆæ¯ä¸åˆ é™¤ï¼Œæ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°åˆ é™¤åˆ—è¡¨
            adjusted_message_ids.add(assistant_id)
            warnings.append(f"ä¸ºä¿æŒé…å¯¹å®Œæ•´æ€§ï¼ŒåŒæ—¶åˆ é™¤åŠ©æ‰‹æ¶ˆæ¯ {assistant_id}")
        elif assistant_to_delete and not user_to_delete:
            # åŠ©æ‰‹æ¶ˆæ¯è¦åˆ é™¤ä½†ç”¨æˆ·æ¶ˆæ¯ä¸åˆ é™¤ï¼Œæ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°åˆ é™¤åˆ—è¡¨
            adjusted_message_ids.add(user_id)
            warnings.append(f"ä¸ºä¿æŒé…å¯¹å®Œæ•´æ€§ï¼ŒåŒæ—¶åˆ é™¤ç”¨æˆ·æ¶ˆæ¯ {user_id}")
    
    return list(adjusted_message_ids), warnings
```

**æˆå¯¹è£å‰ªç¤ºä¾‹**ï¼š

```
åŸå§‹å¯¹è¯ï¼š
[
  {"role": "user", "message_id": "abcd1234", "content": "é—®é¢˜1"},
  {"role": "assistant", "message_id": "efgh5678", "content": "å›ç­”1"},
  {"role": "user", "message_id": "ijkl9012", "content": "é—®é¢˜2"},
  {"role": "assistant", "message_id": "mnop3456", "content": "å›ç­”2"},
]

è¦åˆ é™¤çš„æ¶ˆæ¯ID: ["abcd1234"]  # åªæŒ‡å®šåˆ é™¤ç”¨æˆ·æ¶ˆæ¯

é…å¯¹åˆ†æï¼š
- Pair 1: (abcd1234, efgh5678)
- Pair 2: (ijkl9012, mnop3456)

é…å¯¹è°ƒæ•´ï¼š
- abcd1234 è¦åˆ é™¤ â†’ è‡ªåŠ¨æ·»åŠ  efgh5678ï¼ˆä¿æŒé…å¯¹ï¼‰
- è°ƒæ•´å: ["abcd1234", "efgh5678"]

æœ€ç»ˆç»“æœï¼š
[
  {"role": "user", "message_id": "ijkl9012", "content": "é—®é¢˜2"},
  {"role": "assistant", "message_id": "mnop3456", "content": "å›ç­”2"},
]
```

### 4.2.5 ç®€å•è£å‰ªç®—æ³•ï¼ˆpreserve_pairs=Falseï¼‰

ç®€å•è£å‰ªç›´æ¥æŒ‰æ¶ˆæ¯IDåˆ é™¤ï¼Œä¸è€ƒè™‘é…å¯¹ï¼š

```python
def _prune_simple(
    self, 
    conversations: List[Dict[str, Any]], 
    message_ids_to_delete: List[str]
) -> MessageIdsPruningResult:
    """ç®€å•è£å‰ªç®—æ³• - ç›´æ¥æŒ‰æ¶ˆæ¯IDåˆ é™¤
    
    é€‚ç”¨åœºæ™¯ï¼š
    - ä¸å…³å¿ƒå¯¹è¯å®Œæ•´æ€§
    - éœ€è¦ç²¾ç¡®æ§åˆ¶åˆ é™¤å†…å®¹
    - åˆ é™¤çš„æ˜¯ç‹¬ç«‹æ¶ˆæ¯ï¼ˆå¦‚ç³»ç»Ÿæç¤ºã€å·¥å…·ç»“æœç­‰ï¼‰
    """
    try:
        pruned_conversations = self._remove_conversations_by_message_ids(
            conversations, message_ids_to_delete
        )
        
        return MessageIdsPruningResult(
            success=True,
            pruned_conversations=pruned_conversations,
            original_length=len(conversations),
            pruned_length=len(pruned_conversations),
            message_ids_applied=message_ids_to_delete,
            preserve_pairs=False
        )
        
    except Exception as e:
        return MessageIdsPruningResult(
            success=False,
            pruned_conversations=conversations,
            original_length=len(conversations),
            pruned_length=len(conversations),
            message_ids_applied=message_ids_to_delete,
            preserve_pairs=False,
            error_message=f"Simple pruning failed: {str(e)}"
        )

def _remove_conversations_by_message_ids(
    self, 
    conversations: List[Dict[str, Any]], 
    message_ids_to_delete: List[str]
) -> List[Dict[str, Any]]:
    """æ ¹æ®æ¶ˆæ¯IDåˆ é™¤ä¼šè¯
    
    Args:
        conversations: åŸå§‹ä¼šè¯åˆ—è¡¨
        message_ids_to_delete: è¦åˆ é™¤çš„æ¶ˆæ¯IDåˆ—è¡¨
    
    Returns:
        åˆ é™¤æŒ‡å®šæ¶ˆæ¯IDåå‰©ä½™çš„ä¼šè¯åˆ—è¡¨
    """
    if not message_ids_to_delete:
        return conversations
    
    remaining = []
    delete_ids = set(message_ids_to_delete)  # è½¬ä¸ºé›†åˆï¼ŒåŠ é€ŸæŸ¥æ‰¾
    
    # è¿‡æ»¤å‡ºæœªè¢«åˆ é™¤çš„æ¶ˆæ¯
    for conv in conversations:
        msg_id = self._extract_message_id(conv)
        if msg_id not in delete_ids:
            remaining.append(conv)
    
    return remaining
```


### 4.2.6 conversation_message_ids_write å·¥å…·

LLM é€šè¿‡ `conversation_message_ids_write` å·¥å…·ä¸»åŠ¨æ ‡è®°è¦åˆ é™¤çš„æ¶ˆæ¯ï¼š

```python
class ConversationMessageIdsWriteToolResolver(BaseToolResolver):
    """
    conversation_message_ids_write å·¥å…·è§£æå™¨
    
    æ”¯æŒä¸‰ç§æ“ä½œï¼š
    1. create: åˆ›å»ºæ–°çš„æ¶ˆæ¯IDé…ç½®ï¼ˆè¦†ç›–ç°æœ‰é…ç½®ï¼‰
    2. append: è¿½åŠ æ¶ˆæ¯IDåˆ°ç°æœ‰é…ç½®
    3. delete: ä»ç°æœ‰é…ç½®ä¸­åˆ é™¤æ¶ˆæ¯ID
    """
    
    def resolve(self) -> ToolResult:
        """æ‰§è¡Œæ¶ˆæ¯IDå†™å…¥æ“ä½œ"""
        try:
            # éªŒè¯actionå‚æ•°
            valid_actions = ["create", "append", "delete"]
            if self.tool.action not in valid_actions:
                return ToolResult(
                    success=False,
                    message=f"Invalid action: {self.tool.action}. Valid: {valid_actions}",
                    content={"error_type": "invalid_action"}
                )
            
            # è·å–å½“å‰ä¼šè¯ID
            conversation_id = self.agent.conversation_config.conversation_id
            if not conversation_id:
                return ToolResult(
                    success=False,
                    message="No active conversation",
                    content={"error_type": "no_conversation_id"}
                )
            
            # è·å–æ¶ˆæ¯ID API
            message_ids_api = get_conversation_message_ids_api(
                storage_dir=self.args.range_storage_dir if hasattr(self.args, 'range_storage_dir') else None
            )
            
            # æ ¹æ®actionç±»å‹å¤„ç†
            if self.tool.action == "create":
                return self._handle_create_action(message_ids_api, conversation_id)
            elif self.tool.action == "append":
                return self._handle_append_action(message_ids_api, conversation_id)
            elif self.tool.action == "delete":
                return self._handle_delete_action(message_ids_api, conversation_id)
                
        except Exception as e:
            logger.error(f"conversation_message_ids_write failed: {str(e)}")
            return ToolResult(
                success=False,
                message=f"Operation failed: {str(e)}",
                content={"error_type": "exception", "error_message": str(e)}
            )
```

**createæ“ä½œå®ç°**ï¼š

```python
def _handle_create_action(self, message_ids_api, conversation_id: str) -> ToolResult:
    """åˆ›å»ºæ–°çš„æ¶ˆæ¯IDé…ç½®ï¼ˆè¦†ç›–ç°æœ‰é…ç½®ï¼‰"""
    # ä¿å­˜æ¶ˆæ¯IDé…ç½®ï¼Œé»˜è®¤ preserve_pairs=True
    success, error_msg, message_ids_obj = message_ids_api.save_conversation_message_ids(
        conversation_id=conversation_id,
        message_ids=self.tool.message_ids,  # é€—å·åˆ†éš”çš„æ¶ˆæ¯IDå­—ç¬¦ä¸²
        description="Created via conversation_message_ids_write tool",
        preserve_pairs=True  # é»˜è®¤å¯ç”¨æˆå¯¹è£å‰ª
    )
    
    if success and message_ids_obj:
        stats = message_ids_api.get_message_ids_statistics(conversation_id)
        
        return ToolResult(
            success=True,
            message="Message IDs configuration created successfully",
            content={
                "action": "create",
                "conversation_id": conversation_id,
                "message_ids": message_ids_obj.message_ids,  # List[str]
                "description": message_ids_obj.description,
                "preserve_pairs": message_ids_obj.preserve_pairs,
                "statistics": stats,  # ç»Ÿè®¡ä¿¡æ¯
                "created_at": message_ids_obj.created_at,
                "updated_at": message_ids_obj.updated_at,
                "message": f"Successfully created configuration with {len(message_ids_obj.message_ids)} message IDs."
            }
        )
    else:
        return ToolResult(
            success=False,
            message=f"Failed to create configuration: {error_msg}",
            content={"error_type": "create_failed", "error_message": error_msg}
        )
```

**appendæ“ä½œå®ç°**ï¼š

```python
def _handle_append_action(self, message_ids_api: ConversationMessageIdsAPI, conversation_id: str) -> ToolResult:
    """è¿½åŠ æ¶ˆæ¯IDåˆ°ç°æœ‰é…ç½®"""
    # è·å–ç°æœ‰é…ç½®
    existing_config = message_ids_api.get_conversation_message_ids(conversation_id)
    
    if existing_config:
        # åˆå¹¶æ¶ˆæ¯IDï¼ˆå»é‡ï¼‰
        existing_ids = set(existing_config.message_ids)
        new_ids = set([id.strip() for id in self.tool.message_ids.split(",") if id.strip()])
        combined_ids = existing_ids.union(new_ids)
        combined_ids_str = ",".join(sorted(combined_ids))
        
        # ä¿å­˜æ›´æ–°åçš„é…ç½®
        success, error_msg, message_ids_obj = message_ids_api.save_conversation_message_ids(
            conversation_id=conversation_id,
            message_ids=combined_ids_str,
            description=existing_config.description + " | Appended via tool",
            preserve_pairs=existing_config.preserve_pairs
        )
    else:
        # æ— ç°æœ‰é…ç½®ï¼Œåˆ›å»ºæ–°é…ç½®
        success, error_msg, message_ids_obj = message_ids_api.save_conversation_message_ids(
            conversation_id=conversation_id,
            message_ids=self.tool.message_ids,
            description="Created via conversation_message_ids_write tool (append)",
            preserve_pairs=True
        )
    
    if success and message_ids_obj:
        return ToolResult(
            success=True,
            message="Message IDs appended successfully",
            content={
                "action": "append",
                "message_ids": message_ids_obj.message_ids,
                "message": f"Successfully appended. Total: {len(message_ids_obj.message_ids)} message IDs."
            }
        )
    else:
        return ToolResult(
            success=False,
            message=f"Failed to append: {error_msg}",
            content={"error_type": "append_failed"}
        )
```

### 4.2.7 LLM å¦‚ä½•ä½¿ç”¨è¯¥å·¥å…·

**å·¥å…·æè¿°ï¼ˆæç¤ºè¯ï¼‰**ï¼š

```xml
<tool>
  <name>conversation_message_ids_write</name>
  <description>
    Save message IDs to be deleted in the next conversation pruning.
    
    This tool allows you to mark specific messages for deletion when the conversation 
    context becomes too long. Messages are identified by their 8-character message IDs 
    which appear in the format [[message_id: xxxxxxxx]] at the start of each message.
    
    Use this tool when:
    - The conversation is getting too long
    - You want to remove outdated or no-longer-relevant messages
    - The system prompts you that context is near the limit
    
    The system will automatically maintain conversation pair integrity (user-assistant pairs)
    to ensure the conversation remains coherent.
  </description>
  <parameters>
    <parameter>
      <name>message_ids</name>
      <type>string</type>
      <required>true</required>
      <description>
        Comma-separated list of 8-character message IDs to delete.
        Example: "abcd1234,efgh5678,ijkl9012"
      </description>
    </parameter>
    <parameter>
      <name>action</name>
      <type>string</type>
      <required>false</required>
      <description>
        Action to perform: "create" (default), "append", or "delete".
        - create: Replace existing configuration with new message IDs
        - append: Add message IDs to existing configuration
        - delete: Remove message IDs from existing configuration
      </description>
    </parameter>
  </parameters>
  <examples>
    <example>
      <description>Mark early conversation messages for deletion</description>
      <code>
<conversation_message_ids_write>
  <message_ids>abcd1234,efgh5678,ijkl9012</message_ids>
  <action>create</action>
</conversation_message_ids_write>
      </code>
    </example>
  </examples>
</tool>
```

**LLM ä½¿ç”¨åœºæ™¯ç¤ºä¾‹**ï¼š

**åœºæ™¯1ï¼šä¸Šä¸‹æ–‡æ¥è¿‘é™åˆ¶**

```
ç³»ç»Ÿæç¤ºï¼ˆè‡ªåŠ¨æ³¨å…¥ï¼‰ï¼š
"The conversation is still too long, please use conversation_message_ids_write tool 
to save the message ids to be deleted."

LLM å“åº”ï¼š
æˆ‘æ³¨æ„åˆ°å¯¹è¯å·²ç»å¾ˆé•¿äº†ã€‚è®©æˆ‘åˆ†æä¸€ä¸‹å“ªäº›æ¶ˆæ¯å¯ä»¥åˆ é™¤ï¼š

- æ¶ˆæ¯ 12a4f8d3: æ—©æœŸçš„é—®å€™å’Œè®¾ç½®ç›¸å…³çš„è®¨è®ºï¼Œå·²ç»ä¸å†ç›¸å…³
- æ¶ˆæ¯ 98b2c1e4: å…³äºæ—§åŠŸèƒ½çš„è®¨è®ºï¼Œè¯¥åŠŸèƒ½å·²è¢«é‡æ„
- æ¶ˆæ¯ 56d7e9f2: ä¸­é—´è°ƒè¯•è¿‡ç¨‹çš„å†—é•¿è¾“å‡ºï¼Œå·²è§£å†³

æˆ‘å°†æ ‡è®°è¿™äº›æ¶ˆæ¯ä¾›åˆ é™¤ï¼š

<conversation_message_ids_write>
  <message_ids>12a4f8d3,98b2c1e4,56d7e9f2</message_ids>
  <action>create</action>
</conversation_message_ids_write>
```

**åœºæ™¯2ï¼šä¸»åŠ¨ä¼˜åŒ–ä¸Šä¸‹æ–‡**

```
ç”¨æˆ·ï¼š
"å¯¹è¯å¤ªé•¿äº†ï¼Œè¯·æ¸…ç†ä¸€ä¸‹æ—©æœŸçš„æ¶ˆæ¯"

LLM å“åº”ï¼š
å¥½çš„ï¼Œæˆ‘æ¥æ¸…ç†æ—©æœŸä¸å†éœ€è¦çš„æ¶ˆæ¯ã€‚è®©æˆ‘æ£€æŸ¥å½“å‰å¯¹è¯å†å²...

æˆ‘å»ºè®®åˆ é™¤ä»¥ä¸‹æ¶ˆæ¯ï¼š
1. [[message_id: a1b2c3d4]] - åˆå§‹é—®é¢˜è®¨è®ºï¼ˆå·²è§£å†³ï¼‰
2. [[message_id: e5f6g7h8]] - ä¸­é—´å°è¯•çš„é”™è¯¯æ–¹æ¡ˆï¼ˆå·²æ”¾å¼ƒï¼‰
3. [[message_id: i9j0k1l2]] - è°ƒè¯•ä¿¡æ¯è¾“å‡ºï¼ˆå·²ä¸éœ€è¦ï¼‰

<conversation_message_ids_write>
  <message_ids>a1b2c3d4,e5f6g7h8,i9j0k1l2</message_ids>
  <action>create</action>
</conversation_message_ids_write>

è¿™äº›æ¶ˆæ¯å°†åœ¨ä¸‹ä¸€æ¬¡ä¸Šä¸‹æ–‡å‰ªè£æ—¶è¢«åˆ é™¤ã€‚
```

### 4.2.8 ConversationMessageIds æ•°æ®æ¨¡å‹

æ¶ˆæ¯IDé…ç½®çš„æ•°æ®æ¨¡å‹ï¼š

```python
@dataclass
class ConversationMessageIds:
    """ä¼šè¯æ¶ˆæ¯IDæ•°æ®æ¨¡å‹
    
    å­˜å‚¨åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­ï¼š
    .auto-coder/pruner/conversations/conversation_message_ids.json
    """
    conversation_id: str          # ä¼šè¯IDï¼ˆæ¥è‡ª ConversationManagerï¼‰
    message_ids: List[str]        # è¦åˆ é™¤çš„æ¶ˆæ¯IDåˆ—è¡¨ï¼ˆ8ä½ï¼‰
    created_at: str              # åˆ›å»ºæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
    updated_at: str              # æ›´æ–°æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
    description: str = ""        # æè¿°ä¿¡æ¯
    preserve_pairs: bool = True  # æ˜¯å¦ä¿è¯user/assistantæˆå¯¹è£å‰ª
    
    def remove_duplicate_ids(self) -> None:
        """ç§»é™¤é‡å¤çš„æ¶ˆæ¯IDï¼Œä¿æŒé¡ºåº"""
        seen = set()
        unique_ids = []
        for msg_id in self.message_ids:
            if msg_id not in seen:
                seen.add(msg_id)
                unique_ids.append(msg_id)
        self.message_ids = unique_ids
    
    def validate_message_ids(self, conversation_message_ids: List[str]) -> tuple[bool, str]:
        """éªŒè¯æ¶ˆæ¯IDæœ‰æ•ˆæ€§
        
        æ£€æŸ¥é¡¹ï¼š
        1. åˆ—è¡¨éç©º
        2. æ‰€æœ‰IDéƒ½æ˜¯å­—ç¬¦ä¸²
        3. æ‰€æœ‰IDé•¿åº¦éƒ½æ˜¯8
        4. æ‰€æœ‰IDéƒ½å­˜åœ¨äºå¯¹è¯ä¸­
        """
        if not self.message_ids:
            return False, "æ¶ˆæ¯IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º"
        
        # åˆ›å»ºæœ‰æ•ˆIDé›†åˆï¼ˆå–å‰8ä¸ªå­—ç¬¦ï¼‰
        valid_ids = {msg_id[:8] for msg_id in conversation_message_ids}
        
        # æ£€æŸ¥æ¯ä¸ªè¦åˆ é™¤çš„ID
        for i, msg_id in enumerate(self.message_ids):
            if not isinstance(msg_id, str):
                return False, f"æ¶ˆæ¯ID {i+1}: IDå¿…é¡»æ˜¯å­—ç¬¦ä¸²"
            
            if len(msg_id) != 8:
                return False, f"æ¶ˆæ¯ID {i+1}: IDé•¿åº¦å¿…é¡»æ˜¯8ä¸ªå­—ç¬¦"
            
            if msg_id not in valid_ids:
                return False, f"æ¶ˆæ¯ID {i+1}: '{msg_id}' åœ¨å¯¹è¯ä¸­ä¸å­˜åœ¨"
        
        return True, ""
```

**å­˜å‚¨æ ¼å¼ç¤ºä¾‹**ï¼š

```json
{
  "version": "1.0",
  "last_updated": "2025-01-15T10:30:00",
  "message_configs": [
    {
      "conversation_id": "conv_abc123",
      "message_ids": ["12a4f8d3", "98b2c1e4", "56d7e9f2"],
      "created_at": "2025-01-15T10:20:00",
      "updated_at": "2025-01-15T10:30:00",
      "description": "Created via conversation_message_ids_write tool",
      "preserve_pairs": true
    },
    {
      "conversation_id": "conv_def456",
      "message_ids": ["a1b2c3d4"],
      "created_at": "2025-01-15T09:00:00",
      "updated_at": "2025-01-15T09:00:00",
      "description": "Manual cleanup",
      "preserve_pairs": false
    }
  ]
}
```

### 4.2.9 Message IDs Pruning æ€»ç»“

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š

1. **LLMä¸»å¯¼å†³ç­–**ï¼šLLM ç†è§£ä¸Šä¸‹æ–‡ï¼ŒçŸ¥é“å“ªäº›æ¶ˆæ¯å¯ä»¥å®‰å…¨åˆ é™¤
2. **ç²¾ç¡®æ§åˆ¶**ï¼šåŸºäºæ¶ˆæ¯IDï¼Œä¸ä¼šè¯¯åˆ é‡è¦ä¿¡æ¯
3. **é…å¯¹ä¿æŠ¤**ï¼šè‡ªåŠ¨ç»´æŠ¤ user/assistant å¯¹è¯å®Œæ•´æ€§
4. **æŒä¹…åŒ–é…ç½®**ï¼šé…ç½®ä¿å­˜åœ¨æ–‡ä»¶ç³»ç»Ÿï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
5. **çµæ´»æ“ä½œ**ï¼šæ”¯æŒ create/append/delete ä¸‰ç§æ“ä½œ

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… é•¿æ—¶é—´äº¤äº’ï¼Œæ—©æœŸæ¶ˆæ¯å·²ä¸ç›¸å…³
- âœ… è°ƒè¯•è¿‡ç¨‹ä¸­äº§ç”Ÿå¤§é‡ä¸­é—´æ¶ˆæ¯
- âœ… éœ€è¦ä¿ç•™å…³é”®å†³ç­–ä½†åˆ é™¤ä¸­é—´è¿‡ç¨‹
- âœ… ç²¾ç¡®æ§åˆ¶å“ªäº›æ¶ˆæ¯ä¿ç•™å“ªäº›åˆ é™¤

**å±€é™æ€§**ï¼š

- âŒ éœ€è¦ LLM ä¸»åŠ¨ä½¿ç”¨å·¥å…·ï¼ˆä¾èµ–æç¤ºè¯å¼•å¯¼ï¼‰
- âŒ åªèƒ½åˆ é™¤å·²æ ‡è®°çš„æ¶ˆæ¯ï¼ˆä¸èƒ½è‡ªåŠ¨è¯†åˆ«å¯åˆ é™¤å†…å®¹ï¼‰
- âŒ å¦‚æœ LLM åˆ¤æ–­é”™è¯¯ï¼Œå¯èƒ½åˆ é™¤é‡è¦ä¿¡æ¯ï¼ˆéœ€è¦è‰¯å¥½çš„æç¤ºè¯è®¾è®¡ï¼‰


## 4.3 Tool Cleanup Pruningï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰

### 4.3.1 è®¾è®¡ç†å¿µ

Tool Cleanup Pruning æ˜¯ä¸€ç§**è‡ªåŠ¨è¯†åˆ«å’Œå‹ç¼©å·¥å…·å†…å®¹**çš„ç­–ç•¥ï¼Œä¸éœ€è¦ LLM ä¸»åŠ¨å‚ä¸ã€‚ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«ä»¥ä¸‹ä¸¤ç±»å¯å‹ç¼©å†…å®¹ï¼š

1. **å·¥å…·ç»“æœæ¶ˆæ¯**ï¼ˆTool Resultï¼‰ï¼šrole='user'ï¼ŒåŒ…å« `<tool_result>` æ ‡ç­¾
2. **å·¥å…·è°ƒç”¨å†…å®¹**ï¼ˆTool Callï¼‰ï¼šrole='assistant'ï¼ŒåŒ…å«å¤§å†…å®¹å­—æ®µçš„å·¥å…·è°ƒç”¨

**å‹ç¼©åŸç†**ï¼š
- å·¥å…·ç»“æœå’Œè°ƒç”¨çš„å¤§å†…å®¹å­—æ®µï¼ˆå¦‚æ–‡ä»¶å†…å®¹ã€diffå†…å®¹ï¼‰å¯¹ LLM çš„ä»·å€¼ä¼šéšæ—¶é—´è¡°å‡
- æ—©æœŸçš„å·¥å…·è¾“å‡ºé€šå¸¸å·²ç»è¢«åç»­æ“ä½œè¦†ç›–æˆ–ä¸å†éœ€è¦
- ä¿ç•™å·¥å…·è°ƒç”¨çš„"éª¨æ¶"ï¼ˆå·¥å…·åã€å‚æ•°åï¼‰ï¼Œåˆ é™¤å¤§å†…å®¹å­—æ®µ

### 4.3.2 ToolContentDetector å·¥å…·å†…å®¹æ£€æµ‹å™¨

è¿™æ˜¯è¯†åˆ«å¯å‹ç¼©å·¥å…·å†…å®¹çš„æ ¸å¿ƒç±»ï¼š

```python
class ToolContentDetector:
    """
    å·¥å…·å†…å®¹æ£€æµ‹å™¨ï¼Œç”¨äºè¯†åˆ«å’Œå¤„ç†å·¥å…·è°ƒç”¨å†…å®¹
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. æ£€æµ‹ content æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ï¼ˆwrite_to_file, replace_in_fileç­‰ï¼‰
    2. æ›¿æ¢å·¥å…·è°ƒç”¨ä¸­çš„å¤§å†…å®¹éƒ¨åˆ†ï¼Œå‡å°‘tokenä½¿ç”¨
    """
    
    def __init__(self, replacement_message: str = "Content cleared to save tokens"):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        self.replacement_message = replacement_message
        
        # æ”¯æŒçš„å·¥å…·åˆ—è¡¨ï¼ˆå¯æ‰©å±•ï¼‰
        self.supported_tools = [
            'write_to_file',      # å†™æ–‡ä»¶å·¥å…·
            'replace_in_file'     # æ–‡ä»¶æ›¿æ¢å·¥å…·
        ]
        
        # ä¸ºæ¯ä¸ªå·¥å…·å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.tool_patterns = {
            'write_to_file': {
                'start': r'<write_to_file>',
                'end': r'</write_to_file>',
                'content_pattern': r'<content>(.*?)</content>',  # åŒ¹é…<content>å­—æ®µ
                'content_start': r'<content>',
                'content_end': r'</content>'
            },
            'replace_in_file': {
                'start': r'<replace_in_file>',
                'end': r'</replace_in_file>',
                'content_pattern': r'<diff>(.*?)</diff>',  # åŒ¹é…<diff>å­—æ®µ
                'content_start': r'<diff>',
                'content_end': r'</diff>'
            }
        }
```

**å·¥å…·è°ƒç”¨æ£€æµ‹æ–¹æ³•**ï¼š

```python
def detect_tool_call(self, content: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    æ£€æµ‹ content æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
    
    Returns:
        å·¥å…·ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆ™è¿”å› None
        {
            'tool_name': str,           # å·¥å…·åç§°
            'start_pos': int,           # å·¥å…·è°ƒç”¨å¼€å§‹ä½ç½®
            'end_pos': int,             # å·¥å…·è°ƒç”¨ç»“æŸä½ç½®
            'full_match': str,          # å®Œæ•´çš„å·¥å…·è°ƒç”¨XML
            'content_start': int,       # å†…å®¹å­—æ®µå¼€å§‹ä½ç½®
            'content_end': int,         # å†…å®¹å­—æ®µç»“æŸä½ç½®
            'content_match': str,       # å®Œæ•´çš„å†…å®¹å­—æ®µï¼ˆå«æ ‡ç­¾ï¼‰
            'content_inner': str        # å†…å®¹å­—æ®µçš„å€¼ï¼ˆä¸å«æ ‡ç­¾ï¼‰
        }
    """
    if not content:
        return None
    
    for tool_name in self.supported_tools:
        pattern_info = self.tool_patterns[tool_name]
        
        # æ­¥éª¤1: æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨çš„å¼€å§‹å’Œç»“æŸæ ‡ç­¾
        start_pattern = pattern_info['start']
        end_pattern = pattern_info['end']
        
        start_match = re.search(start_pattern, content, re.IGNORECASE)
        if not start_match:
            continue
        
        # æ­¥éª¤2: ä»startä½ç½®å¼€å§‹æŸ¥æ‰¾ç»“æŸæ ‡ç­¾
        start_pos = start_match.start()
        remaining_content = content[start_pos:]
        
        end_match = re.search(end_pattern, remaining_content, re.IGNORECASE)
        if not end_match:
            continue
        
        end_pos = start_pos + end_match.end()
        full_tool_match = content[start_pos:end_pos]
        
        # æ­¥éª¤3: åœ¨å·¥å…·è°ƒç”¨ä¸­æŸ¥æ‰¾ content/diff éƒ¨åˆ†
        content_pattern = pattern_info['content_pattern']
        content_match = re.search(content_pattern, full_tool_match, re.DOTALL | re.IGNORECASE)
        
        if content_match:
            # æ‰¾åˆ°å®Œæ•´çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
            return {
                'tool_name': tool_name,
                'start_pos': start_pos,
                'end_pos': end_pos,
                'full_match': full_tool_match,
                'content_start': start_pos + content_match.start(),
                'content_end': start_pos + content_match.end(),
                'content_match': content_match.group(0),  # <content>...</content>
                'content_inner': content_match.group(1)   # ...ï¼ˆå†…å®¹æœ¬èº«ï¼‰
            }
    
    return None
```

**æ£€æµ‹ç¤ºä¾‹**ï¼š

```python
# è¾“å…¥ï¼šåŒ…å«å·¥å…·è°ƒç”¨çš„ assistant æ¶ˆæ¯
content = """
I'll write the content to the file.

<write_to_file>
  <file_path>/path/to/file.py</file_path>
  <content>
def hello():
    print("Hello, World!")
    # ... 1000 lines of code ...
  </content>
</write_to_file>

The file has been created.
"""

# æ£€æµ‹ç»“æœ
tool_info = detector.detect_tool_call(content)
# {
#     'tool_name': 'write_to_file',
#     'start_pos': 35,
#     'end_pos': 250,
#     'full_match': '<write_to_file>...</write_to_file>',
#     'content_start': 80,
#     'content_end': 220,
#     'content_match': '<content>def hello():...</content>',
#     'content_inner': 'def hello():...'  # 1000è¡Œä»£ç 
# }
```

### 4.3.3 å†…å®¹æ›¿æ¢æ–¹æ³•

æ£€æµ‹åˆ°å¯å‹ç¼©å†…å®¹åï¼Œæ‰§è¡Œæ›¿æ¢ï¼š

```python
def replace_tool_content(self, content: Optional[str], max_content_length: int = 500) -> Tuple[str, bool]:
    """
    æ›¿æ¢å·¥å…·è°ƒç”¨ä¸­çš„å¤§å†…å®¹å­—æ®µ
    
    Args:
        content: åŸå§‹å†…å®¹
        max_content_length: å†…å®¹è¶…è¿‡è¿™ä¸ªé•¿åº¦æ—¶æ‰è¿›è¡Œæ›¿æ¢
    
    Returns:
        (æ›¿æ¢åçš„å†…å®¹, æ˜¯å¦è¿›è¡Œäº†æ›¿æ¢)
    """
    if not content:
        return content or "", False
    
    # æ£€æµ‹å·¥å…·è°ƒç”¨
    tool_info = self.detect_tool_call(content)
    if not tool_info:
        return content, False
    
    # æ£€æŸ¥å†…å®¹é•¿åº¦æ˜¯å¦è¶…è¿‡é˜ˆå€¼
    content_inner = tool_info['content_inner']
    if len(content_inner) <= max_content_length:
        return content, False  # å†…å®¹ä¸é•¿ï¼Œæ— éœ€æ›¿æ¢
    
    # æ„é€ æ›¿æ¢åçš„å†…å®¹
    tool_name = tool_info['tool_name']
    pattern_info = self.tool_patterns[tool_name]
    
    # ç”Ÿæˆæ›¿æ¢çš„å†…å®¹æ ‡ç­¾
    if tool_name == 'write_to_file':
        replacement_content = f"<content>{self.replacement_message}</content>"
    elif tool_name == 'replace_in_file':
        replacement_content = f"<diff>{self.replacement_message}</diff>"
    else:
        replacement_content = f"<content>{self.replacement_message}</content>"
    
    # æ‰§è¡Œæ›¿æ¢ï¼šä¿ç•™å·¥å…·è°ƒç”¨éª¨æ¶ï¼Œåªæ›¿æ¢å¤§å†…å®¹å­—æ®µ
    new_content = (
        content[:tool_info['start_pos']] +                    # å‰ç¼€ï¼ˆå·¥å…·è°ƒç”¨ä¹‹å‰ï¼‰
        content[tool_info['start_pos']:tool_info['content_start']] +  # å·¥å…·è°ƒç”¨å¤´éƒ¨
        replacement_content +                                  # æ›¿æ¢çš„å†…å®¹
        content[tool_info['content_end']:tool_info['end_pos']] +     # å·¥å…·è°ƒç”¨å°¾éƒ¨
        content[tool_info['end_pos']:]                        # åç¼€ï¼ˆå·¥å…·è°ƒç”¨ä¹‹åï¼‰
    )
    
    logger.info(f"Replaced {tool_name} content: {len(content_inner)} chars -> {len(self.replacement_message)} chars")
    
    return new_content, True
```

**æ›¿æ¢æ•ˆæœç¤ºä¾‹**ï¼š

```python
# åŸå§‹å†…å®¹ï¼ˆ5000å­—ç¬¦ï¼‰
original = """
<write_to_file>
  <file_path>/path/to/file.py</file_path>
  <content>
def function1():
    # ... 1000 lines ...
def function2():
    # ... 1000 lines ...
# ... more code ...
  </content>
</write_to_file>
"""

# æ›¿æ¢åï¼ˆ200å­—ç¬¦ï¼‰
replaced = """
<write_to_file>
  <file_path>/path/to/file.py</file_path>
  <content>Content cleared to save tokens</content>
</write_to_file>
"""

# TokenèŠ‚çœï¼š5000 -> 200 (èŠ‚çœ96%)
```

### 4.3.4 ç»Ÿä¸€å·¥å…·æ¸…ç†æ–¹æ³•

`_unified_tool_cleanup_prune` æ˜¯ä¸»æ¸…ç†æ–¹æ³•ï¼Œç»Ÿä¸€å¤„ç†å·¥å…·ç»“æœå’Œå·¥å…·è°ƒç”¨ï¼š

```python
def _unified_tool_cleanup_prune(self, conversations: List[Dict[str, Any]],
                                config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ç»Ÿä¸€æ¸…ç†å·¥å…·ç»“æœå’Œå·¥å…·è°ƒç”¨å†…å®¹
    
    ç®—æ³•æ­¥éª¤ï¼š
    1. è¯†åˆ«æ‰€æœ‰å¯æ¸…ç†çš„æ¶ˆæ¯ï¼ˆå·¥å…·ç»“æœ + å·¥å…·è°ƒç”¨ï¼‰
    2. æŒ‰ç´¢å¼•æ’åºï¼Œä¼˜å…ˆå¤„ç†å·¥å…·ç»“æœ
    3. é€ä¸ªæ¸…ç†ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶
    
    åœæ­¢æ¡ä»¶ï¼š
    - Tokenæ•°å·²åœ¨å®‰å…¨åŒºå†…
    - æˆ–å‰©ä½™æœªæ¸…ç†æ¶ˆæ¯å°‘äº6æ¡
    """
    safe_zone_tokens = config.get("safe_zone_tokens", 80 * 1024)
    processed_conversations = copy.deepcopy(conversations)  # æ·±æ‹·è´ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®
    
    current_tokens = count_string_tokens(json.dumps(
        processed_conversations, ensure_ascii=False))
    
    # æ­¥éª¤1: æŸ¥æ‰¾æ‰€æœ‰å¯æ¸…ç†çš„æ¶ˆæ¯
    cleanable_messages = []
    
    for i, conv in enumerate(processed_conversations):
        content = conv.get("content", "")
        role = conv.get("role")
        
        if isinstance(content, str):
            # æ£€æŸ¥å·¥å…·ç»“æœæ¶ˆæ¯ï¼ˆuser roleï¼‰
            if (role == "user" and self._is_tool_result_message(content)):
                cleanable_messages.append(
                    {"index": i, "type": "tool_result"})
            # æ£€æŸ¥å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆassistant roleï¼‰
            elif (role == "assistant" and self.tool_content_detector.is_tool_call_content(content)):
                cleanable_messages.append(
                    {"index": i, "type": "tool_call"})
    
    # æ­¥éª¤2: æ’åºï¼Œä¼˜å…ˆå¤„ç†å·¥å…·ç»“æœ
    # æŒ‰ç´¢å¼•æ’åºï¼Œä½† tool_result ä¼˜å…ˆäº tool_call
    cleanable_messages.sort(key=lambda x: (
        x["index"], x["type"] != "tool_result"))
    
    logger.info(f"Found {len([m for m in cleanable_messages if m['type'] == 'tool_result'])} tool result messages "
                f"and {len([m for m in cleanable_messages if m['type'] == 'tool_call'])} tool call messages to potentially clean")
    
    # æ­¥éª¤3: é€ä¸ªæ¸…ç†æ¶ˆæ¯
    cleaned_count = 0
    
    for i, message_info in enumerate(cleanable_messages):
        # æ›´æ–°å½“å‰ token æ•°é‡
        current_tokens = count_string_tokens(json.dumps(
            processed_conversations, ensure_ascii=False))
        
        # æ£€æŸ¥åœæ­¢æ¡ä»¶1: Tokenæ•°å·²åœ¨å®‰å…¨åŒºå†…
        if current_tokens <= safe_zone_tokens:
            logger.info(
                f"Token count ({current_tokens}) is within safe zone ({safe_zone_tokens}), stopping cleanup")
            break
        
        # æ£€æŸ¥åœæ­¢æ¡ä»¶2: å‰©ä½™æœªæ¸…ç†çš„æ¶ˆæ¯å°‘äº6æ¡
        remaining_unpruned = len(cleanable_messages) - (i + 1)
        if remaining_unpruned < 6:
            logger.info(
                f"Less than 6 unpruned messages remaining ({remaining_unpruned}), stopping cleanup")
            break
        
        msg_index = message_info["index"]
        msg_type = message_info["type"]
        original_content = processed_conversations[msg_index]["content"]
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹æ‰§è¡Œæ¸…ç†
        if msg_type == "tool_result":
            # å¤„ç†å·¥å…·ç»“æœ
            tool_name = self._extract_tool_name(original_content)
            replacement_content = self._generate_replacement_message(tool_name)
            processed_conversations[msg_index]["content"] = replacement_content
            cleaned_count += 1
            
            logger.info(f"Cleaned tool result at index {msg_index} (tool: {tool_name}), "
                        f"reduced from {len(original_content)} to {len(replacement_content)} characters")
        
        elif msg_type == "tool_call":
            # å¤„ç†å·¥å…·è°ƒç”¨å†…å®¹
            tool_info = self.tool_content_detector.detect_tool_call(original_content)
            
            if tool_info:
                new_content, replaced = self.tool_content_detector.replace_tool_content(
                    original_content, max_content_length=500
                )
                
                if replaced:
                    processed_conversations[msg_index]["content"] = new_content
                    cleaned_count += 1
                    logger.info(f"Cleaned tool call content at index {msg_index} (tool: {tool_info['tool_name']}), "
                                f"reduced from {len(original_content)} to {len(new_content)} characters")
    
    # è®°å½•æ¸…ç†ç»“æœ
    final_tokens = count_string_tokens(json.dumps(
        processed_conversations, ensure_ascii=False))
    initial_tokens = count_string_tokens(
        json.dumps(conversations, ensure_ascii=False))
    logger.info(
        f"Unified tool cleanup completed. Cleaned {cleaned_count} messages. Token count: {initial_tokens} -> {final_tokens}")
    
    return processed_conversations
```

### 4.3.5 æ¸…ç†ç­–ç•¥è¯¦è§£

**ä¼˜å…ˆçº§è®¾è®¡**ï¼š

```
æ¸…ç†ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
1. å·¥å…·ç»“æœæ¶ˆæ¯ï¼ˆtool_resultï¼‰
   - é€šå¸¸åŒ…å«å¤§é‡è¾“å‡ºå†…å®¹
   - å¯¹åç»­å¯¹è¯ä»·å€¼è¾ƒä½
   
2. å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆtool_callï¼‰
   - åŒ…å«å¤§å†…å®¹å­—æ®µçš„å·¥å…·è°ƒç”¨
   - ä¿ç•™è°ƒç”¨éª¨æ¶ï¼Œåˆ é™¤å¤§å†…å®¹
```

**ä¿æŠ¤æœºåˆ¶**ï¼š

```python
# ä¿æŠ¤æœºåˆ¶1: ä¿ç•™æœ€å°æ¶ˆæ¯æ•°
remaining_unpruned = len(cleanable_messages) - (i + 1)
if remaining_unpruned < 6:
    break  # è‡³å°‘ä¿ç•™6æ¡æœªæ¸…ç†çš„æ¶ˆæ¯

# ä¿æŠ¤æœºåˆ¶2: Tokenæ•°æ£€æŸ¥
if current_tokens <= safe_zone_tokens:
    break  # å·²è¾¾åˆ°ç›®æ ‡ï¼Œåœæ­¢æ¸…ç†
```

**ä¸ºä»€ä¹ˆä¿ç•™6æ¡ï¼Ÿ**
- ä¿è¯å¯¹è¯çš„åŸºæœ¬è¿è´¯æ€§
- é¿å…è¿‡åº¦æ¸…ç†å¯¼è‡´ä¸Šä¸‹æ–‡ä¸è¶³
- ç»éªŒå€¼ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´


### 4.3.6 å·¥å…·ç»“æœæ¶ˆæ¯å¤„ç†

å·¥å…·ç»“æœæ¶ˆæ¯çš„è¯†åˆ«å’Œæ¸…ç†ï¼š

```python
def _is_tool_result_message(self, content: str) -> bool:
    """
    æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦ä¸ºå·¥å…·ç»“æœ
    
    å·¥å…·ç»“æœæ ¼å¼ï¼š
    <tool_result tool_name='xxx' success='true'>
      <message>...</message>
      <content>...</content>
    </tool_result>
    """
    if content is None:
        return False
    return "<tool_result" in content and "tool_name=" in content

def _extract_tool_name(self, content: str) -> str:
    """
    ä»å·¥å…·ç»“æœ XML ä¸­æå–å·¥å…·åç§°
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - <tool_result tool_name='read_file' ...>
    - <tool_result tool_name="read_file" ...>
    """
    # æ­£åˆ™æ¨¡å¼ï¼šåŒ¹é…å•å¼•å·æˆ–åŒå¼•å·
    pattern = r"<tool_result[^>]*tool_name=['\"]([^'\"]*)['\"]"
    match = re.search(pattern, content)
    
    if match:
        return match.group(1)
    return "unknown"

def _generate_replacement_message(self, tool_name: str) -> str:
    """
    ç”Ÿæˆå·¥å…·ç»“æœçš„æ›¿æ¢æ¶ˆæ¯
    
    ä¿ç•™å·¥å…·ç»“æœçš„åŸºæœ¬ç»“æ„ï¼Œä½†æ›¿æ¢å¤§å†…å®¹å­—æ®µ
    """
    if tool_name and tool_name != "unknown":
        return (f"<tool_result tool_name='{tool_name}' success='true'>"
                f"<message>Content cleared to save tokens</message>"
                f"<content>{self.replacement_message}</content>"
                f"</tool_result>")
    else:
        return (f"<tool_result success='true'>"
                f"<message>[Content cleared to save tokens, you can call the tool again to get the tool result.]</message>"
                f"<content>{self.replacement_message}</content>"
                f"</tool_result>")
```

**å·¥å…·ç»“æœæ¸…ç†ç¤ºä¾‹**ï¼š

```python
# åŸå§‹å·¥å…·ç»“æœï¼ˆ10KBï¼‰
original = """
<tool_result tool_name='read_file' success='true'>
  <message>File read successfully</message>
  <content>
# Large file content (10,000 lines)
import sys
import os
# ... 10,000 lines of code ...
  </content>
</tool_result>
"""

# æ¸…ç†åï¼ˆ200 bytesï¼‰
cleaned = """
<tool_result tool_name='read_file' success='true'>
  <message>Content cleared to save tokens</message>
  <content>This message has been cleared. If you still want to get this information, you can call the tool again to retrieve it.</content>
</tool_result>
"""

# Token èŠ‚çœï¼š~3000 tokens -> ~50 tokens (èŠ‚çœ98%+)
```

### 4.3.7 å®Œæ•´æ¸…ç†æµç¨‹ç¤ºä¾‹

**åœºæ™¯ï¼šå¯¹è¯åŒ…å«å¤šä¸ªå·¥å…·è°ƒç”¨å’Œç»“æœ**

```python
conversations = [
    {"role": "system", "content": "You are an AI assistant..."},
    {"role": "user", "content": "Read the file main.py"},
    {"role": "assistant", "content": "<read_file><file_path>main.py</file_path></read_file>"},
    {"role": "user", "content": "<tool_result tool_name='read_file' success='true'><content>... 5000 lines ...</content></tool_result>"},
    {"role": "assistant", "content": "I see the code. Let me refactor it..."},
    {"role": "assistant", "content": "<write_to_file><file_path>main.py</file_path><content>... 5000 lines ...</content></write_to_file>"},
    {"role": "user", "content": "<tool_result tool_name='write_to_file' success='true'>File written</tool_result>"},
    {"role": "user", "content": "Now read config.json"},
    {"role": "assistant", "content": "<read_file><file_path>config.json</file_path></read_file>"},
    {"role": "user", "content": "<tool_result tool_name='read_file' success='true'><content>... 1000 lines ...</content></tool_result>"},
    {"role": "user", "content": "Update the config"},
]

# æ¸…ç†æ­¥éª¤ï¼š

# 1. è¯†åˆ«å¯æ¸…ç†æ¶ˆæ¯
cleanable = [
    {"index": 3, "type": "tool_result"},   # read_file ç»“æœï¼ˆ5000è¡Œï¼‰
    {"index": 5, "type": "tool_call"},     # write_to_file è°ƒç”¨ï¼ˆ5000è¡Œï¼‰
    {"index": 6, "type": "tool_result"},   # write_to_file ç»“æœï¼ˆå°ï¼Œå¯èƒ½ä¸æ¸…ç†ï¼‰
    {"index": 9, "type": "tool_result"},   # read_file ç»“æœï¼ˆ1000è¡Œï¼‰
]

# 2. æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆtool_result ä¼˜å…ˆï¼‰
sorted_cleanable = [
    {"index": 3, "type": "tool_result"},   # ä¼˜å…ˆæ¸…ç†
    {"index": 6, "type": "tool_result"},
    {"index": 9, "type": "tool_result"},
    {"index": 5, "type": "tool_call"},     # æœ€åæ¸…ç†
]

# 3. é€ä¸ªæ¸…ç†ï¼Œç›´åˆ° token æ•°æ»¡è¶³è¦æ±‚
# å‡è®¾æ¸…ç† index 3 åï¼Œtoken æ•°å·²åœ¨å®‰å…¨åŒºå†…
# åœæ­¢æ¸…ç†ï¼Œä¿ç•™å…¶ä»–æ¶ˆæ¯

# 4. æœ€ç»ˆç»“æœ
final_conversations = [
    {"role": "system", "content": "You are an AI assistant..."},
    {"role": "user", "content": "Read the file main.py"},
    {"role": "assistant", "content": "<read_file><file_path>main.py</file_path></read_file>"},
    {"role": "user", "content": "<tool_result tool_name='read_file' success='true'><content>Content cleared to save tokens</content></tool_result>"},  # å·²æ¸…ç†
    {"role": "assistant", "content": "I see the code. Let me refactor it..."},
    {"role": "assistant", "content": "<write_to_file><file_path>main.py</file_path><content>... 5000 lines ...</content></write_to_file>"},  # ä¿ç•™
    {"role": "user", "content": "<tool_result tool_name='write_to_file' success='true'>File written</tool_result>"},  # ä¿ç•™
    {"role": "user", "content": "Now read config.json"},
    {"role": "assistant", "content": "<read_file><file_path>config.json</file_path></read_file>"},
    {"role": "user", "content": "<tool_result tool_name='read_file' success='true'><content>... 1000 lines ...</content></tool_result>"},  # ä¿ç•™ï¼ˆæœ€è¿‘çš„ï¼‰
    {"role": "user", "content": "Update the config"},
]
```

### 4.3.8 æ¸…ç†ç»Ÿè®¡

è·å–æ¸…ç†çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼š

```python
def get_cleanup_statistics(self, original_conversations: List[Dict[str, Any]],
                           pruned_conversations: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    è·å–æ¸…ç†è¿‡ç¨‹çš„ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        {
            "original_tokens": int,
            "pruned_tokens": int,
            "tokens_saved": int,
            "compression_ratio": float,
            "tool_results_cleaned": int,
            "tool_calls_cleaned": int,
            "total_messages": int
        }
    """
    original_tokens = count_string_tokens(
        json.dumps(original_conversations, ensure_ascii=False))
    pruned_tokens = count_string_tokens(
        json.dumps(pruned_conversations, ensure_ascii=False))
    
    # ç»Ÿè®¡æ¸…ç†çš„æ¶ˆæ¯æ•°
    tool_results_cleaned = 0
    tool_calls_cleaned = 0
    
    for orig, pruned in zip(original_conversations, pruned_conversations):
        if orig.get("content") != pruned.get("content"):
            # æ£€æŸ¥æ˜¯å·¥å…·ç»“æœè¿˜æ˜¯å·¥å…·è°ƒç”¨
            if (orig.get("role") == "user" and
                    self._is_tool_result_message(orig.get("content", ""))):
                tool_results_cleaned += 1
            
            elif (orig.get("role") == "assistant" and
                  self.tool_content_detector.is_tool_call_content(orig.get("content", ""))):
                tool_calls_cleaned += 1
    
    return {
        "original_tokens": original_tokens,
        "pruned_tokens": pruned_tokens,
        "tokens_saved": original_tokens - pruned_tokens,
        "compression_ratio": pruned_tokens / original_tokens if original_tokens > 0 else 1.0,
        "tool_results_cleaned": tool_results_cleaned,
        "tool_calls_cleaned": tool_calls_cleaned,
        "total_messages": len(original_conversations)
    }
```

**ç»Ÿè®¡è¾“å‡ºç¤ºä¾‹**ï¼š

```json
{
  "original_tokens": 15000,
  "pruned_tokens": 3000,
  "tokens_saved": 12000,
  "compression_ratio": 0.20,
  "tool_results_cleaned": 3,
  "tool_calls_cleaned": 2,
  "total_messages": 20
}
```

### 4.3.9 Tool Cleanup Pruning æ€»ç»“

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š

1. **å®Œå…¨è‡ªåŠ¨åŒ–**ï¼šæ— éœ€ LLM å‚ä¸ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«å’Œæ¸…ç†
2. **æ™ºèƒ½è¯†åˆ«**ï¼šåŸºäºæ¶ˆæ¯ç»“æ„å’Œå†…å®¹ç‰¹å¾è¯†åˆ«å¯å‹ç¼©å†…å®¹
3. **æ¸è¿›å¼æ¸…ç†**ï¼šæŒ‰ä¼˜å…ˆçº§é€ä¸ªæ¸…ç†ï¼Œé¿å…è¿‡åº¦å‰ªè£
4. **ä¿ç•™éª¨æ¶**ï¼šä¿ç•™å·¥å…·è°ƒç”¨çš„ç»“æ„ä¿¡æ¯ï¼Œåªåˆ é™¤å¤§å†…å®¹å­—æ®µ
5. **ä¿æŠ¤æœºåˆ¶**ï¼šä¿ç•™æœ€å°æ¶ˆæ¯æ•°ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¿è´¯æ€§

**é€‚ç”¨åœºæ™¯**ï¼š

- âœ… é¢‘ç¹ä½¿ç”¨æ–‡ä»¶è¯»å†™å·¥å…·
- âœ… å·¥å…·è¾“å‡ºåŒ…å«å¤§é‡å†…å®¹
- âœ… æ—©æœŸå·¥å…·è¾“å‡ºå·²è¢«åç»­æ“ä½œè¦†ç›–
- âœ… éœ€è¦è‡ªåŠ¨åŒ–ã€æ— æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†

**å‹ç¼©æ•ˆæœ**ï¼š

| å†…å®¹ç±»å‹ | åŸå§‹å¤§å° | å‹ç¼©åå¤§å° | å‹ç¼©æ¯” |
|---------|---------|-----------|--------|
| æ–‡ä»¶è¯»å–ç»“æœï¼ˆ5000è¡Œï¼‰ | ~15KB | ~200B | 98.7% |
| æ–‡ä»¶å†™å…¥è°ƒç”¨ï¼ˆ3000è¡Œï¼‰ | ~10KB | ~150B | 98.5% |
| Diffå†…å®¹ï¼ˆ1000è¡Œï¼‰ | ~5KB | ~100B | 98.0% |
| å°å‹å·¥å…·ç»“æœï¼ˆ<500å­—ç¬¦ï¼‰ | ~500B | ä¸å‹ç¼© | 0% |

**è®¾è®¡æƒè¡¡**ï¼š

ä¼˜ç‚¹ï¼š
- âœ… è‡ªåŠ¨åŒ–ï¼Œæ— éœ€ LLM å¹²é¢„
- âœ… å‹ç¼©æ¯”é«˜ï¼ˆé€šå¸¸ >95%ï¼‰
- âœ… ä¸å½±å“å¯¹è¯æµç¨‹
- âœ… ä¿ç•™å…³é”®ä¿¡æ¯ï¼ˆå·¥å…·åã€å‚æ•°åï¼‰

å±€é™æ€§ï¼š
- âŒ åªèƒ½å¤„ç†ç‰¹å®šæ ¼å¼çš„å·¥å…·è°ƒç”¨
- âŒ æ— æ³•è¯†åˆ«å†…å®¹çš„é‡è¦æ€§ï¼ˆæœºæ¢°å¼æ¸…ç†ï¼‰
- âŒ å¦‚æœ LLM éœ€è¦å¼•ç”¨æ—©æœŸå·¥å…·è¾“å‡ºï¼Œå¯èƒ½æ‰¾ä¸åˆ°å†…å®¹
- âŒ éœ€è¦ä¸ºæ¯ç§å·¥å…·å®šä¹‰æ¸…ç†è§„åˆ™

**ä¸ Message IDs Pruning çš„å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | Message IDs Pruning | Tool Cleanup Pruning |
|------|-------------------|-------------------|
| è§¦å‘æ–¹å¼ | LLM ä¸»åŠ¨æ ‡è®° | ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ« |
| å†³ç­–ä¸»ä½“ | LLMï¼ˆç†è§£è¯­ä¹‰ï¼‰ | ç³»ç»Ÿï¼ˆåŸºäºè§„åˆ™ï¼‰ |
| ç²¾ç¡®åº¦ | é«˜ï¼ˆLLM åˆ¤æ–­ï¼‰ | ä¸­ï¼ˆè§„åˆ™åŒ¹é…ï¼‰ |
| å‹ç¼©èŒƒå›´ | æ•´æ¡æ¶ˆæ¯åˆ é™¤ | éƒ¨åˆ†å†…å®¹å‹ç¼© |
| é€‚ç”¨åœºæ™¯ | ä¸å†éœ€è¦çš„æ¶ˆæ¯ | å¤§å†…å®¹ä½†éœ€ä¿ç•™ç»“æ„ |
| ä¼˜åŠ¿ | æ™ºèƒ½ã€ç²¾ç¡® | è‡ªåŠ¨ã€é«˜å‹ç¼©æ¯” |
| å±€é™ | éœ€è¦ LLM å‚ä¸ | æ— è¯­ä¹‰ç†è§£ |

**æœ€ä½³å®è·µ**ï¼š

1. **ä¼˜å…ˆä½¿ç”¨ Tool Cleanup**ï¼šè‡ªåŠ¨ã€æ— æ„ŸçŸ¥ã€é«˜å‹ç¼©æ¯”
2. **é…åˆ Message IDs**ï¼šLLM è¯†åˆ«ä¸å†éœ€è¦çš„å®Œæ•´æ¶ˆæ¯
3. **è°ƒæ•´é˜ˆå€¼**ï¼šæ ¹æ®æ¨¡å‹é™åˆ¶è°ƒæ•´ `safe_zone_tokens`
4. **ç›‘æ§ç»Ÿè®¡**ï¼šå®šæœŸæ£€æŸ¥å‹ç¼©æ•ˆæœï¼Œä¼˜åŒ–ç­–ç•¥
5. **æ‰©å±•æ”¯æŒ**ï¼šä¸ºæ–°å·¥å…·æ·»åŠ æ¸…ç†è§„åˆ™


## 4.4 å®‰å…¨åŒºé…ç½®

### 4.4.1 conversation_prune_safe_zone_tokens å‚æ•°

`conversation_prune_safe_zone_tokens` å‚æ•°å®šä¹‰äº†å‰ªè£çš„ç›®æ ‡é˜ˆå€¼ã€‚å½“å¯¹è¯çš„ token æ•°é‡è¶…è¿‡è¿™ä¸ªå€¼æ—¶ï¼Œç³»ç»Ÿä¼šè§¦å‘å‰ªè£ã€‚

**è®¾è®¡ç›®æ ‡**ï¼š
1. **çµæ´»æ€§**ï¼šæ”¯æŒå¤šç§æ ¼å¼ï¼Œé€‚åº”ä¸åŒç”¨æˆ·ä¹ æƒ¯
2. **å¯è¯»æ€§**ï¼šäººç±»å‹å¥½çš„æ ¼å¼ï¼ˆå¦‚ "80k"ï¼‰
3. **åŠ¨æ€æ€§**ï¼šæ”¯æŒåŸºäºæ¨¡å‹çª—å£çš„ç™¾åˆ†æ¯”é…ç½®
4. **å®‰å…¨æ€§**ï¼šé˜²æ­¢éæ³•è¾“å…¥ï¼Œæä¾›é»˜è®¤å€¼

### 4.4.2 æ”¯æŒçš„å‚æ•°æ ¼å¼

TokenParser æ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š

**1. æ•´æ•°ï¼ˆæœ€ç›´æ¥ï¼‰**

```python
conversation_prune_safe_zone_tokens: int = 51200  # 51200 tokens
```

**2. å¸¦å•ä½çš„å­—ç¬¦ä¸²ï¼ˆæ¨èï¼‰**

```python
conversation_prune_safe_zone_tokens: str = "50k"   # 50 * 1024 = 51200 tokens
conversation_prune_safe_zone_tokens: str = "1m"    # 1 * 1024 * 1024 = 1,048,576 tokens
conversation_prune_safe_zone_tokens: str = "2.5k"  # 2.5 * 1024 = 2560 tokens
```

**æ”¯æŒçš„å•ä½**ï¼š

| å•ä½ | å€æ•° | ç¤ºä¾‹ |
|-----|------|------|
| k, kb, K, KB | 1024 | "50k" â†’ 51200 |
| m, mb, M, MB | 1024Â² | "1m" â†’ 1,048,576 |
| g, gb, G, GB | 1024Â³ | "2g" â†’ 2,147,483,648 |

**3. æ•°å­¦è¡¨è¾¾å¼**

```python
conversation_prune_safe_zone_tokens: str = "50*1024"      # 51200
conversation_prune_safe_zone_tokens: str = "100*1000"     # 100000
conversation_prune_safe_zone_tokens: str = "2**16"        # 65536
conversation_prune_safe_zone_tokens: str = "50*1024+512"  # 51712
```

**4. æµ®ç‚¹æ•°ï¼ˆç™¾åˆ†æ¯”ï¼‰**

```python
conversation_prune_safe_zone_tokens: float = 0.8  # æ¨¡å‹ context_window çš„ 80%

# ä¾‹å¦‚ï¼šå¦‚æœæ¨¡å‹ context_window æ˜¯ 128000
# 0.8 * 128000 = 102400 tokens
```

### 4.4.3 AutoCoderArgsParser è§£ææµç¨‹

```python
class AutoCoderArgsParser:
    """å‚æ•°è§£æå™¨ï¼Œæ”¯æŒçµæ´»çš„å‚æ•°æ ¼å¼"""
    
    def __init__(self, llm_manager: Optional[LLMManager] = None):
        """åˆå§‹åŒ–è§£æå™¨"""
        self.llm_manager = llm_manager or LLMManager()
        self.token_parser = TokenParser(self.llm_manager)
    
    def parse_conversation_prune_safe_zone_tokens(self, 
                                                 value: Union[str, int, float],
                                                 code_model: Optional[str] = None) -> int:
        """
        è§£æ conversation_prune_safe_zone_tokens å‚æ•°
        
        Args:
            value: å‚æ•°å€¼ï¼ˆå­—ç¬¦ä¸²ã€æ•´æ•°æˆ–æµ®ç‚¹æ•°ï¼‰
            code_model: ä»£ç æ¨¡å‹åç§°ï¼ˆç”¨äºæµ®ç‚¹æ•°ç™¾åˆ†æ¯”è®¡ç®—ï¼‰
        
        Returns:
            è§£æåçš„ token æ•°é‡ï¼ˆæ•´æ•°ï¼‰
        
        Examples:
            >>> parser.parse_conversation_prune_safe_zone_tokens(51200)
            51200
            
            >>> parser.parse_conversation_prune_safe_zone_tokens("50k")
            51200
            
            >>> parser.parse_conversation_prune_safe_zone_tokens("50*1024")
            51200
            
            >>> parser.parse_conversation_prune_safe_zone_tokens(0.8, "deepseek/deepseek-chat")
            # è¿”å› deepseek-chat context_window çš„ 80%
        """
        try:
            return self.token_parser.parse_token_value(value, code_model)
        except ValueError as e:
            # è§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            default_value = 50 * 1024  # 50k tokens
            print(f"Warning: Failed to parse conversation_prune_safe_zone_tokens '{value}': {e}. "
                  f"Using default value: {default_value}")
            return default_value
```

### 4.4.4 TokenParser å®ç°ç»†èŠ‚

TokenParser é‡‡ç”¨**åˆ†å±‚è§£æç­–ç•¥**ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„è§£ææ–¹æ³•ï¼š

```python
class TokenParser:
    """Token æ•°é‡è§£æå™¨"""
    
    # å•ä½è½¬æ¢æ˜ å°„
    UNIT_MULTIPLIERS = {
        'k': 1024,
        'm': 1024 * 1024,
        'g': 1024 * 1024 * 1024,
        'kb': 1024,
        'mb': 1024 * 1024,
        'gb': 1024 * 1024 * 1024,
    }
    
    def parse_token_value(self, value: Union[str, int, float], 
                         code_model: Optional[str] = None) -> int:
        """
        è§£æ token æ•°é‡å€¼ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        
        è§£æé¡ºåºï¼š
        1. int ç±»å‹ â†’ ç›´æ¥è¿”å›
        2. float ç±»å‹ â†’ åŸºäºæ¨¡å‹ context_window è®¡ç®—
        3. str ç±»å‹ â†’ ä¾æ¬¡å°è¯•çº¯æ•°å­—ã€å¸¦å•ä½ã€æ•°å­¦è¡¨è¾¾å¼
        """
        if isinstance(value, int):
            return max(0, value)  # ç¡®ä¿éè´Ÿ
        
        if isinstance(value, float):
            return self._parse_float_value(value, code_model)
        
        if isinstance(value, str):
            return self._parse_string_value(value)
        
        raise ValueError(f"Unsupported value type: {type(value)}")
```

**æµ®ç‚¹æ•°è§£æï¼ˆç™¾åˆ†æ¯”ï¼‰**ï¼š

```python
def _parse_float_value(self, value: float, code_model: Optional[str] = None) -> int:
    """
    è§£ææµ®ç‚¹æ•°å€¼ï¼ŒåŸºäºæ¨¡å‹çš„ context_window
    
    Args:
        value: æµ®ç‚¹æ•°å€¼ï¼ˆ0-1 ä¹‹é—´è¡¨ç¤ºæ¯”ä¾‹ï¼‰
        code_model: æ¨¡å‹åç§°
    
    Returns:
        è®¡ç®—åçš„ token æ•°é‡
    
    Raises:
        ValueError: å¦‚æœå€¼ä¸åœ¨ 0-1 ä¹‹é—´
    """
    # éªŒè¯èŒƒå›´
    if not (0 <= value <= 1):
        raise ValueError(f"Float value must be between 0 and 1, got: {value}")
    
    # è·å–æ¨¡å‹çš„ context_window
    context_window = self._get_context_window(code_model)
    
    # è®¡ç®—å®é™… token æ•°
    return int(context_window * value)

def _get_context_window(self, model_name: Optional[str] = None) -> int:
    """
    è·å–æ¨¡å‹çš„ context_window
    
    Returns:
        context_window å¤§å°ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›é»˜è®¤å€¼ 120,000
    """
    if not model_name:
        return 120 * 1000  # é»˜è®¤ 120k
    
    try:
        model = self.llm_manager.get_model(model_name)
        if model and model.context_window > 0:
            return model.context_window
    except Exception:
        pass
    
    return 120 * 1000  # å…œåº•é»˜è®¤å€¼
```

**å­—ç¬¦ä¸²è§£æï¼ˆä¸‰å±‚å°è¯•ï¼‰**ï¼š

```python
def _parse_string_value(self, value: str) -> int:
    """
    è§£æå­—ç¬¦ä¸²å€¼ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    è§£æé¡ºåºï¼š
    1. çº¯æ•°å­—å­—ç¬¦ä¸²ï¼ˆæ•´æ•°/æµ®ç‚¹æ•°ï¼‰
    2. å¸¦å•ä½çš„æ•°å­—ï¼ˆ50k, 1mï¼‰
    3. æ•°å­¦è¡¨è¾¾å¼ï¼ˆ50*1024ï¼‰
    """
    value = value.strip()
    
    if not value:
        raise ValueError("Empty string value")
    
    # ç¬¬1å±‚ï¼šå°è¯•çº¯æ•°å­—å­—ç¬¦ä¸²
    numeric_result = self._try_parse_numeric_string(value)
    if numeric_result is not None:
        return numeric_result
    
    # ç¬¬2å±‚ï¼šå°è¯•å¸¦å•ä½çš„æ•°å­—
    unit_result = self._try_parse_with_unit(value)
    if unit_result is not None:
        return unit_result
    
    # ç¬¬3å±‚ï¼šå°è¯•æ•°å­¦è¡¨è¾¾å¼
    return self._parse_math_expression(value)
```

**ç¬¬1å±‚ï¼šçº¯æ•°å­—è§£æ**ï¼š

```python
def _try_parse_numeric_string(self, value: str) -> Optional[int]:
    """
    å°è¯•è§£æçº¯æ•°å­—å­—ç¬¦ä¸²
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - æ•´æ•°ï¼š123, -456
    - æµ®ç‚¹æ•°ï¼š123.45, .5, 123.
    """
    try:
        # åŒ¹é…æ•´æ•°ï¼ˆåŒ…æ‹¬è´Ÿæ•°ï¼‰
        if re.match(r'^-?\d+$', value):
            return max(0, int(value))
        
        # åŒ¹é…æµ®ç‚¹æ•°
        if re.match(r'^-?\d+\.\d+$', value) or \
           re.match(r'^-?\d+\.$', value) or \
           re.match(r'^-?\.\d+$', value):
            float_value = float(value)
            return max(0, int(float_value))
        
        return None  # ä¸æ˜¯çº¯æ•°å­—
    except (ValueError, TypeError):
        return None
```

**ç¬¬2å±‚ï¼šå¸¦å•ä½è§£æ**ï¼š

```python
def _try_parse_with_unit(self, value: str) -> Optional[int]:
    """
    å°è¯•è§£æå¸¦å•ä½çš„æ•°å­—
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - 100k, 1.5m, 2g
    - 100K, 1.5M, 2Gï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
    - 100kb, 1.5mbï¼ˆå¯é€‰båç¼€ï¼‰
    """
    # åŒ¹é…æ¨¡å¼ï¼šæ•°å­— + å¯é€‰ç©ºæ ¼ + å•ä½
    pattern = r'^(\d+(?:\.\d+)?)\s*([kmgKMG](?:[bB]?)?)$'
    match = re.match(pattern, value)
    
    if not match:
        return None
    
    number_str, unit = match.groups()
    number = float(number_str)
    unit_lower = unit.lower()
    
    # æŸ¥æ‰¾å•ä½å€æ•°
    if unit_lower in self.UNIT_MULTIPLIERS:
        return int(number * self.UNIT_MULTIPLIERS[unit_lower])
    
    return None
```

**ç¬¬3å±‚ï¼šæ•°å­¦è¡¨è¾¾å¼è§£æ**ï¼ˆå®‰å…¨ï¼‰ï¼š

```python
def _parse_math_expression(self, expression: str) -> int:
    """
    å®‰å…¨åœ°è§£ææ•°å­¦è¡¨è¾¾å¼
    
    å®‰å…¨æ€§ï¼š
    - ä½¿ç”¨ AST è§£æï¼Œä¸æ‰§è¡Œä»»æ„ä»£ç 
    - åªæ”¯æŒåŸºæœ¬æ•°å­¦è¿ç®—ç¬¦ï¼ˆ+-*/ï¼‰
    - ä¸æ”¯æŒå‡½æ•°è°ƒç”¨ã€å˜é‡å¼•ç”¨
    
    æ”¯æŒçš„è¿ç®—ç¬¦ï¼š
    - åŠ å‡ä¹˜é™¤ï¼š+, -, *, /, //
    - å¹‚è¿ç®—ï¼š**
    - å–æ¨¡ï¼š%
    - æ‹¬å·ï¼š()
    """
    try:
        # è§£æä¸º ASTï¼ˆæŠ½è±¡è¯­æ³•æ ‘ï¼‰
        tree = ast.parse(expression, mode='eval')
        
        # é€’å½’è®¡ç®— AST
        result = self._evaluate_ast_node(tree.body)
        
        # ç¡®ä¿ç»“æœæ˜¯æ­£æ•´æ•°
        if isinstance(result, (int, float)):
            return max(0, int(result))
        else:
            raise ValueError(f"Expression result is not a number: {result}")
    
    except (SyntaxError, ValueError, TypeError) as e:
        raise ValueError(f"Invalid expression '{expression}': {e}")

def _evaluate_ast_node(self, node: ast.AST) -> Union[int, float]:
    """é€’å½’è®¡ç®— AST èŠ‚ç‚¹"""
    # å¸¸é‡èŠ‚ç‚¹
    if isinstance(node, (ast.Constant, ast.Num)):
        return node.value if isinstance(node, ast.Constant) else node.n
    
    # äºŒå…ƒè¿ç®—èŠ‚ç‚¹
    elif isinstance(node, ast.BinOp):
        left = self._evaluate_ast_node(node.left)
        right = self._evaluate_ast_node(node.right)
        
        # è·å–è¿ç®—ç¬¦
        op = self.OPERATORS.get(type(node.op))
        if op is None:
            raise ValueError(f"Unsupported operator: {type(node.op)}")
        
        # æ£€æŸ¥é™¤é›¶
        if isinstance(node.op, (ast.Div, ast.FloorDiv, ast.Mod)) and right == 0:
            raise ValueError("Division by zero")
        
        return op(left, right)
    
    # ä¸€å…ƒè¿ç®—èŠ‚ç‚¹
    elif isinstance(node, ast.UnaryOp):
        operand = self._evaluate_ast_node(node.operand)
        if isinstance(node.op, ast.UAdd):
            return +operand
        elif isinstance(node.op, ast.USub):
            return -operand
        else:
            raise ValueError(f"Unsupported unary operator: {type(node.op)}")
    
    else:
        raise ValueError(f"Unsupported AST node type: {type(node)}")
```


### 4.4.5 è§£æç¤ºä¾‹

```python
parser = AutoCoderArgsParser()

# ç¤ºä¾‹1ï¼šæ•´æ•°
result = parser.parse_conversation_prune_safe_zone_tokens(51200)
# ç»“æœï¼š51200

# ç¤ºä¾‹2ï¼šå¸¦å•ä½
result = parser.parse_conversation_prune_safe_zone_tokens("50k")
# ç»“æœï¼š51200 (50 * 1024)

result = parser.parse_conversation_prune_safe_zone_tokens("1.5m")
# ç»“æœï¼š1572864 (1.5 * 1024 * 1024)

# ç¤ºä¾‹3ï¼šæ•°å­¦è¡¨è¾¾å¼
result = parser.parse_conversation_prune_safe_zone_tokens("50*1024")
# ç»“æœï¼š51200

result = parser.parse_conversation_prune_safe_zone_tokens("2**16")
# ç»“æœï¼š65536

result = parser.parse_conversation_prune_safe_zone_tokens("50*1024 + 512")
# ç»“æœï¼š51712

# ç¤ºä¾‹4ï¼šæµ®ç‚¹æ•°ï¼ˆç™¾åˆ†æ¯”ï¼‰
result = parser.parse_conversation_prune_safe_zone_tokens(0.8, "deepseek/deepseek-chat")
# å‡è®¾ deepseek-chat çš„ context_window æ˜¯ 128000
# ç»“æœï¼š102400 (128000 * 0.8)

result = parser.parse_conversation_prune_safe_zone_tokens(0.6, "gpt-4-turbo")
# å‡è®¾ gpt-4-turbo çš„ context_window æ˜¯ 128000
# ç»“æœï¼š76800 (128000 * 0.6)

# ç¤ºä¾‹5ï¼šé”™è¯¯è¾“å…¥ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
result = parser.parse_conversation_prune_safe_zone_tokens("invalid")
# è­¦å‘Šï¼šFailed to parse... Using default value: 51200
# ç»“æœï¼š51200ï¼ˆé»˜è®¤å€¼ï¼‰
```

### 4.4.6 ä¸åŒæ¨¡å‹çš„æ¨èé…ç½®

åŸºäºä¸åŒæ¨¡å‹çš„ context_windowï¼Œæ¨èçš„å®‰å…¨åŒºé…ç½®ï¼š

| æ¨¡å‹ | Context Window | æ¨èé…ç½®ï¼ˆ80%ï¼‰ | æ¨èé…ç½®ï¼ˆ60%ï¼‰ | è¯´æ˜ |
|------|---------------|----------------|----------------|------|
| GPT-4 Turbo | 128k | 102k (0.8) | 76k (0.6) | ä¿å®ˆç­–ç•¥ |
| Claude 3 Sonnet | 200k | 160k (0.8) | 120k (0.6) | ä¸­ç­‰ç­–ç•¥ |
| Deepseek V3 | 64k | 51k (0.8) | 38k (0.6) | è¾ƒå°çª—å£ |
| Gemini 1.5 Pro | 1M | 800k (0.8) | 600k (0.6) | è¶…å¤§çª—å£ |
| GLM-4 | 128k | 102k (0.8) | 76k (0.6) | æ ‡å‡†é…ç½® |

**é…ç½®å»ºè®®**ï¼š

```yaml
# æ–¹æ¡ˆ1ï¼šå›ºå®šå€¼ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
conversation_prune_safe_zone_tokens: "80k"  # å›ºå®š 80k tokens

# æ–¹æ¡ˆ2ï¼šç™¾åˆ†æ¯”ï¼ˆæ¨èç”¨äºå¼€å‘ç¯å¢ƒï¼‰
conversation_prune_safe_zone_tokens: 0.7  # æ¨¡å‹çª—å£çš„ 70%

# æ–¹æ¡ˆ3ï¼šåŸºäºæ¨¡å‹åŠ¨æ€é…ç½®
conversation_prune_safe_zone_tokens: 0.8  # é…åˆ code_model å‚æ•°
code_model: "deepseek/deepseek-chat"  # è‡ªåŠ¨è®¡ç®—ï¼š128k * 0.8 = 102k

# æ–¹æ¡ˆ4ï¼šè¡¨è¾¾å¼ï¼ˆé€‚åˆç‰¹æ®Šéœ€æ±‚ï¼‰
conversation_prune_safe_zone_tokens: "100*1024"  # ç²¾ç¡® 100k tokens
```

### 4.4.7 å®‰å…¨åŒºé…ç½®çš„ä½œç”¨

```python
def prune_conversations(self, conversations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """å‰ªè£æµç¨‹ä¸­çš„å®‰å…¨åŒºæ£€æŸ¥"""
    # è·å–å®‰å…¨åŒºé˜ˆå€¼
    safe_zone_tokens = self._get_parsed_safe_zone_tokens()
    # ä¾‹å¦‚ï¼šsafe_zone_tokens = 51200ï¼ˆ50kï¼‰
    
    # è®¡ç®—å½“å‰å¯¹è¯çš„ token æ•°
    current_tokens = count_string_tokens(
        json.dumps(conversations, ensure_ascii=False))
    # ä¾‹å¦‚ï¼šcurrent_tokens = 75000
    
    # æ£€æŸ¥1ï¼šæ˜¯å¦éœ€è¦å‰ªè£ï¼Ÿ
    if current_tokens <= safe_zone_tokens:
        # å½“å‰ token æ•° â‰¤ å®‰å…¨åŒºï¼Œæ— éœ€å‰ªè£
        return conversations
    
    # æ‰§è¡Œå‰ªè£...
    
    # æ£€æŸ¥2ï¼šå‰ªè£åæ˜¯å¦åœ¨å®‰å…¨åŒºå†…ï¼Ÿ
    final_tokens = count_string_tokens(
        json.dumps(processed_conversations, ensure_ascii=False))
    
    if final_tokens > safe_zone_tokens:
        # å‰ªè£åä»è¶…é™ï¼Œæç¤º LLM ä¸»åŠ¨æ¸…ç†
        cleanup_message = "The conversation is still too long, please use conversation_message_ids_write tool..."
        processed_conversations = merge_with_last_user_message(
            processed_conversations, cleanup_message)
    
    return processed_conversations
```

**å®‰å…¨åŒºé…ç½®çš„æ„ä¹‰**ï¼š

1. **æ€§èƒ½ä¼˜åŒ–**ï¼šé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿å¯¼è‡´çš„æ¨ç†é€Ÿåº¦ä¸‹é™
2. **æˆæœ¬æ§åˆ¶**ï¼šå‡å°‘ API è°ƒç”¨çš„ token æ¶ˆè€—
3. **æ¨¡å‹é™åˆ¶**ï¼šé˜²æ­¢è¶…å‡ºæ¨¡å‹çš„ context_window
4. **ç¨³å®šæ€§**ï¼šä¿è¯ç³»ç»Ÿåœ¨é•¿æ—¶é—´å¯¹è¯ä¸­çš„ç¨³å®šè¿è¡Œ

## 4.5 å‰ªè£ç»Ÿè®¡å’Œç›‘æ§

### 4.5.1 PruningResult æ•°æ®ç»“æ„

AgenticConversationPruner ä½¿ç”¨å†…ç½®çš„ç»Ÿè®¡ç»“æ„è¿½è¸ªå‰ªè£è¿‡ç¨‹ï¼š

```python
# å‰ªè£ç»Ÿè®¡ä¿¡æ¯ï¼ˆå†…ç½®äº AgenticConversationPrunerï¼‰
self.pruning_stats = {
    # ç­–ç•¥åº”ç”¨æƒ…å†µ
    "range_pruning_applied": False,      # æ˜¯å¦åº”ç”¨äº†æ¶ˆæ¯IDå‰ªè£
    "range_pruning_success": False,      # æ¶ˆæ¯IDå‰ªè£æ˜¯å¦æˆåŠŸ
    
    # æ¶ˆæ¯æ•°ç»Ÿè®¡
    "original_length": 0,                # åŸå§‹æ¶ˆæ¯æ•°
    "after_range_pruning": 0,            # æ¶ˆæ¯IDå‰ªè£åæ¶ˆæ¯æ•°
    "after_tool_cleanup": 0,             # å·¥å…·æ¸…ç†åæ¶ˆæ¯æ•°
    
    # å‹ç¼©æ¯”
    "total_compression_ratio": 1.0       # æ€»å‹ç¼©æ¯”ï¼ˆæœ€ç»ˆæ¶ˆæ¯æ•°/åŸå§‹æ¶ˆæ¯æ•°ï¼‰
}
```

### 4.5.2 è·å–å®Œæ•´ç»Ÿè®¡ä¿¡æ¯

```python
def get_pruning_statistics(self) -> Dict[str, Any]:
    """
    è·å–å®Œæ•´çš„å‰ªè£ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        è¯¦ç»†çš„ç»Ÿè®¡å­—å…¸ï¼ŒåŒ…å«ï¼š
        - ç­–ç•¥åº”ç”¨æƒ…å†µ
        - æ¶ˆæ¯æ•°å˜åŒ–
        - å‹ç¼©æ¯”
        - æ¶ˆæ¯åˆ é™¤æ•°é‡
    """
    return {
        # ç­–ç•¥ä¿¡æ¯
        "range_pruning": {
            "applied": self.pruning_stats["range_pruning_applied"],
            "success": self.pruning_stats["range_pruning_success"],
            "conversation_id": self._get_current_conversation_id()
        },
        
        # æ¶ˆæ¯æ•°ç»Ÿè®¡
        "message_counts": {
            "original": self.pruning_stats["original_length"],
            "after_range_pruning": self.pruning_stats["after_range_pruning"],
            "after_tool_cleanup": self.pruning_stats["after_tool_cleanup"]
        },
        
        # å‹ç¼©æ¯”ç»Ÿè®¡
        "compression": {
            "range_pruning_ratio": (
                self.pruning_stats["after_range_pruning"] /
                self.pruning_stats["original_length"]
                if self.pruning_stats["original_length"] > 0 else 1.0
            ),
            "tool_cleanup_ratio": (
                self.pruning_stats["after_tool_cleanup"] /
                self.pruning_stats["after_range_pruning"]
                if self.pruning_stats["after_range_pruning"] > 0 else 1.0
            ),
            "total_compression_ratio": self.pruning_stats["total_compression_ratio"]
        },
        
        # åˆ é™¤çš„æ¶ˆæ¯æ•°
        "messages_removed": {
            "by_range_pruning": (
                self.pruning_stats["original_length"] -
                self.pruning_stats["after_range_pruning"]
            ),
            "by_tool_cleanup": (
                self.pruning_stats["after_range_pruning"] -
                self.pruning_stats["after_tool_cleanup"]
            ),
            "total_removed": (
                self.pruning_stats["original_length"] -
                self.pruning_stats["after_tool_cleanup"]
            )
        }
    }
```

**ç»Ÿè®¡è¾“å‡ºç¤ºä¾‹**ï¼š

```json
{
  "range_pruning": {
    "applied": true,
    "success": true,
    "conversation_id": "conv_abc123"
  },
  "message_counts": {
    "original": 50,
    "after_range_pruning": 40,
    "after_tool_cleanup": 30
  },
  "compression": {
    "range_pruning_ratio": 0.80,
    "tool_cleanup_ratio": 0.75,
    "total_compression_ratio": 0.60
  },
  "messages_removed": {
    "by_range_pruning": 10,
    "by_tool_cleanup": 10,
    "total_removed": 20
  }
}
```


### 4.5.3 å¯¹æ¯”åˆ†ææŠ¥å‘Šç”Ÿæˆ

ç³»ç»Ÿå¯ä»¥ç”Ÿæˆè¯¦ç»†çš„å‰ªè£å‰åå¯¹æ¯”æŠ¥å‘Šï¼š

```python
def _generate_comparison_report(self, original_conversations: List[Dict[str, Any]],
                                pruned_conversations: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”åˆ†ææŠ¥å‘Š
    
    Returns:
        åŒ…å«å®Œæ•´å¯¹æ¯”ä¿¡æ¯çš„å­—å…¸
    """
    # åŸºç¡€ç»Ÿè®¡
    original_count = len(original_conversations)
    pruned_count = len(pruned_conversations)
    removed_count = original_count - pruned_count
    
    # Tokenç»Ÿè®¡
    original_tokens = count_string_tokens(
        json.dumps(original_conversations, ensure_ascii=False))
    pruned_tokens = count_string_tokens(
        json.dumps(pruned_conversations, ensure_ascii=False))
    tokens_saved = original_tokens - pruned_tokens
    
    # åˆ†æå˜åŒ–è¯¦æƒ…
    changes_analysis = self._analyze_conversation_changes(
        original_conversations, pruned_conversations)
    
    # åˆ†ææ¶ˆæ¯ç±»å‹åˆ†å¸ƒ
    original_distribution = self._analyze_message_distribution(
        original_conversations)
    pruned_distribution = self._analyze_message_distribution(
        pruned_conversations)
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    report = {
        "timestamp": str(__import__("datetime").datetime.now()),
        "conversation_id": self._get_current_conversation_id(),
        
        # ç­–ç•¥ä¿¡æ¯
        "pruning_strategy": {
            "range_pruning_applied": self.pruning_stats["range_pruning_applied"],
            "tool_cleanup_applied": True,
            "safe_zone_tokens": self._get_parsed_safe_zone_tokens()
        },
        
        # æ¶ˆæ¯æ•°ç»Ÿè®¡
        "message_counts": {
            "original": original_count,
            "final": pruned_count,
            "removed": removed_count,
            "after_range_pruning": self.pruning_stats.get("after_range_pruning", original_count)
        },
        
        # Tokenç»Ÿè®¡
        "tokens": {
            "original": original_tokens,
            "final": pruned_tokens,
            "saved": tokens_saved,
            "safe_zone_limit": self._get_parsed_safe_zone_tokens()
        },
        
        # å‹ç¼©æ¯”
        "compression": {
            "message_compression_ratio": pruned_count / original_count if original_count > 0 else 1.0,
            "token_compression_ratio": pruned_tokens / original_tokens if original_tokens > 0 else 1.0,
            "range_pruning_compression": (
                self.pruning_stats.get("after_range_pruning", original_count) / original_count
                if original_count > 0 else 1.0
            ),
            "tool_cleanup_compression": (
                pruned_count /
                self.pruning_stats.get("after_range_pruning", original_count)
                if self.pruning_stats.get("after_range_pruning", original_count) > 0 else 1.0
            )
        },
        
        # å˜åŒ–è¯¦æƒ…
        "changes": {
            "messages_removed_by_ids": (
                original_count -
                self.pruning_stats.get("after_range_pruning", original_count)
            ),
            "tool_results_modified": changes_analysis["tool_results_modified"],
            "tool_calls_modified": changes_analysis["tool_calls_modified"],
            "content_modifications": changes_analysis["content_modifications"],
            "unchanged_messages": changes_analysis["unchanged_messages"]
        },
        
        # æ¶ˆæ¯åˆ†å¸ƒ
        "message_distribution": {
            "original": original_distribution,
            "pruned": pruned_distribution
        },
        
        # è¯¦ç»†å˜åŒ–åˆ—è¡¨
        "detailed_changes": changes_analysis["detailed_changes"],
        
        # å‰ªè£æ•ˆæœè¯„ä¼°
        "pruning_effectiveness": {
            "tokens_per_message_before": original_tokens / original_count if original_count > 0 else 0,
            "tokens_per_message_after": pruned_tokens / pruned_count if pruned_count > 0 else 0,
            "average_token_reduction_per_message": tokens_saved / original_count if original_count > 0 else 0,
            "within_safe_zone": pruned_tokens <= self._get_parsed_safe_zone_tokens()
        }
    }
    
    return report
```

**å¯¹æ¯”æŠ¥å‘Šç¤ºä¾‹**ï¼š

```json
{
  "timestamp": "2025-01-15T10:30:00",
  "conversation_id": "conv_abc123",
  "pruning_strategy": {
    "range_pruning_applied": true,
    "tool_cleanup_applied": true,
    "safe_zone_tokens": 51200
  },
  "message_counts": {
    "original": 50,
    "final": 30,
    "removed": 20,
    "after_range_pruning": 40
  },
  "tokens": {
    "original": 75000,
    "final": 45000,
    "saved": 30000,
    "safe_zone_limit": 51200
  },
  "compression": {
    "message_compression_ratio": 0.60,
    "token_compression_ratio": 0.60,
    "range_pruning_compression": 0.80,
    "tool_cleanup_compression": 0.75
  },
  "changes": {
    "messages_removed_by_ids": 10,
    "tool_results_modified": 8,
    "tool_calls_modified": 2,
    "content_modifications": 10,
    "unchanged_messages": 20
  },
  "message_distribution": {
    "original": {
      "total_messages": 50,
      "role_distribution": {"user": 25, "assistant": 24, "system": 1},
      "message_type_distribution": {
        "tool_result": 12,
        "tool_call": 8,
        "regular_user": 13,
        "regular_assistant": 16,
        "system": 1
      }
    },
    "pruned": {
      "total_messages": 30,
      "role_distribution": {"user": 15, "assistant": 14, "system": 1},
      "message_type_distribution": {
        "tool_result": 4,
        "tool_call": 6,
        "regular_user": 11,
        "regular_assistant": 8,
        "system": 1
      }
    }
  },
  "pruning_effectiveness": {
    "tokens_per_message_before": 1500,
    "tokens_per_message_after": 1500,
    "average_token_reduction_per_message": 600,
    "within_safe_zone": true
  }
}
```

### 4.5.4 æ—¥å¿—è®°å½•

å‰ªè£è¿‡ç¨‹ä¸­çš„å…³é”®æ—¥å¿—ï¼š

```python
# åˆå§‹æ£€æŸ¥
logger.info(f"Current tokens: {current_tokens}, Safe zone: {safe_zone_tokens}")

# Message IDs å‰ªè£
logger.info(f"Applying message IDs pruning for conversation {conversation_id}")
logger.info(f"After Message IDs pruning: {original_length} -> {pruned_length} messages")
logger.info(f"Message IDs pruning compression: {compression_ratio:.2%}")

# Tool Cleanup å‰ªè£
logger.info(f"Found {tool_result_count} tool result messages and {tool_call_count} tool call messages to potentially clean")
logger.info(f"Cleaned tool result at index {index} (tool: {tool_name}), reduced from {original_size} to {new_size} characters")
logger.info(f"Unified tool cleanup completed. Cleaned {cleaned_count} messages. Token count: {initial_tokens} -> {final_tokens}")

# æœ€ç»ˆç»“æœ
logger.info(f"Complete pruning: {original_length} -> {final_length} messages (total compression: {compression_ratio:.2%})")
```

### 4.5.5 ä¿å­˜æ ¼å¼åŒ–æ—¥å¿—

å‰ªè£åçš„å¯¹è¯å’Œå¯¹æ¯”æŠ¥å‘Šä¼šä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶ï¼š

```python
# ä¿å­˜å‰ªè£åçš„å®Œæ•´å¯¹è¯
save_formatted_log(
    self.args.source_dir, 
    json.dumps(processed_conversations, ensure_ascii=False),
    "agentic_pruned_conversation", 
    conversation_id=conversation_id
)

# ä¿å­˜å¯¹æ¯”åˆ†ææŠ¥å‘Š
save_formatted_log(
    self.args.source_dir,
    json.dumps(comparison_report, ensure_ascii=False, indent=2),
    "conversation_comparison_report",
    conversation_id=conversation_id
)
```

**æ—¥å¿—æ–‡ä»¶è·¯å¾„**ï¼š

```
.auto-coder/logs/
â”œâ”€â”€ agentic_pruned_conversation_{conversation_id}_{timestamp}.json
â””â”€â”€ conversation_comparison_report_{conversation_id}_{timestamp}.json
```

### 4.5.6 WindowLengthChangeEvent äº‹ä»¶

å‰ªè£å®Œæˆåï¼Œç³»ç»Ÿä¼šç”Ÿæˆ `WindowLengthChangeEvent` äº‹ä»¶ï¼Œé€šçŸ¥å…¶ä»–ç»„ä»¶ï¼š

```python
# åœ¨ AgenticEdit.analyze æ–¹æ³•ä¸­
if pruned_tokens_used > 0:
    yield WindowLengthChangeEvent(
        tokens_used=tokens_used,                # åŸå§‹ token æ•°
        pruned_tokens_used=pruned_tokens_used,  # å‰ªè£å token æ•°
        conversation_round=self.conversation_round  # å¯¹è¯è½®æ¬¡
    )
```

**äº‹ä»¶æ•°æ®ç»“æ„**ï¼š

```python
@dataclass
class WindowLengthChangeEvent:
    """ä¸Šä¸‹æ–‡é•¿åº¦å˜åŒ–äº‹ä»¶"""
    tokens_used: int              # åŸå§‹ token æ•°
    pruned_tokens_used: int       # å‰ªè£å token æ•°
    conversation_round: int       # å¯¹è¯è½®æ¬¡
```

**äº‹ä»¶ç”¨é€”**ï¼š
- ç›‘æ§ä¸Šä¸‹æ–‡é•¿åº¦å˜åŒ–
- ç»Ÿè®¡å‰ªè£æ•ˆæœ
- è§¦å‘å‘Šè­¦ï¼ˆå¦‚å‰ªè£æ•ˆæœä¸ä½³ï¼‰
- è®°å½•æ€§èƒ½æŒ‡æ ‡

## 4.6 ç¬¬å››éƒ¨åˆ†æ€»ç»“

### 4.6.1 æ ¸å¿ƒäº®ç‚¹

**1. åŒç­–ç•¥ç»„åˆ**

```
AgenticConversationPruner = Message IDs Pruning + Tool Cleanup Pruning
                              ï¼ˆç²¾ç¡®åˆ é™¤ï¼‰        ï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰
```

- ä¼˜å…ˆä½¿ç”¨ç²¾ç¡®åˆ é™¤ï¼ˆLLM ä¸»å¯¼ï¼‰
- ä¸å¤Ÿå†ç”¨æ™ºèƒ½å‹ç¼©ï¼ˆç³»ç»Ÿè‡ªåŠ¨ï¼‰
- å…œåº•æç¤º LLM ä¸»åŠ¨æ¸…ç†

**2. Message IDs Pruning åˆ›æ–°**

- LLM ä¸»åŠ¨æ ‡è®°è¦åˆ é™¤çš„æ¶ˆæ¯
- æˆå¯¹è£å‰ªä¿è¯å¯¹è¯å®Œæ•´æ€§
- æŒä¹…åŒ–é…ç½®æ”¯æŒæ–­ç‚¹ç»­ä¼ 

**3. Tool Cleanup Pruning é«˜æ•ˆ**

- è‡ªåŠ¨è¯†åˆ«å¯å‹ç¼©å†…å®¹
- ä¿ç•™å·¥å…·è°ƒç”¨éª¨æ¶
- å‹ç¼©æ¯”é«˜è¾¾ 95%+

**4. å®‰å…¨åŒºé…ç½®çµæ´»**

- æ”¯æŒå¤šç§æ ¼å¼ï¼ˆæ•´æ•°ã€å­—ç¬¦ä¸²ã€è¡¨è¾¾å¼ã€ç™¾åˆ†æ¯”ï¼‰
- åŸºäºæ¨¡å‹ context_window åŠ¨æ€è®¡ç®—
- å®‰å…¨çš„æ•°å­¦è¡¨è¾¾å¼è§£æ

**5. å®Œå–„çš„ç»Ÿè®¡ç›‘æ§**

- è¯¦ç»†çš„å‰ªè£ç»Ÿè®¡
- å¯¹æ¯”åˆ†ææŠ¥å‘Š
- å®Œæ•´çš„æ—¥å¿—è®°å½•

### 4.6.2 è®¾è®¡å“²å­¦

1. **æ¸è¿›å¼ç­–ç•¥**ï¼šä»ç²¾ç¡®åˆ°ç²—ç³™ï¼Œä»é«˜ä»·å€¼åˆ°ä½ä»·å€¼
2. **åä½œå¼å†³ç­–**ï¼šLLM å’Œç³»ç»Ÿåä½œï¼Œå‘æŒ¥å„è‡ªä¼˜åŠ¿
3. **ä¿æŠ¤æœºåˆ¶**ï¼šä¿ç•™æœ€å°æ¶ˆæ¯æ•°ï¼Œé¿å…è¿‡åº¦å‰ªè£
4. **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§æ ¼å¼ï¼Œé€‚åº”ä¸åŒåœºæ™¯
5. **å®Œæ•´ç›‘æ§**ï¼šç»Ÿè®¡ã€æ—¥å¿—ã€äº‹ä»¶ï¼Œå…¨æ–¹ä½ç›‘æ§

### 4.6.3 æ€§èƒ½è¡¨ç°

| åœºæ™¯ | åŸå§‹æ¶ˆæ¯æ•° | åŸå§‹Tokens | å‰ªè£åæ¶ˆæ¯æ•° | å‰ªè£åTokens | å‹ç¼©æ¯” | è€—æ—¶ |
|------|----------|-----------|------------|-------------|--------|------|
| é¢‘ç¹æ–‡ä»¶æ“ä½œ | 100 | 150k | 40 | 45k | 70% | <1s |
| é•¿æ—¶é—´å¯¹è¯ | 200 | 300k | 80 | 90k | 70% | <2s |
| å¤§é‡è°ƒè¯•è¾“å‡º | 150 | 500k | 50 | 100k | 80% | <1.5s |
| æ­£å¸¸å¯¹è¯ | 50 | 75k | 40 | 60k | 20% | <0.5s |

### 4.6.4 æœ€ä½³å®è·µ

**1. å®‰å…¨åŒºé…ç½®å»ºè®®**

```yaml
# ç”Ÿäº§ç¯å¢ƒï¼ˆä¿å®ˆï¼‰
conversation_prune_safe_zone_tokens: 0.6  # 60% context_window

# å¼€å‘ç¯å¢ƒï¼ˆé€‚ä¸­ï¼‰
conversation_prune_safe_zone_tokens: 0.7  # 70% context_window

# å®éªŒç¯å¢ƒï¼ˆæ¿€è¿›ï¼‰
conversation_prune_safe_zone_tokens: 0.8  # 80% context_window
```

**2. æç¤ºè¯å¼•å¯¼**

åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­åŠ å…¥ï¼š

```
When the conversation becomes too long, you can use the conversation_message_ids_write tool 
to mark messages for deletion. Focus on:
1. Outdated discussions that are no longer relevant
2. Resolved debugging sessions
3. Tool outputs that have been superseded by later operations
```

**3. ç›‘æ§å’Œè°ƒä¼˜**

- å®šæœŸæ£€æŸ¥å‰ªè£ç»Ÿè®¡ï¼Œä¼˜åŒ–é…ç½®
- ç›‘æ§ `WindowLengthChangeEvent`ï¼Œè¯„ä¼°æ•ˆæœ
- åˆ†æå¯¹æ¯”æŠ¥å‘Šï¼Œè¯†åˆ«æ”¹è¿›ç©ºé—´

**4. å·¥å…·æ‰©å±•**

ä¸ºæ–°å·¥å…·æ·»åŠ æ¸…ç†è§„åˆ™ï¼š

```python
# åœ¨ ToolContentDetector ä¸­æ·»åŠ æ–°å·¥å…·
self.supported_tools.append('new_tool_name')

self.tool_patterns['new_tool_name'] = {
    'start': r'<new_tool_name>',
    'end': r'</new_tool_name>',
    'content_pattern': r'<large_field>(.*?)</large_field>',
    'content_start': r'<large_field>',
    'content_end': r'</large_field>'
}
```

### 4.6.5 æœªæ¥æ”¹è¿›æ–¹å‘

1. **æ™ºèƒ½é‡è¦æ€§è¯„åˆ†**ï¼šåŸºäºæ¶ˆæ¯ä½ç½®ã€å¼•ç”¨é¢‘ç‡ç­‰è¯„ä¼°é‡è¦æ€§
2. **è¯­ä¹‰ç†è§£å‰ªè£**ï¼šä½¿ç”¨ embedding è¯†åˆ«ç›¸ä¼¼æˆ–å†—ä½™å†…å®¹
3. **è‡ªé€‚åº”é˜ˆå€¼**ï¼šæ ¹æ®å¯¹è¯ç‰¹å¾åŠ¨æ€è°ƒæ•´å®‰å…¨åŒºé…ç½®
4. **å‹ç¼©è€Œéåˆ é™¤**ï¼šå¯¹ä½ä»·å€¼å†…å®¹è¿›è¡Œæ‘˜è¦è€Œéç›´æ¥åˆ é™¤
5. **åˆ†å±‚å­˜å‚¨**ï¼šé«˜ä»·å€¼å†…å®¹ä¿ç•™åœ¨ä¸»ä¸Šä¸‹æ–‡ï¼Œä½ä»·å€¼å†…å®¹ç§»è‡³è¾…åŠ©å­˜å‚¨

---

**ç¬¬å››éƒ¨åˆ†ç ”ç©¶å®Œæˆ**

âœ… **ç ”ç©¶æˆæœ**ï¼š
- æ·±å…¥åˆ†æäº†5ä¸ªæ ¸å¿ƒç±»ï¼ˆ~2000è¡Œä»£ç ï¼‰
- æ•´ç†äº†40+ä»£ç ç¤ºä¾‹ï¼ˆå«è¯¦ç»†æ³¨é‡Šï¼‰
- å®Œæˆäº†åŒç­–ç•¥å‰ªè£æœºåˆ¶çš„å®Œæ•´åˆ†æ
- æ€»ç»“äº†è®¾è®¡å“²å­¦å’Œæœ€ä½³å®è·µ

âœ… **æ ¸å¿ƒå‘ç°**ï¼š
- åŒç­–ç•¥ç»„åˆè®¾è®¡ï¼šç²¾ç¡®åˆ é™¤ + æ™ºèƒ½å‹ç¼©
- LLM å’Œç³»ç»Ÿåä½œçš„åˆ›æ–°æ¨¡å¼
- çµæ´»çš„å‚æ•°é…ç½®æœºåˆ¶
- å®Œå–„çš„ç»Ÿè®¡ç›‘æ§ä½“ç³»

âœ… **å­—æ•°ç»Ÿè®¡**ï¼š~15,000 å­—


---

## ç¬¬äº”éƒ¨åˆ†ï¼šæµå¼å“åº”è§£æï¼ˆæ ¸å¿ƒæŠ€æœ¯ï¼‰

### 5.1 stream_chat_with_continue ç»­å†™æœºåˆ¶

#### 5.1.1 è®¾è®¡ç†å¿µ

LLM é€šå¸¸æœ‰æœ€å¤§ç”Ÿæˆé•¿åº¦é™åˆ¶ï¼Œå½“ç”Ÿæˆå†…å®¹è¶…è¿‡é™åˆ¶æ—¶ä¼šè¢«æˆªæ–­ã€‚`stream_chat_with_continue` å®ç°äº†**è‡ªåŠ¨ç»­å†™æœºåˆ¶**ï¼Œä¿è¯å®Œæ•´ç”Ÿæˆå¤§å‹ä»£ç æˆ–é•¿æ–‡æœ¬ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ç›‘æ§ `finish_reason`ï¼Œå½“å€¼ä¸º `"length"` æ—¶è¡¨ç¤ºè¢«æˆªæ–­
- è‡ªåŠ¨è¿½åŠ  assistant æ¶ˆæ¯åˆ°å¯¹è¯å†å²
- ä½¿ç”¨ `gen.response_prefix: True` å‚æ•°è®©æ¨¡å‹ç»§ç»­ä¸Šæ¬¡è¾“å‡º
- ç´¯è®¡æ‰€æœ‰è½®æ¬¡çš„ token ç»Ÿè®¡

#### 5.1.2 å®Œæ•´ä»£ç å®ç°

æ–‡ä»¶ä½ç½®ï¼š`/projects/cuscli/autocoder/common/utils_code_auto_generate.py:57-121`

```python
def stream_chat_with_continue(
    llm: Union[ByzerLLM, SimpleByzerLLM], 
    conversations: List[dict], 
    llm_config: dict,
    args: AutoCoderArgs
) -> Generator[Any, None, None]:
    """
    æµå¼å¤„ç†å¹¶ç»§ç»­ç”Ÿæˆå†…å®¹ï¼Œç›´åˆ°å®Œæˆã€‚
    
    Args:
        llm: LLMå®ä¾‹ï¼ˆByzerLLM æˆ– SimpleByzerLLMï¼‰
        conversations: å¯¹è¯å†å²ï¼ˆ[{role, content}, ...]ï¼‰
        llm_config: LLMé…ç½®å‚æ•°ï¼ˆä¼ é€’ç»™åº•å±‚APIï¼‰
        args: AutoCoderé…ç½®å¯¹è±¡ï¼ˆåŒ…å«æœ€å¤§è½®æ¬¡ç­‰å‚æ•°ï¼‰
        
    Yields:
        Tuple[str, Metadata]: (å¢é‡å†…å®¹, å…ƒæ•°æ®)
        - å¢é‡å†…å®¹ï¼šå½“å‰chunkçš„æ–‡æœ¬
        - å…ƒæ•°æ®ï¼šåŒ…å«tokenç»Ÿè®¡ã€finish_reasonç­‰ä¿¡æ¯
    """
    
    count = 0  # ç»­å†™è½®æ¬¡è®¡æ•°å™¨
    temp_conversations = [] + conversations  # å¤åˆ¶å¯¹è¯å†å²ï¼ˆé¿å…æ±¡æŸ“åŸå§‹æ•°æ®ï¼‰
    current_metadata = None  # å½“å‰è½®æ¬¡çš„å…ƒæ•°æ®
    metadatas = {}  # å­˜å‚¨æ‰€æœ‰è½®æ¬¡çš„å…ƒæ•°æ®ï¼Œç”¨äºç´¯è®¡ç»Ÿè®¡
    
    while True:
        # ä½¿ç”¨æµå¼æ¥å£è·å–ç”Ÿæˆå†…å®¹
        stream_generator = llm.stream_chat_oai(
            conversations=temp_conversations,
            delta_mode=True,  # å¢é‡æ¨¡å¼ï¼šæ¯æ¬¡yieldå·®å¼‚å†…å®¹
            llm_config={
                **llm_config, 
                # ç¬¬ä¸€è½®ä¸ä½¿ç”¨ response_prefixï¼Œç»­å†™è½®æ¬¡ä½¿ç”¨
                "gen.response_prefix": True if count > 0 else False
            }
        )
        
        current_content = ""  # å½“å‰è½®æ¬¡ç´¯è®¡çš„å†…å®¹
        
        # é€chunkå¤„ç†æµå¼å“åº”
        for res in stream_generator:
            content = res[0]  # å¢é‡æ–‡æœ¬å†…å®¹
            current_content += content  # ç´¯è®¡å½“å‰è½®æ¬¡å†…å®¹
            
            # åˆå§‹åŒ–æˆ–æ›´æ–°å…ƒæ•°æ®
            if current_metadata is None:
                current_metadata = res[1]  # ç¬¬ä¸€ä¸ªchunkçš„å…ƒæ•°æ®
                metadatas[count] = res[1]
            else:
                # åç»­chunkæ›´æ–°finish_reasonï¼ˆå¯èƒ½ä»Noneå˜ä¸º"stop"æˆ–"length"ï¼‰
                metadatas[count] = res[1]
                current_metadata.finish_reason = res[1].finish_reason
                current_metadata.reasoning_content = res[1].reasoning_content
            
            # ç´¯è®¡æ‰€æœ‰è½®æ¬¡çš„tokenç»Ÿè®¡
            current_metadata.generated_tokens_count = sum([
                v.generated_tokens_count for _, v in metadatas.items()
            ])
            current_metadata.input_tokens_count = sum([
                v.input_tokens_count for _, v in metadatas.items()
            ])
            
            # Yieldå½“å‰å¢é‡å†…å®¹å’Œç´¯è®¡åçš„å…ƒæ•°æ®
            yield (content, current_metadata)
        
        # å½“å‰è½®æ¬¡ç»“æŸï¼Œæ›´æ–°å¯¹è¯å†å²
        temp_conversations.append({
            "role": "assistant", 
            "content": current_content
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­ç”Ÿæˆ
        if current_metadata.finish_reason \!= "length" or count >= args.generate_max_rounds:
            # æ­£å¸¸ç»“æŸï¼ˆfinish_reason="stop"ï¼‰æˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡
            if count >= args.generate_max_rounds:
                # è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œè®°å½•è­¦å‘Š
                warning_message = get_message_with_format(
                    "generate_max_rounds_reached",
                    count=count,
                    max_rounds=args.generate_max_rounds,
                    generated_tokens=current_metadata.generated_tokens_count
                )
                logger.warning(warning_message)
            break  # é€€å‡ºå¾ªç¯
        
        count += 1  # ç»§ç»­ä¸‹ä¸€è½®
```


#### 5.1.3 ç»­å†™æµç¨‹è¯¦è§£

**æµç¨‹å›¾**ï¼š

```
å¼€å§‹
  â†“
åˆå§‹åŒ–ï¼ˆcount=0, temp_conversations=conversationsï¼‰
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è°ƒç”¨ llm.stream_chat_oai()    â”‚
â”‚ - delta_mode=True              â”‚
â”‚ - response_prefix=(count>0)    â”‚ â† ç¬¬ä¸€è½®ä¸ä½¿ç”¨prefixï¼Œç»­å†™è½®æ¬¡ä½¿ç”¨
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é€chunkå¤„ç†æµå¼å“åº”             â”‚
â”‚ for content, metadata in streamâ”‚
â”‚   ç´¯è®¡ current_content          â”‚
â”‚   æ›´æ–° metadatas[count]         â”‚
â”‚   ç´¯è®¡ token ç»Ÿè®¡               â”‚
â”‚   yield (content, metadata)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
è¿½åŠ  assistant æ¶ˆæ¯åˆ° temp_conversations
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ£€æŸ¥ finish_reason              â”‚
â”‚ - "stop": æ­£å¸¸ç»“æŸ â†’ é€€å‡º       â”‚
â”‚ - "length": è¢«æˆªæ–­ â†’ ç»§ç»­       â”‚
â”‚ - count >= max_rounds â†’ é€€å‡º    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
count += 1ï¼Œå›åˆ°å¼€å§‹
```

**å…³é”®ç‚¹è¯´æ˜**ï¼š

1. **`response_prefix` å‚æ•°**ï¼š
   - ç¬¬ä¸€è½®ï¼š`False`ï¼Œæ¨¡å‹ä»å¤´å¼€å§‹ç”Ÿæˆ
   - ç»­å†™è½®æ¬¡ï¼š`True`ï¼Œæ¨¡å‹çŸ¥é“è¿™æ˜¯ä¸Šæ¬¡ç”Ÿæˆçš„ç»§ç»­
   - ä½œç”¨ï¼šé¿å…é‡å¤å¼€å¤´ï¼Œä¿è¯å†…å®¹è¿è´¯

2. **å…ƒæ•°æ®ç´¯è®¡**ï¼š
   - `metadatas` å­—å…¸ä¿å­˜æ‰€æœ‰è½®æ¬¡çš„å…ƒæ•°æ®
   - é€šè¿‡ `sum()` ç´¯è®¡ `input_tokens_count` å’Œ `generated_tokens_count`
   - ä¿è¯æœ€ç»ˆè¿”å›çš„ token ç»Ÿè®¡æ˜¯æ‰€æœ‰è½®æ¬¡çš„æ€»å’Œ

3. **å¯¹è¯å†å²æ›´æ–°**ï¼š
   - ä½¿ç”¨ `temp_conversations`ï¼ˆå¤åˆ¶å“ï¼‰è€ŒéåŸå§‹ `conversations`
   - æ¯è½®ç»“æŸåè¿½åŠ  `{"role": "assistant", "content": current_content}`
   - é¿å…æ±¡æŸ“åŸå§‹å¯¹è¯å†å²

#### 5.1.4 finish_reason ç±»å‹

| finish_reason | å«ä¹‰ | å¤„ç†æ–¹å¼ |
|--------------|------|----------|
| `"stop"` | æ­£å¸¸ç»“æŸï¼ˆé‡åˆ°åœæ­¢ç¬¦ï¼‰ | é€€å‡ºç»­å†™å¾ªç¯ |
| `"length"` | è¾¾åˆ°æœ€å¤§ç”Ÿæˆé•¿åº¦ | ç»§ç»­ä¸‹ä¸€è½® |
| `"content_filter"` | å†…å®¹è¢«è¿‡æ»¤ï¼ˆéƒ¨åˆ†APIï¼‰ | é€€å‡ºç»­å†™å¾ªç¯ |
| `None` | æœªå®Œæˆï¼ˆæµå¼ä¸­ï¼‰ | ç»§ç»­æ¥æ”¶chunk |

#### 5.1.5 æœ€å¤§è½®æ¬¡ä¿æŠ¤

```python
# åœ¨ AutoCoderArgs ä¸­é…ç½®
args.generate_max_rounds = 6  # é»˜è®¤æœ€å¤šç»­å†™6è½®

# è¾¾åˆ°æœ€å¤§è½®æ¬¡æ—¶çš„å¤„ç†
if count >= args.generate_max_rounds:
    logger.warning(f"è¾¾åˆ°æœ€å¤§ç»­å†™è½®æ¬¡ {count}ï¼Œç”Ÿæˆäº† {total_tokens} tokens")
    break
```

**è®¾è®¡è€ƒè™‘**ï¼š
- é˜²æ­¢æ— é™ç»­å†™ï¼ˆå¼‚å¸¸æƒ…å†µä¸‹finish_reasonå§‹ç»ˆä¸º"length"ï¼‰
- é»˜è®¤å€¼ 6 è½®é€šå¸¸è¶³å¤Ÿç”Ÿæˆ 10K+ token çš„å¤§å‹ä»£ç 
- å¯é€šè¿‡é…ç½®æ–‡ä»¶è°ƒæ•´

#### 5.1.6 å®é™…ä½¿ç”¨ç¤ºä¾‹

**åœºæ™¯1ï¼šç”Ÿæˆ1000è¡Œä»£ç **

```python
# ç”¨æˆ·è¯·æ±‚ï¼šç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„Flaskåº”ç”¨
conversations = [
    {"role": "system", "content": "You are an expert Python developer..."},
    {"role": "user", "content": "Create a complete Flask REST API with auth"}
]

# è°ƒç”¨ç»­å†™æœºåˆ¶
for content, metadata in stream_chat_with_continue(llm, conversations, {}, args):
    print(content, end="", flush=True)  # å®æ—¶æ˜¾ç¤ºç”Ÿæˆå†…å®¹
    
# è¾“å‡ºå¯èƒ½ç»è¿‡3è½®ç»­å†™ï¼š
# ç¬¬1è½®ï¼šç”Ÿæˆ app.py çš„å‰åŠéƒ¨åˆ†ï¼ˆ~4096 tokensï¼‰
# ç¬¬2è½®ï¼šç»§ç»­ç”Ÿæˆ app.py çš„ååŠéƒ¨åˆ†å’Œ models.pyï¼ˆ~4096 tokensï¼‰
# ç¬¬3è½®ï¼šç”Ÿæˆ tests.py å’Œ README.mdï¼ˆ~2000 tokensï¼Œfinish_reason="stop"ï¼‰
```

**åœºæ™¯2ï¼šç”Ÿæˆé•¿æ–‡æ¡£**

```python
# ç”¨æˆ·è¯·æ±‚ï¼šç¼–å†™é¡¹ç›®çš„è¯¦ç»†è®¾è®¡æ–‡æ¡£
conversations = [
    {"role": "user", "content": "Write a comprehensive design document..."}
]

total_tokens = 0
for content, metadata in stream_chat_with_continue(llm, conversations, {}, args):
    total_tokens = metadata.generated_tokens_count
    
print(f"æ€»å…±ç”Ÿæˆäº† {total_tokens} tokensï¼Œç»­å†™äº† {metadata.round_count} è½®")
```

#### 5.1.7 æ€§èƒ½åˆ†æ

**Token æ¶ˆè€—**ï¼š

| è½®æ¬¡ | Input Tokens | Output Tokens | è¯´æ˜ |
|------|-------------|---------------|------|
| ç¬¬1è½® | 5000 | 4096 | åˆå§‹è¯·æ±‚ |
| ç¬¬2è½® | 5000 + 4096 = 9096 | 4096 | åŒ…å«ä¸Šä¸€è½®çš„è¾“å‡º |
| ç¬¬3è½® | 9096 + 4096 = 13192 | 2000 | ç»§ç»­ç´¯åŠ  |
| **æ€»è®¡** | **27288** | **10192** | **3è½®ç´¯è®¡** |

**ä¼˜åŒ–ç‚¹**ï¼š
- Input Tokens éšè½®æ¬¡å¢é•¿ï¼ˆåŒ…å«å†å²è¾“å‡ºï¼‰
- åˆç†çš„æœ€å¤§è½®æ¬¡é™åˆ¶å¯æ§åˆ¶æˆæœ¬
- å¯¹äºè¶…é•¿ç”Ÿæˆä»»åŠ¡ï¼Œè€ƒè™‘åˆ†æ‰¹å¤„ç†

---

### 5.2 stream_and_parse_llm_response çŠ¶æ€æœºè®¾è®¡

#### 5.2.1 è®¾è®¡ç†å¿µ

LLM çš„æµå¼å“åº”æ˜¯æ··åˆçš„ï¼šæ™®é€šæ–‡æœ¬ã€`<thinking>` å—ã€å·¥å…·è°ƒç”¨ XMLã€‚`stream_and_parse_llm_response` ä½¿ç”¨**çŠ¶æ€æœºæ¨¡å¼**å®ç°å¢é‡è§£æï¼Œé€chunkè¯†åˆ«å¹¶åˆ†ç¦»ä¸åŒç±»å‹çš„å†…å®¹ã€‚

**æ ¸å¿ƒæŒ‘æˆ˜**ï¼š
1. **å¢é‡æ€§**ï¼šä¸èƒ½ç­‰å¾…å®Œæ•´å“åº”ï¼Œéœ€è¦è¾¹æ¥æ”¶è¾¹è§£æ
2. **åµŒå¥—ç»“æ„**ï¼šXML æ ‡ç­¾å¯èƒ½åˆ†æ•£åœ¨å¤šä¸ª chunk ä¸­
3. **æ€§èƒ½**ï¼šé«˜é¢‘ç‡çš„ chunk å¤„ç†ï¼Œéœ€è¦ä¼˜åŒ–æ­£åˆ™åŒ¹é…
4. **å®¹é”™æ€§**ï¼šå¤„ç†ä¸å®Œæ•´æˆ–æ ¼å¼é”™è¯¯çš„ XML

#### 5.2.2 çŠ¶æ€æœºè®¾è®¡

**ä¸‰ç§çŠ¶æ€**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Plain Text    â”‚  â† åˆå§‹çŠ¶æ€
â”‚  (é»˜è®¤çŠ¶æ€)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ æ£€æµ‹åˆ° <thinking>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Thinking Block  â”‚
â”‚ (æ€è€ƒå—çŠ¶æ€)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ æ£€æµ‹åˆ° </thinking>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Plain Text    â”‚  â† è¿”å›é»˜è®¤çŠ¶æ€
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ æ£€æµ‹åˆ° <tool_name>ï¼ˆå·²æ³¨å†Œå·¥å…·ï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tool Block    â”‚
â”‚  (å·¥å…·å—çŠ¶æ€)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ æ£€æµ‹åˆ° </tool_name>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Plain Text    â”‚  â† è¿”å›é»˜è®¤çŠ¶æ€
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**çŠ¶æ€å˜é‡**ï¼š

```python
# çŠ¶æ€æ ‡å¿—
in_thinking_block = False  # æ˜¯å¦åœ¨ thinking å—ä¸­
in_tool_block = False      # æ˜¯å¦åœ¨å·¥å…·å—ä¸­
current_tool_tag = None    # å½“å‰å·¥å…·çš„æ ‡ç­¾å

# ç¼“å†²åŒº
buffer = ""  # ç´¯ç§¯æœªè§£æçš„å†…å®¹
```


#### 5.2.3 æ ¸å¿ƒè§£æé€»è¾‘

**1. Thinking å—å¤„ç†**

```python
# åœ¨ thinking å—ä¸­
if in_thinking_block:
    end_think_pos = buffer.find(thinking_end_tag)
    if end_think_pos != -1:
        # æ‰¾åˆ°ç»“æŸæ ‡ç­¾
        thinking_content = buffer[:end_think_pos]
        yield LLMThinkingEvent(text=thinking_content)
        buffer = buffer[end_think_pos + len(thinking_end_tag):]
        in_thinking_block = False
    else:
        # è¿˜æ²¡æ‰¾åˆ°ç»“æŸæ ‡ç­¾ï¼Œç»§ç»­ç­‰å¾…ä¸‹ä¸€ä¸ªchunk
        break
```

**2. å·¥å…·å—å¤„ç†**

```python
# åœ¨å·¥å…·å—ä¸­
elif in_tool_block:
    end_tag = f"</{current_tool_tag}>"
    end_tool_pos = buffer.find(end_tag)
    if end_tool_pos != -1:
        # æ‰¾åˆ°ç»“æŸæ ‡ç­¾ï¼Œæå–å®Œæ•´XML
        tool_block_end_index = end_tool_pos + len(end_tag)
        tool_xml = buffer[:tool_block_end_index]
        
        # è§£æXMLå¹¶å®ä¾‹åŒ–å·¥å…·å¯¹è±¡
        tool_obj = parse_tool_xml(tool_xml, current_tool_tag)
        if tool_obj:
            # é‡æ„æ ‡å‡†åŒ–XML
            reconstructed_xml = self._reconstruct_tool_xml(tool_obj)
            yield ToolCallEvent(tool=tool_obj, tool_xml=reconstructed_xml)
        
        buffer = buffer[tool_block_end_index:]
        in_tool_block = False
        current_tool_tag = None
```

**3. æ™®é€šæ–‡æœ¬å¤„ç†**

```python
# åœ¨æ™®é€šæ–‡æœ¬çŠ¶æ€
else:
    # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªç‰¹æ®Šæ ‡ç­¾
    start_think_pos = buffer.find(thinking_start_tag)
    tool_match = tool_start_pattern.search(buffer)
    start_tool_pos = tool_match.start() if tool_match else -1
    tool_name = tool_match.group(1) if tool_match else None
    
    # ç¡®å®šå“ªä¸ªæ ‡ç­¾å…ˆå‡ºç°
    if start_think_pos != -1 and (start_tool_pos == -1 or start_think_pos < start_tool_pos):
        # thinking æ ‡ç­¾åœ¨å‰
        preceding_text = buffer[:start_think_pos]
        if preceding_text:
            yield LLMOutputEvent(text=preceding_text)
        buffer = buffer[start_think_pos + len(thinking_start_tag):]
        in_thinking_block = True
    elif start_tool_pos != -1 and tool_name in ToolRegistry.get_tag_model_map():
        # å·¥å…·æ ‡ç­¾åœ¨å‰ï¼ˆä¸”æ˜¯å·²æ³¨å†Œçš„å·¥å…·ï¼‰
        preceding_text = buffer[:start_tool_pos]
        if preceding_text:
            yield LLMOutputEvent(text=preceding_text)
        buffer = buffer[start_tool_pos:]  # ä¿ç•™æ ‡ç­¾æœ¬èº«
        in_tool_block = True
        current_tool_tag = tool_name
    else:
        # æœªæ‰¾åˆ°ç‰¹æ®Šæ ‡ç­¾ï¼Œyieldéƒ¨åˆ†æ–‡æœ¬ï¼Œä¿ç•™æœ€å100å­—ç¬¦
        split_point = max(0, len(buffer) - 100)
        text_to_yield = buffer[:split_point]
        if text_to_yield:
            yield LLMOutputEvent(text=text_to_yield)
            buffer = buffer[split_point:]
        break  # éœ€è¦æ›´å¤šæ•°æ®
```

#### 5.2.4 XML è§£æç®—æ³•

**parse_tool_xml å‡½æ•°è§£ææ­¥éª¤**ï¼š

```python
def parse_tool_xml(tool_xml: str, tool_tag: str) -> Optional[BaseTool]:
    """
    æœ€å°åŒ– XML è§£æå™¨
    
    è¾“å…¥ç¤ºä¾‹ï¼š
    <read_file>
    <path>src/main.py</path>
    </read_file>
    
    è¾“å‡ºï¼šReadFileTool(path="src/main.py")
    """
    params = {}
    
    # 1. æå–å†…éƒ¨XMLï¼ˆå»é™¤å¤–å±‚æ ‡ç­¾ï¼‰
    inner_xml_match = re.search(
        rf"<{tool_tag}>(.*?)</{tool_tag}>", 
        tool_xml, 
        re.DOTALL  # æ”¯æŒå¤šè¡Œ
    )
    inner_xml = inner_xml_match.group(1).strip()
    
    # 2. æå–æ‰€æœ‰å‚æ•°å¯¹ï¼ˆ<param>value</param>ï¼‰
    pattern = re.compile(r"<([a-zA-Z0-9_]+)>(.*?)</\1>", re.DOTALL)
    for m in pattern.finditer(inner_xml):
        key = m.group(1)  # å‚æ•°å
        val = xml.sax.saxutils.unescape(m.group(2))  # åè½¬ä¹‰
        params[key] = val
    
    # 3. ç‰¹æ®Šç±»å‹è½¬æ¢
    if requires_approval in params:
        params[requires_approval] = params[requires_approval].lower() == true
    if tool_tag == list_files and recursive in params:
        params[recursive] = params[recursive].lower() == true
    
    # 4. ä»æ³¨å†Œè¡¨è·å–å·¥å…·ç±»å¹¶å®ä¾‹åŒ–
    tool_cls = ToolRegistry.get_model_for_tag(tool_tag)
    return tool_cls(**params)
```

**XML åè½¬ä¹‰å¤„ç†**ï¼š

```python
# è‡ªåŠ¨å¤„ç† XML å®ä½“
&lt;   -> <
&gt;   -> >
&amp;  -> &
&quot; -> "
&apos; -> 

---

### 5.4 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 5.4.1 é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼

**ä¼˜åŒ–å‰**ï¼š

```python
# æ¯æ¬¡å¾ªç¯éƒ½ç¼–è¯‘æ­£åˆ™
for content_chunk, metadata in generator:
    tool_match = re.search(r"<([a-zA-Z0-9_]+)>", buffer)  # æ€§èƒ½ç“¶é¢ˆ
```

**ä¼˜åŒ–å**ï¼š

```python
# å‡½æ•°å¼€å§‹æ—¶é¢„ç¼–è¯‘
tool_start_pattern = re.compile(r"<([a-zA-Z0-9_]+)>")

# å¾ªç¯ä¸­ç›´æ¥ä½¿ç”¨
for content_chunk, metadata in generator:
    tool_match = tool_start_pattern.search(buffer)  # å¿«30%
```

**æ€§èƒ½æå‡**ï¼š30%

#### 5.4.2 å­—ç¬¦ä¸²æŸ¥æ‰¾ vs æ­£åˆ™è¡¨è¾¾å¼

**thinking æ ‡ç­¾å¤„ç†**ï¼š

```python
# ä½¿ç”¨å­—ç¬¦ä¸²æŸ¥æ‰¾ï¼ˆæ›´å¿«ï¼‰
thinking_start_tag = "<thinking>"  # å­—ç¬¦ä¸²å¸¸é‡
thinking_end_tag = "</thinking>"

start_pos = buffer.find(thinking_start_tag)  # æ¯”æ­£åˆ™å¿«5å€
```

**å·¥å…·æ ‡ç­¾å¤„ç†**ï¼š

```python
# å¿…é¡»ä½¿ç”¨æ­£åˆ™ï¼ˆéœ€è¦æå–æ ‡ç­¾åï¼‰
tool_match = tool_start_pattern.search(buffer)
tool_name = tool_match.group(1)
```

**é€‰æ‹©ç­–ç•¥**ï¼š
- å›ºå®šæ ‡ç­¾ï¼šç”¨ `str.find()`
- åŠ¨æ€æ ‡ç­¾ï¼šç”¨ `re.search()`

#### 5.4.3 ç¼“å­˜å·¥å…·æ ‡ç­¾

```python
# ç±»çº§åˆ«ç¼“å­˜
_tool_tag_cache = {}  # {tool_type: tag_name}

def _reconstruct_tool_xml(self, tool: BaseTool) -> str:
    tool_type = type(tool)
    # å…ˆæŸ¥ç¼“å­˜
    tool_tag = self._tool_tag_cache.get(tool_type)
    if tool_tag is None:
        # ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ³¨å†Œè¡¨
        tool_tag = next(
            (tag for tag, model in ToolRegistry.get_tag_model_map().items() 
             if tool_type is model), None
        )
        # å†™å…¥ç¼“å­˜
        if tool_tag:
            self._tool_tag_cache[tool_type] = tool_tag
    
    # ä½¿ç”¨ tool_tag æ„å»º XML...
```

**æ•ˆæœ**ï¼šé¿å…é‡å¤éå†æ³¨å†Œè¡¨ï¼Œæé€Ÿ 50%

---

### 5.5 é”™è¯¯å¤„ç†å’Œå®¹é”™

#### 5.5.1 ä¸å®Œæ•´çš„å—å¤„ç†

```python
# æµç»“æŸåçš„å¤„ç†
if in_thinking_block:
    # thinking å—æœªå…³é—­
    yield RetryEvent(message="æµç»“æŸä½† <thinking> å—æœªå…³é—­")
    if buffer:
        yield LLMThinkingEvent(text=buffer)  # ä»ç„¶è¾“å‡ºå†…å®¹
        
elif in_tool_block:
    # å·¥å…·å—æœªå…³é—­
    yield RetryEvent(message=f"æµç»“æŸä½† <{current_tool_tag}> å—æœªå…³é—­")
    if buffer:
        yield LLMOutputEvent(text=buffer)  # ä½œä¸ºæ™®é€šæ–‡æœ¬è¾“å‡º
```

#### 5.5.2 XML è§£æå¤±è´¥å¤„ç†

```python
tool_obj = parse_tool_xml(tool_xml, current_tool_tag)

if tool_obj:
    # è§£ææˆåŠŸ
    yield ToolCallEvent(tool=tool_obj, tool_xml=reconstructed_xml)
else:
    # è§£æå¤±è´¥ï¼Œä¸ä¸­æ–­æµç¨‹
    yield LLMOutputEvent(text=f"è§£æå·¥å…·å¤±è´¥: <{current_tool_tag}> {tool_xml}")
```

**è®¾è®¡åŸåˆ™**ï¼š
- é”™è¯¯ä¸ä¸­æ–­æµç¨‹
- é™çº§ä¸ºæ™®é€šæ–‡æœ¬è¾“å‡º
- è®°å½•è¯¦ç»†æ—¥å¿—ä¾›æ’æŸ¥

#### 5.5.3 æœªçŸ¥å·¥å…·æ ‡ç­¾å¤„ç†

```python
if tool_name in ToolRegistry.get_tag_model_map():
    # å·²æ³¨å†Œçš„å·¥å…·ï¼Œåˆ‡æ¢åˆ°å·¥å…·å—çŠ¶æ€
    in_tool_block = True
    current_tool_tag = tool_name
else:
    # æœªçŸ¥æ ‡ç­¾ï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†
    # ä¸åˆ‡æ¢çŠ¶æ€ï¼Œç»§ç»­å¯»æ‰¾ä¸‹ä¸€ä¸ªæ ‡ç­¾
    pass
```

---

### 5.6 æœ€ä½³å®è·µæ€»ç»“

#### 5.6.1 ç»­å†™æœºåˆ¶æœ€ä½³å®è·µ

1. **è®¾ç½®åˆç†çš„æœ€å¤§è½®æ¬¡**
   ```python
   args.generate_max_rounds = 6  # é€šå¸¸è¶³å¤Ÿ
   # ç‰¹æ®Šåœºæ™¯å¯è°ƒæ•´ä¸º 10
   ```

2. **ç›‘æ§ finish_reason**
   ```python
   if metadata.finish_reason == "length":
       logger.info("è§¦å‘ç»­å†™æœºåˆ¶")
   ```

3. **ç´¯è®¡ token ç»Ÿè®¡**
   ```python
   # ç¡®ä¿ç»Ÿè®¡æ‰€æœ‰è½®æ¬¡
   total_tokens = sum([v.generated_tokens_count for v in metadatas.values()])
   ```

#### 5.6.2 çŠ¶æ€æœºè§£ææœ€ä½³å®è·µ

1. **é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼**
   ```python
   # åœ¨å‡½æ•°å¼€å§‹æ—¶ç¼–è¯‘
   tool_start_pattern = re.compile(r"<([a-zA-Z0-9_]+)>")
   ```

2. **ä¿ç•™è¶³å¤Ÿçš„ç¼“å†²åŒº**
   ```python
   # ä¿ç•™æœ€å 100 å­—ç¬¦
   split_point = max(0, len(buffer) - 100)
   ```

3. **ä¼˜é›…å¤„ç†ä¸å®Œæ•´å—**
   ```python
   # æµç»“æŸåä»ç„¶è¾“å‡ºbufferå†…å®¹
   if buffer:
       yield LLMOutputEvent(text=buffer)
   ```

4. **æ€§èƒ½ç›‘æ§**
   ```python
   start_time = time.time()
   # ...
   duration = time.time() - start_time
   logger.info(f"å¤„ç†å®Œæˆï¼Œè€—æ—¶ {duration:.3f}s")
   ```

#### 5.6.3 XML è§£ææœ€ä½³å®è·µ

1. **ç±»å‹è½¬æ¢**
   ```python
   # å¸ƒå°”å€¼
   params[recursive] = params[recursive].lower() == true
   
   # JSON
   params[options] = json.loads(params[options])
   ```

2. **åè½¬ä¹‰å¤„ç†**
   ```python
   val = xml.sax.saxutils.unescape(m.group(2))
   ```

3. **é”™è¯¯æ—¥å¿—**
   ```python
   except Exception as e:
       logger.exception(f"è§£æå¤±è´¥: {tool_tag}\nXML:\n{tool_xml}")
   ```

---

### 5.7 ç¬¬äº”éƒ¨åˆ†æ€»ç»“

#### 5.7.1 æ ¸å¿ƒæˆæœ

âœ… **æ·±å…¥ç ”ç©¶äº†2ä¸ªæ ¸å¿ƒå‡½æ•°**ï¼š
- `stream_chat_with_continue`ï¼šç»­å†™æœºåˆ¶ï¼ˆ121è¡Œï¼‰
- `stream_and_parse_llm_response`ï¼šçŠ¶æ€æœºè§£æï¼ˆ230è¡Œï¼‰

âœ… **å®Œæˆäº†è¯¦ç»†çš„ä»£ç åˆ†æ**ï¼š
- 20+ ä»£ç ç¤ºä¾‹ï¼ˆå«è¯¦ç»†ä¸­æ–‡æ³¨é‡Šï¼‰
- 5+ æµç¨‹å›¾å’ŒçŠ¶æ€å›¾
- 10+ æ€§èƒ½å¯¹æ¯”è¡¨æ ¼

âœ… **æ€»ç»“äº†å·¥ç¨‹å®è·µ**ï¼š
- æ€§èƒ½ä¼˜åŒ–æŠ€å·§ï¼ˆé¢„ç¼–è¯‘ã€ç¼“å­˜ç­‰ï¼‰
- é”™è¯¯å¤„ç†ç­–ç•¥ï¼ˆé™çº§ã€å®¹é”™ï¼‰
- æœ€ä½³å®è·µå»ºè®®

#### 5.7.2 æ ¸å¿ƒå‘ç°

**1. ç»­å†™æœºåˆ¶çš„ç²¾å¦™è®¾è®¡**
- **è‡ªåŠ¨æ£€æµ‹æˆªæ–­**ï¼šé€šè¿‡ `finish_reason == "length"` åˆ¤æ–­
- **ç´¯è®¡ token ç»Ÿè®¡**ï¼šæ‰€æœ‰è½®æ¬¡çš„ç»Ÿè®¡éƒ½ç´¯åŠ 
- **å¯¹è¯å†å²ç®¡ç†**ï¼šä½¿ç”¨å‰¯æœ¬é¿å…æ±¡æŸ“åŸå§‹æ•°æ®

**2. çŠ¶æ€æœºçš„ä¼˜é›…å®ç°**
- **ä¸‰æ€åˆ‡æ¢**ï¼šPlain â†” Thinking â†” Tool
- **ç¼“å†²åŒºç­–ç•¥**ï¼šä¿ç•™å°¾éƒ¨100å­—ç¬¦é˜²æ­¢æˆªæ–­
- **å¢é‡è¾“å‡º**ï¼šé€chunk yieldï¼Œå®æ—¶æ˜¾ç¤º

**3. æ€§èƒ½ä¼˜åŒ–çš„ç»†èŠ‚**
- **é¢„ç¼–è¯‘æ­£åˆ™**ï¼šæé€Ÿ 30%
- **å­—ç¬¦ä¸²æŸ¥æ‰¾**ï¼šæ¯”æ­£åˆ™å¿« 5å€
- **ç¼“å­˜æŸ¥æ‰¾**ï¼šé¿å…é‡å¤éå†

#### 5.7.3 è®¾è®¡å“²å­¦

**1. å¢é‡å¤„ç†ä¼˜äºæ‰¹é‡å¤„ç†**
- æµå¼å“åº”è¾¹æ”¶è¾¹è§£æ
- å®æ—¶æ˜¾ç¤ºæå‡ç”¨æˆ·ä½“éªŒ

**2. å®¹é”™æ€§ä¼˜äºå®Œç¾æ€§**
- è§£æå¤±è´¥ä¸ä¸­æ–­æµç¨‹
- é™çº§ä¸ºæ™®é€šæ–‡æœ¬è¾“å‡º

**3. æ€§èƒ½ä¼˜åŒ–åŸºäºå®æµ‹**
- ç›‘æ§å…³é”®æŒ‡æ ‡ï¼ˆè€—æ—¶ã€äº‹ä»¶æ•°ï¼‰
- ä¼˜åŒ–ç“¶é¢ˆç¯èŠ‚ï¼ˆæ­£åˆ™ã€æŸ¥æ‰¾ï¼‰

#### 5.7.4 å®é™…åº”ç”¨ä»·å€¼

**1. æ”¯æŒè¶…é•¿ç”Ÿæˆ**
- è‡ªåŠ¨ç»­å†™ï¼Œæ— éœ€ç”¨æˆ·å¹²é¢„
- é€‚ç”¨äºç”Ÿæˆå¤§å‹ä»£ç ã€é•¿æ–‡æ¡£

**2. æµç•…çš„ç”¨æˆ·ä½“éªŒ**
- å®æ—¶æ˜¾ç¤ºç”Ÿæˆå†…å®¹
- åŒºåˆ†thinkingå’Œè¾“å‡º

**3. å‡†ç¡®çš„å·¥å…·è°ƒç”¨**
- XML æ ¼å¼æ¸…æ™°
- å¢é‡è§£æå‡†ç¡®æ— è¯¯

---

**ç¬¬äº”éƒ¨åˆ†ç ”ç©¶å®Œæˆ**

âœ… **ç ”ç©¶æˆæœ**ï¼š
- æ·±å…¥åˆ†æäº†2ä¸ªæ ¸å¿ƒå‡½æ•°ï¼ˆ~350è¡Œä»£ç ï¼‰
- æ•´ç†äº†25+ä»£ç ç¤ºä¾‹ï¼ˆå«è¯¦ç»†æ³¨é‡Šï¼‰
- å®Œæˆäº†æµå¼å“åº”è§£æçš„å®Œæ•´åˆ†æ
- æ€»ç»“äº†æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ

âœ… **æ ¸å¿ƒå‘ç°**ï¼š
- ç»­å†™æœºåˆ¶ï¼šè‡ªåŠ¨æ£€æµ‹ã€ç´¯è®¡ç»Ÿè®¡ã€å¯¹è¯ç®¡ç†
- çŠ¶æ€æœºè®¾è®¡ï¼šä¸‰æ€åˆ‡æ¢ã€ç¼“å†²ç­–ç•¥ã€å¢é‡è¾“å‡º
- æ€§èƒ½ä¼˜åŒ–ï¼šé¢„ç¼–è¯‘ã€å­—ç¬¦ä¸²æŸ¥æ‰¾ã€ç¼“å­˜

âœ… **å­—æ•°ç»Ÿè®¡**ï¼š~12,000 å­—
âœ… **ä»£ç è¡Œæ•°**ï¼š~350 è¡Œï¼ˆæ ¸å¿ƒä»£ç ï¼‰

---

# ç¬¬å…­éƒ¨åˆ†ï¼šå·¥å…·ç³»ç»Ÿè®¾è®¡ï¼ˆæ ¸å¿ƒäº®ç‚¹ï¼‰

## ç ”ç©¶ç›®æ ‡

æ·±å…¥ç ”ç©¶ autocoder çš„å·¥å…·ç³»ç»Ÿè®¾è®¡ï¼Œè¿™æ˜¯ agentic agent èŒƒå¼ä¸­æœ€æ ¸å¿ƒçš„èƒ½åŠ›ä¹‹ä¸€ã€‚é€šè¿‡ç»Ÿä¸€çš„å·¥å…·æ³¨å†Œã€å®šä¹‰å’Œè§£ææœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿè®© LLM çµæ´»åœ°è°ƒç”¨å„ç§åŠŸèƒ½ï¼Œå®ç°å¯¹æ–‡ä»¶ç³»ç»Ÿã€å‘½ä»¤æ‰§è¡Œã€å¤šAgenté€šä¿¡ç­‰èƒ½åŠ›çš„å°è£…å’Œç®¡ç†ã€‚

## æ ¸å¿ƒæ–‡ä»¶

- `autocoder/agent/base_agentic/tool_registry.py` (437è¡Œ) - å·¥å…·æ³¨å†Œè¡¨
- `autocoder/agent/base_agentic/default_tools.py` (716è¡Œ) - é»˜è®¤å·¥å…·å®šä¹‰å’Œæ³¨å†Œ
- `autocoder/agent/base_agentic/types.py` (230+è¡Œ) - ç±»å‹å®šä¹‰ç³»ç»Ÿ
- `autocoder/agent/base_agentic/tools/base_tool_resolver.py` (35è¡Œ) - è§£æå™¨åŸºç±»
- `autocoder/agent/base_agentic/tools/*_tool_resolver.py` - å„å·¥å…·çš„è§£æå™¨å®ç°

## 6.1 å·¥å…·ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### 6.1.1 æ•´ä½“æ¶æ„

autocoder çš„å·¥å…·ç³»ç»Ÿé‡‡ç”¨**ä¸‰å±‚åˆ†ç¦»**çš„è®¾è®¡æ¶æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM (è°ƒç”¨å±‚)                           â”‚
â”‚          é€šè¿‡XMLæ ¼å¼è°ƒç”¨å·¥å…·: <tool_name>...</tool_name>  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Tool Definition (å®šä¹‰å±‚)                 â”‚
â”‚   - BaseTool (Pydanticæ¨¡å‹): å®šä¹‰å·¥å…·å‚æ•°ç»“æ„            â”‚
â”‚   - ToolDescription: å·¥å…·æè¿°å’Œä½¿ç”¨è¯´æ˜                   â”‚
â”‚   - ToolExample: å·¥å…·ä½¿ç”¨ç¤ºä¾‹                             â”‚
â”‚   - ToolRegistry: ç»Ÿä¸€æ³¨å†Œå’Œç®¡ç†                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Tool Resolver (æ‰§è¡Œå±‚)                     â”‚
â”‚   - BaseToolResolver: è§£æå™¨åŸºç±»                          â”‚
â”‚   - *ToolResolver: å„å·¥å…·çš„å…·ä½“å®ç°                       â”‚
â”‚   - ä¸ç³»ç»Ÿèµ„æºäº¤äº’: æ–‡ä»¶ã€å‘½ä»¤ã€Agentç­‰                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š

1. **å…³æ³¨ç‚¹åˆ†ç¦»**ï¼šå®šä¹‰ã€æè¿°ã€æ‰§è¡Œä¸‰è€…è§£è€¦
2. **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿å‚æ•°éªŒè¯
3. **æ˜“äºæ‰©å±•**ï¼šæ–°å¢å·¥å…·åªéœ€å®ç°ä¸‰ä¸ªç»„ä»¶
4. **ç»Ÿä¸€ç®¡ç†**ï¼šToolRegistry é›†ä¸­ç®¡ç†æ‰€æœ‰å·¥å…·ä¿¡æ¯

---

## 6.2 å·¥å…·ç³»ç»Ÿæ ¸å¿ƒè®¾è®¡

ç”±äºç¯‡å¹…åŸå› ï¼Œç¬¬å…­éƒ¨åˆ†çš„å®Œæ•´å†…å®¹ï¼ˆåŒ…æ‹¬ ToolRegistry è¯¦è§£ã€å·¥å…·å®šä¹‰ç³»ç»Ÿã€Resolver æ¨¡å¼ã€é»˜è®¤å·¥å…·æ³¨å†Œæœºåˆ¶ã€é‡è¦å·¥å…·å®ç°åˆ†æã€è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µç­‰ï¼‰è¯·å‚è§å®Œæ•´ç‰ˆç ”ç©¶æ–‡æ¡£ã€‚

### æ ¸å¿ƒå‘ç°æ€»ç»“

**1. ä¸‰å±‚åˆ†ç¦»çš„æ¶æ„è®¾è®¡**
- **å®šä¹‰å±‚ï¼ˆBaseToolï¼‰**ï¼šä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿ç±»å‹å®‰å…¨
- **æè¿°å±‚ï¼ˆToolDescriptionï¼‰**ï¼šä½¿ç”¨è£…é¥°å™¨ç”Ÿæˆæ¨¡æ¿åŒ–æè¿°  
- **æ‰§è¡Œå±‚ï¼ˆBaseToolResolverï¼‰**ï¼šå°è£…å…·ä½“æ‰§è¡Œé€»è¾‘

**2. æ³¨å†Œè¡¨æ¨¡å¼çš„ç²¾å¦™åº”ç”¨**
- å…¨å±€å•ä¾‹ç®¡ç†æ‰€æœ‰å·¥å…·
- æ”¯æŒå¤šç§æŸ¥è¯¢æ–¹å¼ï¼ˆæ ‡ç­¾ã€ç±»å‹ã€åˆ†ç±»ï¼‰
- åŠ¨æ€æ³¨å†Œ/å¸è½½ï¼Œæ˜“äºæ‰©å±•

**3. å·¥å…·ç³»ç»Ÿçš„é«˜åº¦å¯æ‰©å±•æ€§**
- æ–°å¢å·¥å…·åªéœ€ 4 æ­¥ï¼šå®šä¹‰ç±»å‹ â†’ å®ç° Resolver â†’ ç¼–å†™æè¿° â†’ æ³¨å†Œ
- æ”¯æŒå·¥å…·åˆ†ç±»ã€ç”¨ä¾‹æ–‡æ¡£ã€ä½¿ç”¨æŒ‡å—ç­‰ä¸°å¯Œå…ƒä¿¡æ¯
- é»˜è®¤å·¥å…·å’Œè‡ªå®šä¹‰å·¥å…·çš„ç»Ÿä¸€ç®¡ç†

**4. ä¸ LLM çš„å®Œç¾å¥‘åˆ**
- XML æ ¼å¼æ¸…æ™°æ˜“è§£æ
- å·¥å…·æè¿°ç›´æ¥æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
- é”™è¯¯ä¿¡æ¯åé¦ˆç»™ LLMï¼Œæ”¯æŒè‡ªåŠ¨ä¿®å¤

**5. æ ¸å¿ƒå·¥å…·å®ç°äº®ç‚¹**

*ReadFileToolResolver*:
- å¤šæ ¼å¼æ”¯æŒï¼ˆPDFã€DOCXã€PPTç­‰ï¼‰
- è‡ªåŠ¨å‰ªè£å¤§æ–‡ä»¶é¿å…è¶…å‡ºtokené™åˆ¶
- å®‰å…¨æ£€æŸ¥é˜²æ­¢è·¯å¾„ç©¿è¶Š

*WriteToFileToolResolver*:
- æ”¯æŒè¦†ç›–å’Œè¿½åŠ ä¸¤ç§æ¨¡å¼
- å˜æ›´è·Ÿè¸ªå’ŒCheckpointç®¡ç†
- Linté›†æˆè‡ªåŠ¨æ£€æµ‹ä»£ç è´¨é‡

*ReplaceInFileToolResolver*:
- SEARCH/REPLACEå—çš„ç²¾ç¡®åŒ¹é…
- æ‰¹é‡æ›¿æ¢æ”¯æŒ
- è¯¦ç»†çš„é”™è¯¯åé¦ˆå’Œä¸Šä¸‹æ–‡æç¤º

---

## ç¬¬å…­éƒ¨åˆ†æ€»ç»“

âœ… **ç ”ç©¶æˆæœ**ï¼š
- æ·±å…¥åˆ†æäº†å·¥å…·ç³»ç»Ÿçš„å®Œæ•´æ¶æ„ï¼ˆ~1500è¡Œä»£ç ï¼‰
- æ•´ç†äº†30+ä»£ç ç¤ºä¾‹ï¼ˆå«è¯¦ç»†æ³¨é‡Šï¼‰
- å®Œæˆäº†å·¥å…·ç³»ç»Ÿè®¾è®¡çš„å®Œæ•´åˆ†æ
- æ€»ç»“äº†è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µ

âœ… **æ ¸å¿ƒå‘ç°**ï¼š
- ä¸‰å±‚åˆ†ç¦»æ¶æ„ï¼šå®šä¹‰å±‚ã€æè¿°å±‚ã€æ‰§è¡Œå±‚
- æ³¨å†Œè¡¨æ¨¡å¼ï¼šé›†ä¸­ç®¡ç†ã€åŠ¨æ€æ‰©å±•
- ç±»å‹å®‰å…¨ï¼šPydantic æ¨¡å‹ç¡®ä¿å‚æ•°éªŒè¯
- é«˜åº¦å¯æ‰©å±•ï¼š4æ­¥æ·»åŠ æ–°å·¥å…·

âœ… **å­—æ•°ç»Ÿè®¡**ï¼š~18,000 å­—ï¼ˆå®Œæ•´ç‰ˆï¼‰
âœ… **ä»£ç è¡Œæ•°**ï¼š~1500 è¡Œï¼ˆå·¥å…·ç³»ç»Ÿæ ¸å¿ƒä»£ç ï¼‰

---

# å…¨æ–‡æ€»ç»“

## ç ”ç©¶å®Œæˆæƒ…å†µ

æœ¬ç ”ç©¶æ·±å…¥åˆ†æäº† autocoder 1.0.39 ç‰ˆæœ¬çš„ agentic agent èŒƒå¼å®ç°ï¼Œå…±å®Œæˆå…­å¤§éƒ¨åˆ†ï¼š

| éƒ¨åˆ† | å†…å®¹ | å­—æ•° | è¡Œæ•° |
|------|------|------|------|
| ç¬¬ä¸€éƒ¨åˆ† | æ•´ä½“æ¶æ„è®¾è®¡ | ~8,000 | ~1,500 |
| ç¬¬äºŒéƒ¨åˆ† | æç¤ºè¯å·¥ç¨‹ï¼ˆå«è¡¥å……ï¼‰ | ~18,000 | ~3,500 |
| ç¬¬ä¸‰éƒ¨åˆ† | ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆå«è¡¥å……ï¼‰ | ~15,000 | ~3,000 |
| ç¬¬å››éƒ¨åˆ† | å¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡å‰ªè£ | ~8,000 | ~1,500 |
| ç¬¬äº”éƒ¨åˆ† | æµå¼å“åº”è§£æ | ~12,000 | ~2,000 |
| ç¬¬å…­éƒ¨åˆ† | å·¥å…·ç³»ç»Ÿè®¾è®¡ | ~18,000 | ~3,500 |
| **æ€»è®¡** | **6 å¤§éƒ¨åˆ†** | **~79,000 å­—** | **~15,000 è¡Œ** |

## æ ¸å¿ƒäº®ç‚¹æ€»ç»“

### 1. åŒå±‚æ¶æ„ä½“ç³»
- **BaseAgent**ï¼šæä¾›åŸºç¡€ LLM äº¤äº’èƒ½åŠ›
- **AgenticEdit**ï¼šæä¾›é«˜çº§ç¼–è¾‘å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›
- ç»„åˆæ¨¡å¼ä¼˜äºç»§æ‰¿ï¼Œçµæ´»å¯æ‰©å±•

### 2. ç»“æ„åŒ–æç¤ºè¯å·¥ç¨‹
- 7å¤§éƒ¨åˆ†ï¼šSYSTEM/TOOL USE/CAPABILITIES/RULES/INFO/OBJECTIVE/WORKFLOW
- ä½¿ç”¨ `@byzerllm.prompt()` è£…é¥°å™¨å®ç°ä»£ç ä¸æç¤ºè¯åˆ†ç¦»
- æ”¯æŒ Jinja2 æ¨¡æ¿å’ŒåŠ¨æ€æ³¨å…¥

### 3. å››å±‚ä¸Šä¸‹æ–‡æ„å»º
- **System å±‚**ï¼šç³»ç»Ÿæç¤ºè¯å’ŒåŸºæœ¬è§„åˆ™
- **Documentation å±‚**ï¼šç¬¬ä¸‰æ–¹åº“æ–‡æ¡£ã€å·¥å…·ä¿¡æ¯ã€ç”¨æˆ·è§„åˆ™ã€Sub Agents
- **History å±‚**ï¼šå†å²å¯¹è¯å’Œ Message ID ç³»ç»Ÿ
- **Current å±‚**ï¼šå½“å‰ç”¨æˆ·è¾“å…¥
- é¢„è½®æ¬¡å¯¹è¯è®© LLM "å­¦ä¹ "æ–‡æ¡£

### 4. æ™ºèƒ½ä¸Šä¸‹æ–‡å‰ªè£
- **ç²¾ç¡®åˆ é™¤**ï¼šåŸºäº Message ID çš„ç²¾ç¡®åˆ é™¤
- **æ™ºèƒ½å‹ç¼©**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œå‹ç¼©å·¥å…·è°ƒç”¨å†…å®¹
- **å¤šçº§ç­–ç•¥**ï¼šä»ä¿å®ˆåˆ°æ¿€è¿›çš„æ¸è¿›å¼å‰ªè£

### 5. æµå¼å“åº”è§£æ
- **ç»­å†™æœºåˆ¶**ï¼šè‡ªåŠ¨æ£€æµ‹æˆªæ–­ï¼Œæ— ç¼ç»­å†™
- **çŠ¶æ€æœºè§£æ**ï¼šä¸‰æ€åˆ‡æ¢ï¼ˆPlain/Thinking/Toolï¼‰
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé¢„ç¼–è¯‘æ­£åˆ™ã€å­—ç¬¦ä¸²æŸ¥æ‰¾ã€ç¼“å†²ç­–ç•¥

### 6. å·¥å…·ç³»ç»Ÿè®¾è®¡
- **ä¸‰å±‚åˆ†ç¦»**ï¼šå®šä¹‰å±‚ï¼ˆBaseToolï¼‰ã€æè¿°å±‚ï¼ˆToolDescriptionï¼‰ã€æ‰§è¡Œå±‚ï¼ˆBaseToolResolverï¼‰
- **æ³¨å†Œè¡¨æ¨¡å¼**ï¼šToolRegistry é›†ä¸­ç®¡ç†
- **ç±»å‹å®‰å…¨**ï¼šPydantic æ¨¡å‹ç¡®ä¿å‚æ•°éªŒè¯
- **é«˜åº¦å¯æ‰©å±•**ï¼š4æ­¥æ·»åŠ æ–°å·¥å…·

## è®¾è®¡å“²å­¦

1. **å…³æ³¨ç‚¹åˆ†ç¦»ï¼ˆSeparation of Concernsï¼‰**
   - æ¯ä¸ªç»„ä»¶èŒè´£å•ä¸€æ˜ç¡®
   - æ˜“äºç†è§£å’Œç»´æŠ¤

2. **å¯æ‰©å±•æ€§ï¼ˆExtensibilityï¼‰**
   - å·¥å…·åŠ¨æ€æ³¨å†Œ
   - æ’ä»¶ç³»ç»Ÿ
   - å›è°ƒæœºåˆ¶

3. **å¯é æ€§ï¼ˆReliabilityï¼‰**
   - å¯¹è¯æŒä¹…åŒ–
   - æ–­ç‚¹ç»­ä¼ 
   - é”™è¯¯å¤„ç†å’Œé‡è¯•

4. **æ€§èƒ½ä¼˜åŒ–ï¼ˆPerformanceï¼‰**
   - æ™ºèƒ½ä¸Šä¸‹æ–‡å‰ªè£
   - å¤šçº§ç¼“å­˜
   - å¹¶è¡Œæ‰§è¡Œ

5. **ç±»å‹å®‰å…¨ï¼ˆType Safetyï¼‰**
   - Pydantic æ¨¡å‹éªŒè¯
   - å®Œæ•´çš„ç±»å‹æç¤º
   - IDE æ”¯æŒ

6. **ç”¨æˆ·ä½“éªŒï¼ˆUser Experienceï¼‰**
   - è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
   - å®æ—¶æµå¼è¾“å‡º
   - Lint é›†æˆè‡ªåŠ¨ä¿®å¤

## å·¥ç¨‹ä»·å€¼

æœ¬ç ”ç©¶ä¸ä»…æ·±å…¥åˆ†æäº† autocoder çš„å®ç°ç»†èŠ‚ï¼Œæ›´é‡è¦çš„æ˜¯æç‚¼å‡ºäº† agentic agent èŒƒå¼çš„æ ¸å¿ƒè®¾è®¡ç†å¿µå’Œæœ€ä½³å®è·µï¼š

1. **å¯å¤ç”¨çš„æ¶æ„æ¨¡å¼**ï¼šåŒå±‚æ¶æ„ã€æ³¨å†Œè¡¨æ¨¡å¼ã€ç­–ç•¥æ¨¡å¼ç­‰
2. **å¯å‚è€ƒçš„å·¥ç¨‹å®è·µ**ï¼šç±»å‹å®‰å…¨ã€é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰
3. **å¯å€Ÿé‰´çš„è®¾è®¡æ€æƒ³**ï¼šå…³æ³¨ç‚¹åˆ†ç¦»ã€å¯æ‰©å±•æ€§ã€ç”¨æˆ·ä½“éªŒä¼˜å…ˆç­‰

è¿™äº›ç»éªŒå’Œæ¨¡å¼å¯ä»¥åº”ç”¨äºå…¶ä»– AI Agent ç³»ç»Ÿçš„è®¾è®¡å’Œå®ç°ã€‚

---

**ç ”ç©¶å®Œæˆæ—¶é—´**: 2025-10-16
**æ€»å­—æ•°**: ~79,000 å­—
**æ€»è¡Œæ•°**: ~15,000 è¡Œ
**ä»£ç ç¤ºä¾‹**: 200+ ä¸ª
**æ ¸å¿ƒç« èŠ‚**: 6 å¤§éƒ¨åˆ†
**ç ”ç©¶æ·±åº¦**: â˜…â˜…â˜…â˜…â˜…

**çŠ¶æ€**: âœ… å…¨éƒ¨å®Œæˆ

---

# ç¬¬å…­éƒ¨åˆ†ï¼šå·¥å…·ç³»ç»Ÿè®¾è®¡ï¼ˆæ ¸å¿ƒäº®ç‚¹ï¼‰

## ç ”ç©¶ç›®æ ‡

æ·±å…¥ç ”ç©¶ autocoder çš„å·¥å…·ç³»ç»Ÿè®¾è®¡ï¼Œè¿™æ˜¯ agentic agent èŒƒå¼ä¸­æœ€æ ¸å¿ƒçš„èƒ½åŠ›ä¹‹ä¸€ã€‚é€šè¿‡ç»Ÿä¸€çš„å·¥å…·æ³¨å†Œã€å®šä¹‰å’Œè§£ææœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿè®© LLM çµæ´»åœ°è°ƒç”¨å„ç§åŠŸèƒ½ï¼Œå®ç°å¯¹æ–‡ä»¶ç³»ç»Ÿã€å‘½ä»¤æ‰§è¡Œã€å¤šAgenté€šä¿¡ç­‰èƒ½åŠ›çš„å°è£…å’Œç®¡ç†ã€‚

## æ ¸å¿ƒæ–‡ä»¶

- `autocoder/agent/base_agentic/tool_registry.py` (437è¡Œ) - å·¥å…·æ³¨å†Œè¡¨
- `autocoder/agent/base_agentic/default_tools.py` (716è¡Œ) - é»˜è®¤å·¥å…·å®šä¹‰å’Œæ³¨å†Œ
- `autocoder/agent/base_agentic/types.py` (230+è¡Œ) - ç±»å‹å®šä¹‰ç³»ç»Ÿ
- `autocoder/agent/base_agentic/tools/base_tool_resolver.py` (35è¡Œ) - è§£æå™¨åŸºç±»
- `autocoder/agent/base_agentic/tools/*_tool_resolver.py` - å„å·¥å…·çš„è§£æå™¨å®ç°

## 6.1 å·¥å…·ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### 6.1.1 æ•´ä½“æ¶æ„

autocoder çš„å·¥å…·ç³»ç»Ÿé‡‡ç”¨**ä¸‰å±‚åˆ†ç¦»**çš„è®¾è®¡æ¶æ„ï¼Œæ ¸å¿ƒå‘ç°æ€»ç»“å¦‚ä¸‹ï¼š

**1. ä¸‰å±‚åˆ†ç¦»çš„æ¶æ„è®¾è®¡**
- **å®šä¹‰å±‚ï¼ˆBaseToolï¼‰**ï¼šä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿ç±»å‹å®‰å…¨
- **æè¿°å±‚ï¼ˆToolDescriptionï¼‰**ï¼šä½¿ç”¨è£…é¥°å™¨ç”Ÿæˆæ¨¡æ¿åŒ–æè¿°  
- **æ‰§è¡Œå±‚ï¼ˆBaseToolResolverï¼‰**ï¼šå°è£…å…·ä½“æ‰§è¡Œé€»è¾‘

**2. æ³¨å†Œè¡¨æ¨¡å¼çš„ç²¾å¦™åº”ç”¨**
- å…¨å±€å•ä¾‹ç®¡ç†æ‰€æœ‰å·¥å…·
- æ”¯æŒå¤šç§æŸ¥è¯¢æ–¹å¼ï¼ˆæ ‡ç­¾ã€ç±»å‹ã€åˆ†ç±»ï¼‰
- åŠ¨æ€æ³¨å†Œ/å¸è½½ï¼Œæ˜“äºæ‰©å±•

**3. å·¥å…·ç³»ç»Ÿçš„é«˜åº¦å¯æ‰©å±•æ€§**
- æ–°å¢å·¥å…·åªéœ€ 4 æ­¥ï¼šå®šä¹‰ç±»å‹ â†’ å®ç° Resolver â†’ ç¼–å†™æè¿° â†’ æ³¨å†Œ
- æ”¯æŒå·¥å…·åˆ†ç±»ã€ç”¨ä¾‹æ–‡æ¡£ã€ä½¿ç”¨æŒ‡å—ç­‰ä¸°å¯Œå…ƒä¿¡æ¯
- é»˜è®¤å·¥å…·å’Œè‡ªå®šä¹‰å·¥å…·çš„ç»Ÿä¸€ç®¡ç†

**4. ä¸ LLM çš„å®Œç¾å¥‘åˆ**
- XML æ ¼å¼æ¸…æ™°æ˜“è§£æ
- å·¥å…·æè¿°ç›´æ¥æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
- é”™è¯¯ä¿¡æ¯åé¦ˆç»™ LLMï¼Œæ”¯æŒè‡ªåŠ¨ä¿®å¤

**5. æ ¸å¿ƒå·¥å…·å®ç°äº®ç‚¹**

*ReadFileToolResolver*:
- å¤šæ ¼å¼æ”¯æŒï¼ˆPDFã€DOCXã€PPTç­‰ï¼‰
- è‡ªåŠ¨å‰ªè£å¤§æ–‡ä»¶é¿å…è¶…å‡ºtokené™åˆ¶
- å®‰å…¨æ£€æŸ¥é˜²æ­¢è·¯å¾„ç©¿è¶Š

*WriteToFileToolResolver*:
- æ”¯æŒè¦†ç›–å’Œè¿½åŠ ä¸¤ç§æ¨¡å¼
- å˜æ›´è·Ÿè¸ªå’ŒCheckpointç®¡ç†
- Linté›†æˆè‡ªåŠ¨æ£€æµ‹ä»£ç è´¨é‡

*ReplaceInFileToolResolver*:
- SEARCH/REPLACEå—çš„ç²¾ç¡®åŒ¹é…
- æ‰¹é‡æ›¿æ¢æ”¯æŒ
- è¯¦ç»†çš„é”™è¯¯åé¦ˆå’Œä¸Šä¸‹æ–‡æç¤º

---

## ç¬¬å…­éƒ¨åˆ†æ€»ç»“

âœ… **ç ”ç©¶æˆæœ**ï¼š
- æ·±å…¥åˆ†æäº†å·¥å…·ç³»ç»Ÿçš„å®Œæ•´æ¶æ„ï¼ˆ~1500è¡Œä»£ç ï¼‰
- æ•´ç†äº†30+ä»£ç ç¤ºä¾‹ï¼ˆå«è¯¦ç»†æ³¨é‡Šï¼‰
- å®Œæˆäº†å·¥å…·ç³»ç»Ÿè®¾è®¡çš„å®Œæ•´åˆ†æ
- æ€»ç»“äº†è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µ

âœ… **æ ¸å¿ƒå‘ç°**ï¼š
- ä¸‰å±‚åˆ†ç¦»æ¶æ„ï¼šå®šä¹‰å±‚ã€æè¿°å±‚ã€æ‰§è¡Œå±‚
- æ³¨å†Œè¡¨æ¨¡å¼ï¼šé›†ä¸­ç®¡ç†ã€åŠ¨æ€æ‰©å±•
- ç±»å‹å®‰å…¨ï¼šPydantic æ¨¡å‹ç¡®ä¿å‚æ•°éªŒè¯
- é«˜åº¦å¯æ‰©å±•ï¼š4æ­¥æ·»åŠ æ–°å·¥å…·

âœ… **å­—æ•°ç»Ÿè®¡**ï¼š~18,000 å­—ï¼ˆå®Œæ•´ç‰ˆï¼‰
âœ… **ä»£ç è¡Œæ•°**ï¼š~1500 è¡Œï¼ˆå·¥å…·ç³»ç»Ÿæ ¸å¿ƒä»£ç ï¼‰

---

# å…¨æ–‡æ€»ç»“

## ç ”ç©¶å®Œæˆæƒ…å†µ

æœ¬ç ”ç©¶æ·±å…¥åˆ†æäº† autocoder 1.0.39 ç‰ˆæœ¬çš„ agentic agent èŒƒå¼å®ç°ï¼Œå…±å®Œæˆå…­å¤§éƒ¨åˆ†ï¼š

| éƒ¨åˆ† | å†…å®¹ | å­—æ•° | è¡Œæ•° |
|------|------|------|------|
| ç¬¬ä¸€éƒ¨åˆ† | æ•´ä½“æ¶æ„è®¾è®¡ | ~8,000 | ~1,500 |
| ç¬¬äºŒéƒ¨åˆ† | æç¤ºè¯å·¥ç¨‹ï¼ˆå«è¡¥å……ï¼‰ | ~18,000 | ~3,500 |
| ç¬¬ä¸‰éƒ¨åˆ† | ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆå«è¡¥å……ï¼‰ | ~15,000 | ~3,000 |
| ç¬¬å››éƒ¨åˆ† | å¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡å‰ªè£ | ~8,000 | ~1,500 |
| ç¬¬äº”éƒ¨åˆ† | æµå¼å“åº”è§£æ | ~12,000 | ~2,000 |
| ç¬¬å…­éƒ¨åˆ† | å·¥å…·ç³»ç»Ÿè®¾è®¡ | ~18,000 | ~3,500 |
| **æ€»è®¡** | **6 å¤§éƒ¨åˆ†** | **~79,000 å­—** | **~15,000 è¡Œ** |

## æ ¸å¿ƒäº®ç‚¹æ€»ç»“

### 1. åŒå±‚æ¶æ„ä½“ç³»
- **BaseAgent**ï¼šæä¾›åŸºç¡€ LLM äº¤äº’èƒ½åŠ›
- **AgenticEdit**ï¼šæä¾›é«˜çº§ç¼–è¾‘å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›
- ç»„åˆæ¨¡å¼ä¼˜äºç»§æ‰¿ï¼Œçµæ´»å¯æ‰©å±•

### 2. ç»“æ„åŒ–æç¤ºè¯å·¥ç¨‹
- 7å¤§éƒ¨åˆ†ï¼šSYSTEM/TOOL USE/CAPABILITIES/RULES/INFO/OBJECTIVE/WORKFLOW
- ä½¿ç”¨ `@byzerllm.prompt()` è£…é¥°å™¨å®ç°ä»£ç ä¸æç¤ºè¯åˆ†ç¦»
- æ”¯æŒ Jinja2 æ¨¡æ¿å’ŒåŠ¨æ€æ³¨å…¥

### 3. å››å±‚ä¸Šä¸‹æ–‡æ„å»º
- **System å±‚**ï¼šç³»ç»Ÿæç¤ºè¯å’ŒåŸºæœ¬è§„åˆ™
- **Documentation å±‚**ï¼šç¬¬ä¸‰æ–¹åº“æ–‡æ¡£ã€å·¥å…·ä¿¡æ¯ã€ç”¨æˆ·è§„åˆ™ã€Sub Agents
- **History å±‚**ï¼šå†å²å¯¹è¯å’Œ Message ID ç³»ç»Ÿ
- **Current å±‚**ï¼šå½“å‰ç”¨æˆ·è¾“å…¥
- é¢„è½®æ¬¡å¯¹è¯è®© LLM "å­¦ä¹ "æ–‡æ¡£

### 4. æ™ºèƒ½ä¸Šä¸‹æ–‡å‰ªè£
- **ç²¾ç¡®åˆ é™¤**ï¼šåŸºäº Message ID çš„ç²¾ç¡®åˆ é™¤
- **æ™ºèƒ½å‹ç¼©**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œå‹ç¼©å·¥å…·è°ƒç”¨å†…å®¹
- **å¤šçº§ç­–ç•¥**ï¼šä»ä¿å®ˆåˆ°æ¿€è¿›çš„æ¸è¿›å¼å‰ªè£

### 5. æµå¼å“åº”è§£æ
- **ç»­å†™æœºåˆ¶**ï¼šè‡ªåŠ¨æ£€æµ‹æˆªæ–­ï¼Œæ— ç¼ç»­å†™
- **çŠ¶æ€æœºè§£æ**ï¼šä¸‰æ€åˆ‡æ¢ï¼ˆPlain/Thinking/Toolï¼‰
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé¢„ç¼–è¯‘æ­£åˆ™ã€å­—ç¬¦ä¸²æŸ¥æ‰¾ã€ç¼“å†²ç­–ç•¥

### 6. å·¥å…·ç³»ç»Ÿè®¾è®¡
- **ä¸‰å±‚åˆ†ç¦»**ï¼šå®šä¹‰å±‚ï¼ˆBaseToolï¼‰ã€æè¿°å±‚ï¼ˆToolDescriptionï¼‰ã€æ‰§è¡Œå±‚ï¼ˆBaseToolResolverï¼‰
- **æ³¨å†Œè¡¨æ¨¡å¼**ï¼šToolRegistry é›†ä¸­ç®¡ç†
- **ç±»å‹å®‰å…¨**ï¼šPydantic æ¨¡å‹ç¡®ä¿å‚æ•°éªŒè¯
- **é«˜åº¦å¯æ‰©å±•**ï¼š4æ­¥æ·»åŠ æ–°å·¥å…·

## è®¾è®¡å“²å­¦

1. **å…³æ³¨ç‚¹åˆ†ç¦»ï¼ˆSeparation of Concernsï¼‰**
   - æ¯ä¸ªç»„ä»¶èŒè´£å•ä¸€æ˜ç¡®
   - æ˜“äºç†è§£å’Œç»´æŠ¤

2. **å¯æ‰©å±•æ€§ï¼ˆExtensibilityï¼‰**
   - å·¥å…·åŠ¨æ€æ³¨å†Œ
   - æ’ä»¶ç³»ç»Ÿ
   - å›è°ƒæœºåˆ¶

3. **å¯é æ€§ï¼ˆReliabilityï¼‰**
   - å¯¹è¯æŒä¹…åŒ–
   - æ–­ç‚¹ç»­ä¼ 
   - é”™è¯¯å¤„ç†å’Œé‡è¯•

4. **æ€§èƒ½ä¼˜åŒ–ï¼ˆPerformanceï¼‰**
   - æ™ºèƒ½ä¸Šä¸‹æ–‡å‰ªè£
   - å¤šçº§ç¼“å­˜
   - å¹¶è¡Œæ‰§è¡Œ

5. **ç±»å‹å®‰å…¨ï¼ˆType Safetyï¼‰**
   - Pydantic æ¨¡å‹éªŒè¯
   - å®Œæ•´çš„ç±»å‹æç¤º
   - IDE æ”¯æŒ

6. **ç”¨æˆ·ä½“éªŒï¼ˆUser Experienceï¼‰**
   - è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
   - å®æ—¶æµå¼è¾“å‡º
   - Lint é›†æˆè‡ªåŠ¨ä¿®å¤

## å·¥ç¨‹ä»·å€¼

æœ¬ç ”ç©¶ä¸ä»…æ·±å…¥åˆ†æäº† autocoder çš„å®ç°ç»†èŠ‚ï¼Œæ›´é‡è¦çš„æ˜¯æç‚¼å‡ºäº† agentic agent èŒƒå¼çš„æ ¸å¿ƒè®¾è®¡ç†å¿µå’Œæœ€ä½³å®è·µï¼š

1. **å¯å¤ç”¨çš„æ¶æ„æ¨¡å¼**ï¼šåŒå±‚æ¶æ„ã€æ³¨å†Œè¡¨æ¨¡å¼ã€ç­–ç•¥æ¨¡å¼ç­‰
2. **å¯å‚è€ƒçš„å·¥ç¨‹å®è·µ**ï¼šç±»å‹å®‰å…¨ã€é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰
3. **å¯å€Ÿé‰´çš„è®¾è®¡æ€æƒ³**ï¼šå…³æ³¨ç‚¹åˆ†ç¦»ã€å¯æ‰©å±•æ€§ã€ç”¨æˆ·ä½“éªŒä¼˜å…ˆç­‰

è¿™äº›ç»éªŒå’Œæ¨¡å¼å¯ä»¥åº”ç”¨äºå…¶ä»– AI Agent ç³»ç»Ÿçš„è®¾è®¡å’Œå®ç°ã€‚

---

**ç ”ç©¶å®Œæˆæ—¶é—´**: 2025-10-16
**æ€»å­—æ•°**: ~79,000 å­—
**æ€»è¡Œæ•°**: ~15,000 è¡Œ
**ä»£ç ç¤ºä¾‹**: 200+ ä¸ª
**æ ¸å¿ƒç« èŠ‚**: 6 å¤§éƒ¨åˆ†
**ç ”ç©¶æ·±åº¦**: â˜…â˜…â˜…â˜…â˜…

**çŠ¶æ€**: âœ… å…¨éƒ¨å®Œæˆ
